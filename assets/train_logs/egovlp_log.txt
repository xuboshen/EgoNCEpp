2024-05-01 16:27:16,352 - train - INFO - EgoVLP_lora(
  (text_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (video_model): PeftModel(
    (base_model): LoraModel(
      (model): SpaceTimeTransformer(
        (patch_embed): VideoPatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (blocks): ModuleList(
          (0-11): 12 x SpaceTimeBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (timeattn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=3072, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=3072, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act): GELU(approximate='none')
              (fc2): lora.Linear(
                (base_layer): Linear(in_features=3072, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=3072, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pre_logits): Identity()
        (head): Identity()
        (fc): Identity()
      )
    )
  )
  (txt_proj): Sequential(
    (0): ReLU()
    (1): Linear(in_features=768, out_features=256, bias=True)
  )
  (vid_proj): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
)
Trainable parameters: 3301632
2024-05-01 16:28:10,625 - train - INFO - EgoVLP_lora(
  (text_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (video_model): PeftModel(
    (base_model): LoraModel(
      (model): SpaceTimeTransformer(
        (patch_embed): VideoPatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (blocks): ModuleList(
          (0-11): 12 x SpaceTimeBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (timeattn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=3072, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=3072, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act): GELU(approximate='none')
              (fc2): lora.Linear(
                (base_layer): Linear(in_features=3072, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=3072, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pre_logits): Identity()
        (head): Identity()
        (fc): Identity()
      )
    )
  )
  (txt_proj): Sequential(
    (0): ReLU()
    (1): Linear(in_features=768, out_features=256, bias=True)
  )
  (vid_proj): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
)
Trainable parameters: 3301632
2024-05-01 16:28:24,148 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:28:24,153 - trainer - INFO - Train Epoch: 1 dl0 [0/2572210 (0%)] Loss: nan; lr: 1.4000000000000001e-06; Time/iteration: 0.219m; Time so far/epoch: 0.004h
2024-05-01 16:28:26,758 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:28:29,378 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:28:31,982 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:30:45,146 - train - INFO - EgoVLP_lora(
  (text_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (video_model): PeftModel(
    (base_model): LoraModel(
      (model): SpaceTimeTransformer(
        (patch_embed): VideoPatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (blocks): ModuleList(
          (0-11): 12 x SpaceTimeBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (timeattn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=3072, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=3072, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act): GELU(approximate='none')
              (fc2): lora.Linear(
                (base_layer): Linear(in_features=3072, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=3072, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pre_logits): Identity()
        (head): Identity()
        (fc): Identity()
      )
    )
  )
  (txt_proj): Sequential(
    (0): ReLU()
    (1): Linear(in_features=768, out_features=256, bias=True)
  )
  (vid_proj): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
)
Trainable parameters: 3301632
2024-05-01 16:30:57,340 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:30:57,344 - trainer - INFO - Train Epoch: 1 dl0 [0/2572210 (0%)] Loss: nan; lr: 1.4000000000000001e-06; Time/iteration: 0.197m; Time so far/epoch: 0.003h
2024-05-01 16:30:59,951 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:31:02,592 - tensorboardX.x2num - WARNING - NaN or Inf found in input tensor.
2024-05-01 16:32:14,202 - train - INFO - EgoVLP_lora(
  (text_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (video_model): PeftModel(
    (base_model): LoraModel(
      (model): SpaceTimeTransformer(
        (patch_embed): VideoPatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (blocks): ModuleList(
          (0-11): 12 x SpaceTimeBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (timeattn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=3072, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=3072, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act): GELU(approximate='none')
              (fc2): lora.Linear(
                (base_layer): Linear(in_features=3072, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=3072, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pre_logits): Identity()
        (head): Identity()
        (fc): Identity()
      )
    )
  )
  (txt_proj): Sequential(
    (0): ReLU()
    (1): Linear(in_features=768, out_features=256, bias=True)
  )
  (vid_proj): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
)
Trainable parameters: 3301632
2024-05-01 16:32:27,359 - trainer - INFO - Train Epoch: 1 dl0 [0/2572210 (0%)] Loss: 1.634843; lr: 1.4000000000000001e-06; Time/iteration: 0.213m; Time so far/epoch: 0.004h
2024-05-01 16:32:48,305 - trainer - INFO - Train Epoch: 1 dl0 [576/2572210 (0%)] Loss: 1.804532; lr: 1.02e-05; Time/iteration: 0.349m; Time so far/epoch: 0.009h
2024-05-01 16:33:36,794 - train - INFO - EgoVLP_lora(
  (text_model): DistilBertModel(
    (embeddings): Embeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): Transformer(
      (layer): ModuleList(
        (0-5): 6 x TransformerBlock(
          (attention): MultiHeadSelfAttention(
            (dropout): Dropout(p=0.1, inplace=False)
            (q_lin): Linear(in_features=768, out_features=768, bias=True)
            (k_lin): Linear(in_features=768, out_features=768, bias=True)
            (v_lin): Linear(in_features=768, out_features=768, bias=True)
            (out_lin): Linear(in_features=768, out_features=768, bias=True)
          )
          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (ffn): FFN(
            (dropout): Dropout(p=0.1, inplace=False)
            (lin1): Linear(in_features=768, out_features=3072, bias=True)
            (lin2): Linear(in_features=3072, out_features=768, bias=True)
            (activation): GELUActivation()
          )
          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
  )
  (video_model): PeftModel(
    (base_model): LoraModel(
      (model): SpaceTimeTransformer(
        (patch_embed): VideoPatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (blocks): ModuleList(
          (0-11): 12 x SpaceTimeBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (timeattn): VarAttention(
              (qkv): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=2304, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (proj): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): lora.Linear(
                (base_layer): Linear(in_features=768, out_features=3072, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=768, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=3072, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (act): GELU(approximate='none')
              (fc2): lora.Linear(
                (base_layer): Linear(in_features=3072, out_features=768, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=3072, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=768, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (pre_logits): Identity()
        (head): Identity()
        (fc): Identity()
      )
    )
  )
  (txt_proj): Sequential(
    (0): ReLU()
    (1): Linear(in_features=768, out_features=256, bias=True)
  )
  (vid_proj): Sequential(
    (0): Linear(in_features=768, out_features=256, bias=True)
  )
)
Trainable parameters: 3301632
2024-05-01 16:34:20,057 - trainer - INFO - Train Epoch: 1 dl0 [0/321526 (0%)] Loss: 2.247008; lr: 1.4000000000000001e-06; Time/iteration: 0.674m; Time so far/epoch: 0.011h
2024-05-01 16:34:51,064 - trainer - INFO - Train Epoch: 1 dl0 [576/321526 (0%)] Loss: 2.204649; lr: 1.02e-05; Time/iteration: 0.517m; Time so far/epoch: 0.020h
2024-05-01 16:35:18,643 - trainer - INFO - Train Epoch: 1 dl0 [1152/321526 (0%)] Loss: 2.080968; lr: 1.8999999999999998e-05; Time/iteration: 0.460m; Time so far/epoch: 0.028h
2024-05-01 16:35:45,499 - trainer - INFO - Train Epoch: 1 dl0 [1728/321526 (1%)] Loss: 2.129156; lr: 2.78e-05; Time/iteration: 0.448m; Time so far/epoch: 0.035h
2024-05-01 16:36:11,298 - trainer - INFO - Train Epoch: 1 dl0 [2304/321526 (1%)] Loss: 2.134840; lr: 2.999999657411554e-05; Time/iteration: 0.430m; Time so far/epoch: 0.042h
2024-05-01 16:36:38,156 - trainer - INFO - Train Epoch: 1 dl0 [2880/321526 (1%)] Loss: 2.051344; lr: 2.9999981347965555e-05; Time/iteration: 0.448m; Time so far/epoch: 0.050h
2024-05-01 16:37:03,375 - trainer - INFO - Train Epoch: 1 dl0 [3456/321526 (1%)] Loss: 2.260039; lr: 2.999995394090869e-05; Time/iteration: 0.420m; Time so far/epoch: 0.057h
2024-05-01 16:37:28,492 - trainer - INFO - Train Epoch: 1 dl0 [4032/321526 (1%)] Loss: 2.189289; lr: 2.9999914352967437e-05; Time/iteration: 0.419m; Time so far/epoch: 0.064h
2024-05-01 16:37:52,014 - trainer - INFO - Train Epoch: 1 dl0 [4608/321526 (1%)] Loss: 2.159281; lr: 2.9999862584174263e-05; Time/iteration: 0.392m; Time so far/epoch: 0.070h
2024-05-01 16:38:15,324 - trainer - INFO - Train Epoch: 1 dl0 [5184/321526 (2%)] Loss: 2.190059; lr: 2.9999798634571634e-05; Time/iteration: 0.388m; Time so far/epoch: 0.077h
2024-05-01 16:38:38,788 - trainer - INFO - Train Epoch: 1 dl0 [5760/321526 (2%)] Loss: 2.080590; lr: 2.9999722504212002e-05; Time/iteration: 0.391m; Time so far/epoch: 0.083h
2024-05-01 16:39:01,593 - trainer - INFO - Train Epoch: 1 dl0 [6336/321526 (2%)] Loss: 2.100476; lr: 2.9999634193157813e-05; Time/iteration: 0.380m; Time so far/epoch: 0.089h
2024-05-01 16:39:24,249 - trainer - INFO - Train Epoch: 1 dl0 [6912/321526 (2%)] Loss: 2.150305; lr: 2.9999533701481513e-05; Time/iteration: 0.378m; Time so far/epoch: 0.096h
2024-05-01 16:39:46,693 - trainer - INFO - Train Epoch: 1 dl0 [7488/321526 (2%)] Loss: 2.116245; lr: 2.9999421029265524e-05; Time/iteration: 0.374m; Time so far/epoch: 0.102h
2024-05-01 16:40:10,239 - trainer - INFO - Train Epoch: 1 dl0 [8064/321526 (3%)] Loss: 2.083883; lr: 2.9999296176602275e-05; Time/iteration: 0.392m; Time so far/epoch: 0.109h
2024-05-01 16:40:33,018 - trainer - INFO - Train Epoch: 1 dl0 [8640/321526 (3%)] Loss: 2.073156; lr: 2.999915914359417e-05; Time/iteration: 0.380m; Time so far/epoch: 0.115h
2024-05-01 16:40:56,137 - trainer - INFO - Train Epoch: 1 dl0 [9216/321526 (3%)] Loss: 2.050302; lr: 2.999900993035361e-05; Time/iteration: 0.385m; Time so far/epoch: 0.121h
2024-05-01 16:41:19,585 - trainer - INFO - Train Epoch: 1 dl0 [9792/321526 (3%)] Loss: 2.161041; lr: 2.9998848537003e-05; Time/iteration: 0.391m; Time so far/epoch: 0.128h
2024-05-01 16:41:42,188 - trainer - INFO - Train Epoch: 1 dl0 [10368/321526 (3%)] Loss: 2.102195; lr: 2.999867496367472e-05; Time/iteration: 0.377m; Time so far/epoch: 0.134h
2024-05-01 16:42:05,662 - trainer - INFO - Train Epoch: 1 dl0 [10944/321526 (3%)] Loss: 2.027499; lr: 2.9998489210511144e-05; Time/iteration: 0.391m; Time so far/epoch: 0.141h
2024-05-01 16:42:28,456 - trainer - INFO - Train Epoch: 1 dl0 [11520/321526 (4%)] Loss: 2.098304; lr: 2.999829127766464e-05; Time/iteration: 0.380m; Time so far/epoch: 0.147h
2024-05-01 16:42:51,696 - trainer - INFO - Train Epoch: 1 dl0 [12096/321526 (4%)] Loss: 2.033793; lr: 2.9998081165297566e-05; Time/iteration: 0.387m; Time so far/epoch: 0.153h
2024-05-01 16:43:14,939 - trainer - INFO - Train Epoch: 1 dl0 [12672/321526 (4%)] Loss: 2.062078; lr: 2.9997858873582268e-05; Time/iteration: 0.387m; Time so far/epoch: 0.160h
2024-05-01 16:43:37,448 - trainer - INFO - Train Epoch: 1 dl0 [13248/321526 (4%)] Loss: 2.114061; lr: 2.999762440270109e-05; Time/iteration: 0.375m; Time so far/epoch: 0.166h
2024-05-01 16:44:00,448 - trainer - INFO - Train Epoch: 1 dl0 [13824/321526 (4%)] Loss: 2.055970; lr: 2.9997377752846352e-05; Time/iteration: 0.383m; Time so far/epoch: 0.172h
2024-05-01 16:44:23,280 - trainer - INFO - Train Epoch: 1 dl0 [14400/321526 (4%)] Loss: 2.030379; lr: 2.9997118924220373e-05; Time/iteration: 0.381m; Time so far/epoch: 0.179h
2024-05-01 16:44:46,832 - trainer - INFO - Train Epoch: 1 dl0 [14976/321526 (5%)] Loss: 2.072536; lr: 2.9996847917035466e-05; Time/iteration: 0.393m; Time so far/epoch: 0.185h
2024-05-01 16:45:09,594 - trainer - INFO - Train Epoch: 1 dl0 [15552/321526 (5%)] Loss: 2.144834; lr: 2.9996564731513928e-05; Time/iteration: 0.379m; Time so far/epoch: 0.192h
2024-05-01 16:45:32,203 - trainer - INFO - Train Epoch: 1 dl0 [16128/321526 (5%)] Loss: 2.122092; lr: 2.999626936788804e-05; Time/iteration: 0.377m; Time so far/epoch: 0.198h
2024-05-01 16:45:55,154 - trainer - INFO - Train Epoch: 1 dl0 [16704/321526 (5%)] Loss: 2.063340; lr: 2.9995961826400084e-05; Time/iteration: 0.383m; Time so far/epoch: 0.204h
2024-05-01 16:46:18,106 - trainer - INFO - Train Epoch: 1 dl0 [17280/321526 (5%)] Loss: 2.090593; lr: 2.999564210730232e-05; Time/iteration: 0.383m; Time so far/epoch: 0.211h
2024-05-01 16:46:41,948 - trainer - INFO - Train Epoch: 1 dl0 [17856/321526 (6%)] Loss: 2.003939; lr: 2.9995310210857005e-05; Time/iteration: 0.397m; Time so far/epoch: 0.217h
2024-05-01 16:47:04,770 - trainer - INFO - Train Epoch: 1 dl0 [18432/321526 (6%)] Loss: 1.946645; lr: 2.999496613733638e-05; Time/iteration: 0.380m; Time so far/epoch: 0.224h
2024-05-01 16:47:27,300 - trainer - INFO - Train Epoch: 1 dl0 [19008/321526 (6%)] Loss: 1.913931; lr: 2.999460988702268e-05; Time/iteration: 0.375m; Time so far/epoch: 0.230h
2024-05-01 16:47:50,712 - trainer - INFO - Train Epoch: 1 dl0 [19584/321526 (6%)] Loss: 2.105715; lr: 2.9994241460208125e-05; Time/iteration: 0.390m; Time so far/epoch: 0.236h
2024-05-01 16:48:13,542 - trainer - INFO - Train Epoch: 1 dl0 [20160/321526 (6%)] Loss: 2.074211; lr: 2.999386085719492e-05; Time/iteration: 0.380m; Time so far/epoch: 0.243h
2024-05-01 16:48:37,647 - trainer - INFO - Train Epoch: 1 dl0 [20736/321526 (6%)] Loss: 2.188972; lr: 2.999346807829526e-05; Time/iteration: 0.402m; Time so far/epoch: 0.249h
2024-05-01 16:49:00,534 - trainer - INFO - Train Epoch: 1 dl0 [21312/321526 (7%)] Loss: 2.039168; lr: 2.9993063123831322e-05; Time/iteration: 0.381m; Time so far/epoch: 0.256h
2024-05-01 16:49:23,466 - trainer - INFO - Train Epoch: 1 dl0 [21888/321526 (7%)] Loss: 2.118382; lr: 2.999264599413528e-05; Time/iteration: 0.382m; Time so far/epoch: 0.262h
2024-05-01 16:49:45,948 - trainer - INFO - Train Epoch: 1 dl0 [22464/321526 (7%)] Loss: 2.123105; lr: 2.9992216689549296e-05; Time/iteration: 0.375m; Time so far/epoch: 0.268h
2024-05-01 16:50:08,769 - trainer - INFO - Train Epoch: 1 dl0 [23040/321526 (7%)] Loss: 2.170964; lr: 2.9991775210425506e-05; Time/iteration: 0.380m; Time so far/epoch: 0.275h
2024-05-01 16:50:32,643 - trainer - INFO - Train Epoch: 1 dl0 [23616/321526 (7%)] Loss: 2.064299; lr: 2.9991321557126044e-05; Time/iteration: 0.398m; Time so far/epoch: 0.281h
2024-05-01 16:50:55,530 - trainer - INFO - Train Epoch: 1 dl0 [24192/321526 (8%)] Loss: 2.153509; lr: 2.9990855730023024e-05; Time/iteration: 0.381m; Time so far/epoch: 0.288h
2024-05-01 16:51:18,587 - trainer - INFO - Train Epoch: 1 dl0 [24768/321526 (8%)] Loss: 2.042005; lr: 2.999037772949854e-05; Time/iteration: 0.384m; Time so far/epoch: 0.294h
2024-05-01 16:51:41,029 - trainer - INFO - Train Epoch: 1 dl0 [25344/321526 (8%)] Loss: 1.992206; lr: 2.998988755594469e-05; Time/iteration: 0.374m; Time so far/epoch: 0.300h
2024-05-01 16:52:04,095 - trainer - INFO - Train Epoch: 1 dl0 [25920/321526 (8%)] Loss: 2.010944; lr: 2.998938520976354e-05; Time/iteration: 0.384m; Time so far/epoch: 0.307h
2024-05-01 16:52:27,178 - trainer - INFO - Train Epoch: 1 dl0 [26496/321526 (8%)] Loss: 2.076599; lr: 2.998887069136715e-05; Time/iteration: 0.385m; Time so far/epoch: 0.313h
2024-05-01 16:52:50,525 - trainer - INFO - Train Epoch: 1 dl0 [27072/321526 (8%)] Loss: 2.037890; lr: 2.9988344001177555e-05; Time/iteration: 0.389m; Time so far/epoch: 0.320h
2024-05-01 16:53:14,249 - trainer - INFO - Train Epoch: 1 dl0 [27648/321526 (9%)] Loss: 2.038863; lr: 2.9987805139626786e-05; Time/iteration: 0.395m; Time so far/epoch: 0.326h
2024-05-01 16:53:36,598 - trainer - INFO - Train Epoch: 1 dl0 [28224/321526 (9%)] Loss: 2.019190; lr: 2.9987254107156845e-05; Time/iteration: 0.372m; Time so far/epoch: 0.332h
2024-05-01 16:53:59,918 - trainer - INFO - Train Epoch: 1 dl0 [28800/321526 (9%)] Loss: 2.034091; lr: 2.9986690904219734e-05; Time/iteration: 0.389m; Time so far/epoch: 0.339h
2024-05-01 16:54:22,748 - trainer - INFO - Train Epoch: 1 dl0 [29376/321526 (9%)] Loss: 2.153896; lr: 2.998611553127742e-05; Time/iteration: 0.380m; Time so far/epoch: 0.345h
2024-05-01 16:54:46,545 - trainer - INFO - Train Epoch: 1 dl0 [29952/321526 (9%)] Loss: 2.140773; lr: 2.9985527988801865e-05; Time/iteration: 0.397m; Time so far/epoch: 0.352h
2024-05-01 16:55:09,513 - trainer - INFO - Train Epoch: 1 dl0 [30528/321526 (9%)] Loss: 2.057244; lr: 2.9984928277275007e-05; Time/iteration: 0.383m; Time so far/epoch: 0.358h
2024-05-01 16:55:31,984 - trainer - INFO - Train Epoch: 1 dl0 [31104/321526 (10%)] Loss: 1.961440; lr: 2.9984316397188766e-05; Time/iteration: 0.375m; Time so far/epoch: 0.365h
2024-05-01 16:55:54,975 - trainer - INFO - Train Epoch: 1 dl0 [31680/321526 (10%)] Loss: 1.997745; lr: 2.998369234904505e-05; Time/iteration: 0.383m; Time so far/epoch: 0.371h
2024-05-01 16:56:17,788 - trainer - INFO - Train Epoch: 1 dl0 [32256/321526 (10%)] Loss: 1.861232; lr: 2.998305613335574e-05; Time/iteration: 0.380m; Time so far/epoch: 0.377h
2024-05-01 16:56:41,124 - trainer - INFO - Train Epoch: 1 dl0 [32832/321526 (10%)] Loss: 2.018182; lr: 2.9982407750642704e-05; Time/iteration: 0.389m; Time so far/epoch: 0.384h
2024-05-01 16:57:04,267 - trainer - INFO - Train Epoch: 1 dl0 [33408/321526 (10%)] Loss: 2.123675; lr: 2.9981747201437784e-05; Time/iteration: 0.386m; Time so far/epoch: 0.390h
2024-05-01 16:57:27,846 - trainer - INFO - Train Epoch: 1 dl0 [33984/321526 (11%)] Loss: 2.021743; lr: 2.9981074486282803e-05; Time/iteration: 0.393m; Time so far/epoch: 0.397h
2024-05-01 16:57:50,634 - trainer - INFO - Train Epoch: 1 dl0 [34560/321526 (11%)] Loss: 2.140797; lr: 2.9980389605729573e-05; Time/iteration: 0.380m; Time so far/epoch: 0.403h
2024-05-01 16:58:13,116 - trainer - INFO - Train Epoch: 1 dl0 [35136/321526 (11%)] Loss: 2.050738; lr: 2.997969256033987e-05; Time/iteration: 0.375m; Time so far/epoch: 0.409h
2024-05-01 16:58:36,794 - trainer - INFO - Train Epoch: 1 dl0 [35712/321526 (11%)] Loss: 2.079748; lr: 2.9978983350685453e-05; Time/iteration: 0.395m; Time so far/epoch: 0.416h
2024-05-01 16:58:59,615 - trainer - INFO - Train Epoch: 1 dl0 [36288/321526 (11%)] Loss: 1.852746; lr: 2.997826197734807e-05; Time/iteration: 0.380m; Time so far/epoch: 0.422h
2024-05-01 16:59:23,846 - trainer - INFO - Train Epoch: 1 dl0 [36864/321526 (11%)] Loss: 1.941056; lr: 2.9977528440919432e-05; Time/iteration: 0.404m; Time so far/epoch: 0.429h
2024-05-01 16:59:46,438 - trainer - INFO - Train Epoch: 1 dl0 [37440/321526 (12%)] Loss: 2.021498; lr: 2.997678274200123e-05; Time/iteration: 0.377m; Time so far/epoch: 0.435h
2024-05-01 17:00:09,063 - trainer - INFO - Train Epoch: 1 dl0 [38016/321526 (12%)] Loss: 2.094829; lr: 2.997602488120514e-05; Time/iteration: 0.377m; Time so far/epoch: 0.442h
2024-05-01 17:00:31,958 - trainer - INFO - Train Epoch: 1 dl0 [38592/321526 (12%)] Loss: 2.068187; lr: 2.9975254859152808e-05; Time/iteration: 0.381m; Time so far/epoch: 0.448h
2024-05-01 17:00:54,864 - trainer - INFO - Train Epoch: 1 dl0 [39168/321526 (12%)] Loss: 1.908218; lr: 2.997447267647585e-05; Time/iteration: 0.382m; Time so far/epoch: 0.454h
2024-05-01 17:01:18,600 - trainer - INFO - Train Epoch: 1 dl0 [39744/321526 (12%)] Loss: 2.016692; lr: 2.9973678333815865e-05; Time/iteration: 0.396m; Time so far/epoch: 0.461h
2024-05-01 17:01:40,864 - trainer - INFO - Train Epoch: 1 dl0 [40320/321526 (13%)] Loss: 1.939999; lr: 2.997287183182443e-05; Time/iteration: 0.371m; Time so far/epoch: 0.467h
2024-05-01 17:02:03,816 - trainer - INFO - Train Epoch: 1 dl0 [40896/321526 (13%)] Loss: 2.027281; lr: 2.997205317116308e-05; Time/iteration: 0.383m; Time so far/epoch: 0.473h
2024-05-01 17:02:26,717 - trainer - INFO - Train Epoch: 1 dl0 [41472/321526 (13%)] Loss: 2.093333; lr: 2.9971222352503338e-05; Time/iteration: 0.382m; Time so far/epoch: 0.480h
2024-05-01 17:02:50,047 - trainer - INFO - Train Epoch: 1 dl0 [42048/321526 (13%)] Loss: 1.995074; lr: 2.997037937652669e-05; Time/iteration: 0.389m; Time so far/epoch: 0.486h
2024-05-01 17:03:14,084 - trainer - INFO - Train Epoch: 1 dl0 [42624/321526 (13%)] Loss: 2.017101; lr: 2.996952424392461e-05; Time/iteration: 0.401m; Time so far/epoch: 0.493h
2024-05-01 17:03:36,967 - trainer - INFO - Train Epoch: 1 dl0 [43200/321526 (13%)] Loss: 2.047761; lr: 2.9968656955398517e-05; Time/iteration: 0.381m; Time so far/epoch: 0.499h
2024-05-01 17:04:00,265 - trainer - INFO - Train Epoch: 1 dl0 [43776/321526 (14%)] Loss: 1.947097; lr: 2.996777751165983e-05; Time/iteration: 0.388m; Time so far/epoch: 0.506h
2024-05-01 17:04:23,121 - trainer - INFO - Train Epoch: 1 dl0 [44352/321526 (14%)] Loss: 2.176249; lr: 2.9966885913429917e-05; Time/iteration: 0.381m; Time so far/epoch: 0.512h
2024-05-01 17:04:47,034 - trainer - INFO - Train Epoch: 1 dl0 [44928/321526 (14%)] Loss: 1.965640; lr: 2.9965982161440128e-05; Time/iteration: 0.399m; Time so far/epoch: 0.519h
2024-05-01 17:05:10,711 - trainer - INFO - Train Epoch: 1 dl0 [45504/321526 (14%)] Loss: 2.000203; lr: 2.996506625643178e-05; Time/iteration: 0.395m; Time so far/epoch: 0.525h
2024-05-01 17:05:33,879 - trainer - INFO - Train Epoch: 1 dl0 [46080/321526 (14%)] Loss: 2.003759; lr: 2.9964138199156152e-05; Time/iteration: 0.386m; Time so far/epoch: 0.532h
2024-05-01 17:05:56,879 - trainer - INFO - Train Epoch: 1 dl0 [46656/321526 (15%)] Loss: 2.147015; lr: 2.99631979903745e-05; Time/iteration: 0.383m; Time so far/epoch: 0.538h
2024-05-01 17:06:20,958 - trainer - INFO - Train Epoch: 1 dl0 [47232/321526 (15%)] Loss: 2.118576; lr: 2.9962245630858042e-05; Time/iteration: 0.401m; Time so far/epoch: 0.545h
2024-05-01 17:06:44,599 - trainer - INFO - Train Epoch: 1 dl0 [47808/321526 (15%)] Loss: 1.987997; lr: 2.996128112138796e-05; Time/iteration: 0.394m; Time so far/epoch: 0.551h
2024-05-01 17:07:07,610 - trainer - INFO - Train Epoch: 1 dl0 [48384/321526 (15%)] Loss: 1.976871; lr: 2.9960304462755413e-05; Time/iteration: 0.384m; Time so far/epoch: 0.558h
2024-05-01 17:07:30,776 - trainer - INFO - Train Epoch: 1 dl0 [48960/321526 (15%)] Loss: 2.142905; lr: 2.995931565576152e-05; Time/iteration: 0.386m; Time so far/epoch: 0.564h
2024-05-01 17:07:53,707 - trainer - INFO - Train Epoch: 1 dl0 [49536/321526 (15%)] Loss: 2.048022; lr: 2.995831470121736e-05; Time/iteration: 0.382m; Time so far/epoch: 0.571h
2024-05-01 17:08:16,409 - trainer - INFO - Train Epoch: 1 dl0 [50112/321526 (16%)] Loss: 2.095441; lr: 2.9957301599943978e-05; Time/iteration: 0.378m; Time so far/epoch: 0.577h
2024-05-01 17:08:39,697 - trainer - INFO - Train Epoch: 1 dl0 [50688/321526 (16%)] Loss: 2.162298; lr: 2.995627635277239e-05; Time/iteration: 0.388m; Time so far/epoch: 0.583h
2024-05-01 17:09:02,645 - trainer - INFO - Train Epoch: 1 dl0 [51264/321526 (16%)] Loss: 1.936831; lr: 2.995523896054357e-05; Time/iteration: 0.382m; Time so far/epoch: 0.590h
2024-05-01 17:09:27,044 - trainer - INFO - Train Epoch: 1 dl0 [51840/321526 (16%)] Loss: 1.947006; lr: 2.9954189424108447e-05; Time/iteration: 0.407m; Time so far/epoch: 0.597h
2024-05-01 17:09:49,790 - trainer - INFO - Train Epoch: 1 dl0 [52416/321526 (16%)] Loss: 1.769858; lr: 2.995312774432792e-05; Time/iteration: 0.379m; Time so far/epoch: 0.603h
2024-05-01 17:10:12,067 - trainer - INFO - Train Epoch: 1 dl0 [52992/321526 (16%)] Loss: 2.001975; lr: 2.995205392207285e-05; Time/iteration: 0.371m; Time so far/epoch: 0.609h
2024-05-01 17:10:34,840 - trainer - INFO - Train Epoch: 1 dl0 [53568/321526 (17%)] Loss: 2.022284; lr: 2.9950967958224055e-05; Time/iteration: 0.380m; Time so far/epoch: 0.615h
2024-05-01 17:10:57,473 - trainer - INFO - Train Epoch: 1 dl0 [54144/321526 (17%)] Loss: 2.033159; lr: 2.9949869853672308e-05; Time/iteration: 0.377m; Time so far/epoch: 0.622h
2024-05-01 17:11:20,937 - trainer - INFO - Train Epoch: 1 dl0 [54720/321526 (17%)] Loss: 2.079297; lr: 2.994875960931835e-05; Time/iteration: 0.391m; Time so far/epoch: 0.628h
2024-05-01 17:11:43,790 - trainer - INFO - Train Epoch: 1 dl0 [55296/321526 (17%)] Loss: 2.070508; lr: 2.994763722607287e-05; Time/iteration: 0.381m; Time so far/epoch: 0.634h
2024-05-01 17:12:06,581 - trainer - INFO - Train Epoch: 1 dl0 [55872/321526 (17%)] Loss: 2.017697; lr: 2.9946502704856516e-05; Time/iteration: 0.380m; Time so far/epoch: 0.641h
2024-05-01 17:12:29,775 - trainer - INFO - Train Epoch: 1 dl0 [56448/321526 (18%)] Loss: 1.983782; lr: 2.9945356046599906e-05; Time/iteration: 0.387m; Time so far/epoch: 0.647h
2024-05-01 17:12:52,235 - trainer - INFO - Train Epoch: 1 dl0 [57024/321526 (18%)] Loss: 2.115628; lr: 2.99441972522436e-05; Time/iteration: 0.374m; Time so far/epoch: 0.654h
2024-05-01 17:13:16,469 - trainer - INFO - Train Epoch: 1 dl0 [57600/321526 (18%)] Loss: 1.879905; lr: 2.9943026322738105e-05; Time/iteration: 0.404m; Time so far/epoch: 0.660h
2024-05-01 17:13:39,801 - trainer - INFO - Train Epoch: 1 dl0 [58176/321526 (18%)] Loss: 1.987865; lr: 2.99418432590439e-05; Time/iteration: 0.389m; Time so far/epoch: 0.667h
2024-05-01 17:14:03,483 - trainer - INFO - Train Epoch: 1 dl0 [58752/321526 (18%)] Loss: 2.022922; lr: 2.994064806213141e-05; Time/iteration: 0.395m; Time so far/epoch: 0.673h
2024-05-01 17:14:25,989 - trainer - INFO - Train Epoch: 1 dl0 [59328/321526 (18%)] Loss: 1.934929; lr: 2.993944073298101e-05; Time/iteration: 0.375m; Time so far/epoch: 0.680h
2024-05-01 17:14:49,827 - trainer - INFO - Train Epoch: 1 dl0 [59904/321526 (19%)] Loss: 1.870133; lr: 2.993822127258303e-05; Time/iteration: 0.397m; Time so far/epoch: 0.686h
2024-05-01 17:15:13,732 - trainer - INFO - Train Epoch: 1 dl0 [60480/321526 (19%)] Loss: 1.952827; lr: 2.9936989681937754e-05; Time/iteration: 0.398m; Time so far/epoch: 0.693h
2024-05-01 17:15:36,890 - trainer - INFO - Train Epoch: 1 dl0 [61056/321526 (19%)] Loss: 1.921397; lr: 2.9935745962055402e-05; Time/iteration: 0.386m; Time so far/epoch: 0.699h
2024-05-01 17:16:00,634 - trainer - INFO - Train Epoch: 1 dl0 [61632/321526 (19%)] Loss: 1.966049; lr: 2.993449011395616e-05; Time/iteration: 0.396m; Time so far/epoch: 0.706h
2024-05-01 17:16:23,112 - trainer - INFO - Train Epoch: 1 dl0 [62208/321526 (19%)] Loss: 1.913762; lr: 2.993322213867015e-05; Time/iteration: 0.375m; Time so far/epoch: 0.712h
2024-05-01 17:16:46,438 - trainer - INFO - Train Epoch: 1 dl0 [62784/321526 (20%)] Loss: 1.923698; lr: 2.9931942037237454e-05; Time/iteration: 0.389m; Time so far/epoch: 0.719h
2024-05-01 17:17:09,560 - trainer - INFO - Train Epoch: 1 dl0 [63360/321526 (20%)] Loss: 1.920144; lr: 2.9930649810708087e-05; Time/iteration: 0.385m; Time so far/epoch: 0.725h
2024-05-01 17:17:33,489 - trainer - INFO - Train Epoch: 1 dl0 [63936/321526 (20%)] Loss: 1.968145; lr: 2.9929345460142014e-05; Time/iteration: 0.399m; Time so far/epoch: 0.732h
2024-05-01 17:17:56,843 - trainer - INFO - Train Epoch: 1 dl0 [64512/321526 (20%)] Loss: 1.999652; lr: 2.9928028986609156e-05; Time/iteration: 0.389m; Time so far/epoch: 0.738h
2024-05-01 17:18:19,281 - trainer - INFO - Train Epoch: 1 dl0 [65088/321526 (20%)] Loss: 2.004783; lr: 2.9926700391189366e-05; Time/iteration: 0.374m; Time so far/epoch: 0.744h
2024-05-01 17:18:42,367 - trainer - INFO - Train Epoch: 1 dl0 [65664/321526 (20%)] Loss: 1.882456; lr: 2.9925359674972435e-05; Time/iteration: 0.385m; Time so far/epoch: 0.751h
2024-05-01 17:19:05,418 - trainer - INFO - Train Epoch: 1 dl0 [66240/321526 (21%)] Loss: 1.967490; lr: 2.9924006839058115e-05; Time/iteration: 0.384m; Time so far/epoch: 0.757h
2024-05-01 17:19:29,439 - trainer - INFO - Train Epoch: 1 dl0 [66816/321526 (21%)] Loss: 2.094191; lr: 2.992264188455608e-05; Time/iteration: 0.400m; Time so far/epoch: 0.764h
2024-05-01 17:19:52,753 - trainer - INFO - Train Epoch: 1 dl0 [67392/321526 (21%)] Loss: 1.939766; lr: 2.992126481258596e-05; Time/iteration: 0.389m; Time so far/epoch: 0.770h
2024-05-01 17:20:15,656 - trainer - INFO - Train Epoch: 1 dl0 [67968/321526 (21%)] Loss: 2.043877; lr: 2.9919875624277315e-05; Time/iteration: 0.382m; Time so far/epoch: 0.777h
2024-05-01 17:20:39,499 - trainer - INFO - Train Epoch: 1 dl0 [68544/321526 (21%)] Loss: 1.917077; lr: 2.9918474320769646e-05; Time/iteration: 0.397m; Time so far/epoch: 0.783h
2024-05-01 17:21:02,591 - trainer - INFO - Train Epoch: 1 dl0 [69120/321526 (21%)] Loss: 2.030871; lr: 2.9917060903212393e-05; Time/iteration: 0.385m; Time so far/epoch: 0.790h
2024-05-01 17:21:26,949 - trainer - INFO - Train Epoch: 1 dl0 [69696/321526 (22%)] Loss: 1.987768; lr: 2.991563537276493e-05; Time/iteration: 0.406m; Time so far/epoch: 0.796h
2024-05-01 17:21:50,012 - trainer - INFO - Train Epoch: 1 dl0 [70272/321526 (22%)] Loss: 1.940312; lr: 2.991419773059657e-05; Time/iteration: 0.384m; Time so far/epoch: 0.803h
2024-05-01 17:22:13,033 - trainer - INFO - Train Epoch: 1 dl0 [70848/321526 (22%)] Loss: 1.965414; lr: 2.9912747977886562e-05; Time/iteration: 0.384m; Time so far/epoch: 0.809h
2024-05-01 17:22:36,208 - trainer - INFO - Train Epoch: 1 dl0 [71424/321526 (22%)] Loss: 2.056017; lr: 2.991128611582408e-05; Time/iteration: 0.386m; Time so far/epoch: 0.816h
2024-05-01 17:22:58,866 - trainer - INFO - Train Epoch: 1 dl0 [72000/321526 (22%)] Loss: 2.017383; lr: 2.9909812145608242e-05; Time/iteration: 0.378m; Time so far/epoch: 0.822h
2024-05-01 17:23:23,541 - trainer - INFO - Train Epoch: 1 dl0 [72576/321526 (23%)] Loss: 1.955835; lr: 2.990832606844809e-05; Time/iteration: 0.411m; Time so far/epoch: 0.829h
2024-05-01 17:23:46,832 - trainer - INFO - Train Epoch: 1 dl0 [73152/321526 (23%)] Loss: 1.938378; lr: 2.99068278855626e-05; Time/iteration: 0.388m; Time so far/epoch: 0.835h
2024-05-01 17:24:10,127 - trainer - INFO - Train Epoch: 1 dl0 [73728/321526 (23%)] Loss: 2.003268; lr: 2.990531759818068e-05; Time/iteration: 0.388m; Time so far/epoch: 0.842h
2024-05-01 17:24:32,870 - trainer - INFO - Train Epoch: 1 dl0 [74304/321526 (23%)] Loss: 1.846305; lr: 2.990379520754116e-05; Time/iteration: 0.379m; Time so far/epoch: 0.848h
2024-05-01 17:24:55,854 - trainer - INFO - Train Epoch: 1 dl0 [74880/321526 (23%)] Loss: 2.018964; lr: 2.990226071489281e-05; Time/iteration: 0.383m; Time so far/epoch: 0.855h
2024-05-01 17:25:19,988 - trainer - INFO - Train Epoch: 1 dl0 [75456/321526 (23%)] Loss: 2.020515; lr: 2.990071412149431e-05; Time/iteration: 0.402m; Time so far/epoch: 0.861h
2024-05-01 17:25:43,284 - trainer - INFO - Train Epoch: 1 dl0 [76032/321526 (24%)] Loss: 1.934965; lr: 2.989915542861428e-05; Time/iteration: 0.388m; Time so far/epoch: 0.868h
2024-05-01 17:26:06,890 - trainer - INFO - Train Epoch: 1 dl0 [76608/321526 (24%)] Loss: 2.051579; lr: 2.9897584637531267e-05; Time/iteration: 0.393m; Time so far/epoch: 0.874h
2024-05-01 17:26:29,264 - trainer - INFO - Train Epoch: 1 dl0 [77184/321526 (24%)] Loss: 1.992151; lr: 2.9896001749533718e-05; Time/iteration: 0.373m; Time so far/epoch: 0.880h
2024-05-01 17:26:52,563 - trainer - INFO - Train Epoch: 1 dl0 [77760/321526 (24%)] Loss: 1.853716; lr: 2.989440676592003e-05; Time/iteration: 0.388m; Time so far/epoch: 0.887h
2024-05-01 17:27:15,926 - trainer - INFO - Train Epoch: 1 dl0 [78336/321526 (24%)] Loss: 1.976405; lr: 2.9892799687998514e-05; Time/iteration: 0.389m; Time so far/epoch: 0.893h
2024-05-01 17:27:39,825 - trainer - INFO - Train Epoch: 1 dl0 [78912/321526 (25%)] Loss: 2.019403; lr: 2.9891180517087388e-05; Time/iteration: 0.398m; Time so far/epoch: 0.900h
2024-05-01 17:28:03,594 - trainer - INFO - Train Epoch: 1 dl0 [79488/321526 (25%)] Loss: 2.052941; lr: 2.988954925451481e-05; Time/iteration: 0.396m; Time so far/epoch: 0.907h
2024-05-01 17:28:26,095 - trainer - INFO - Train Epoch: 1 dl0 [80064/321526 (25%)] Loss: 1.991880; lr: 2.988790590161884e-05; Time/iteration: 0.375m; Time so far/epoch: 0.913h
2024-05-01 17:28:49,750 - trainer - INFO - Train Epoch: 1 dl0 [80640/321526 (25%)] Loss: 1.992357; lr: 2.988625045974746e-05; Time/iteration: 0.394m; Time so far/epoch: 0.919h
2024-05-01 17:29:12,851 - trainer - INFO - Train Epoch: 1 dl0 [81216/321526 (25%)] Loss: 2.031211; lr: 2.9884582930258575e-05; Time/iteration: 0.385m; Time so far/epoch: 0.926h
2024-05-01 17:29:36,587 - trainer - INFO - Train Epoch: 1 dl0 [81792/321526 (25%)] Loss: 2.027754; lr: 2.988290331452e-05; Time/iteration: 0.396m; Time so far/epoch: 0.932h
2024-05-01 17:30:00,528 - trainer - INFO - Train Epoch: 1 dl0 [82368/321526 (26%)] Loss: 1.925464; lr: 2.988121161390945e-05; Time/iteration: 0.399m; Time so far/epoch: 0.939h
2024-05-01 17:30:23,119 - trainer - INFO - Train Epoch: 1 dl0 [82944/321526 (26%)] Loss: 2.024609; lr: 2.987950782981459e-05; Time/iteration: 0.377m; Time so far/epoch: 0.945h
2024-05-01 17:30:46,101 - trainer - INFO - Train Epoch: 1 dl0 [83520/321526 (26%)] Loss: 2.048580; lr: 2.987779196363295e-05; Time/iteration: 0.383m; Time so far/epoch: 0.952h
2024-05-01 17:31:09,173 - trainer - INFO - Train Epoch: 1 dl0 [84096/321526 (26%)] Loss: 1.829014; lr: 2.987606401677201e-05; Time/iteration: 0.385m; Time so far/epoch: 0.958h
2024-05-01 17:31:33,576 - trainer - INFO - Train Epoch: 1 dl0 [84672/321526 (26%)] Loss: 2.044286; lr: 2.987432399064913e-05; Time/iteration: 0.407m; Time so far/epoch: 0.965h
2024-05-01 17:31:56,894 - trainer - INFO - Train Epoch: 1 dl0 [85248/321526 (27%)] Loss: 1.926843; lr: 2.9872571886691602e-05; Time/iteration: 0.389m; Time so far/epoch: 0.971h
2024-05-01 17:32:19,624 - trainer - INFO - Train Epoch: 1 dl0 [85824/321526 (27%)] Loss: 1.950337; lr: 2.987080770633661e-05; Time/iteration: 0.379m; Time so far/epoch: 0.978h
2024-05-01 17:32:42,620 - trainer - INFO - Train Epoch: 1 dl0 [86400/321526 (27%)] Loss: 2.019908; lr: 2.9869031451031244e-05; Time/iteration: 0.383m; Time so far/epoch: 0.984h
2024-05-01 17:33:05,328 - trainer - INFO - Train Epoch: 1 dl0 [86976/321526 (27%)] Loss: 1.989125; lr: 2.9867243122232504e-05; Time/iteration: 0.378m; Time so far/epoch: 0.990h
2024-05-01 17:33:29,472 - trainer - INFO - Train Epoch: 1 dl0 [87552/321526 (27%)] Loss: 2.218600; lr: 2.98654427214073e-05; Time/iteration: 0.402m; Time so far/epoch: 0.997h
2024-05-01 17:33:52,655 - trainer - INFO - Train Epoch: 1 dl0 [88128/321526 (27%)] Loss: 1.845827; lr: 2.9863630250032425e-05; Time/iteration: 0.386m; Time so far/epoch: 1.004h
2024-05-01 17:34:16,244 - trainer - INFO - Train Epoch: 1 dl0 [88704/321526 (28%)] Loss: 2.107342; lr: 2.9861805709594587e-05; Time/iteration: 0.393m; Time so far/epoch: 1.010h
2024-05-01 17:34:39,221 - trainer - INFO - Train Epoch: 1 dl0 [89280/321526 (28%)] Loss: 1.943988; lr: 2.9859969101590398e-05; Time/iteration: 0.383m; Time so far/epoch: 1.017h
2024-05-01 17:35:02,108 - trainer - INFO - Train Epoch: 1 dl0 [89856/321526 (28%)] Loss: 1.945815; lr: 2.9858120427526354e-05; Time/iteration: 0.381m; Time so far/epoch: 1.023h
2024-05-01 17:35:26,597 - trainer - INFO - Train Epoch: 1 dl0 [90432/321526 (28%)] Loss: 1.924019; lr: 2.9856259688918857e-05; Time/iteration: 0.408m; Time so far/epoch: 1.030h
2024-05-01 17:35:49,871 - trainer - INFO - Train Epoch: 1 dl0 [91008/321526 (28%)] Loss: 2.028472; lr: 2.9854386887294207e-05; Time/iteration: 0.388m; Time so far/epoch: 1.036h
2024-05-01 17:36:13,759 - trainer - INFO - Train Epoch: 1 dl0 [91584/321526 (28%)] Loss: 1.813762; lr: 2.9852502024188596e-05; Time/iteration: 0.398m; Time so far/epoch: 1.043h
2024-05-01 17:36:36,485 - trainer - INFO - Train Epoch: 1 dl0 [92160/321526 (29%)] Loss: 1.965188; lr: 2.985060510114811e-05; Time/iteration: 0.379m; Time so far/epoch: 1.049h
2024-05-01 17:36:59,974 - trainer - INFO - Train Epoch: 1 dl0 [92736/321526 (29%)] Loss: 2.085841; lr: 2.9848696119728717e-05; Time/iteration: 0.391m; Time so far/epoch: 1.056h
2024-05-01 17:37:24,257 - trainer - INFO - Train Epoch: 1 dl0 [93312/321526 (29%)] Loss: 2.157743; lr: 2.9846775081496298e-05; Time/iteration: 0.405m; Time so far/epoch: 1.062h
2024-05-01 17:37:48,000 - trainer - INFO - Train Epoch: 1 dl0 [93888/321526 (29%)] Loss: 1.932861; lr: 2.9844841988026614e-05; Time/iteration: 0.396m; Time so far/epoch: 1.069h
2024-05-01 17:38:12,214 - trainer - INFO - Train Epoch: 1 dl0 [94464/321526 (29%)] Loss: 1.925239; lr: 2.98428968409053e-05; Time/iteration: 0.404m; Time so far/epoch: 1.076h
2024-05-01 17:38:34,984 - trainer - INFO - Train Epoch: 1 dl0 [95040/321526 (30%)] Loss: 1.938978; lr: 2.9840939641727896e-05; Time/iteration: 0.379m; Time so far/epoch: 1.082h
2024-05-01 17:38:58,417 - trainer - INFO - Train Epoch: 1 dl0 [95616/321526 (30%)] Loss: 1.888917; lr: 2.9838970392099826e-05; Time/iteration: 0.391m; Time so far/epoch: 1.089h
2024-05-01 17:39:21,709 - trainer - INFO - Train Epoch: 1 dl0 [96192/321526 (30%)] Loss: 1.951486; lr: 2.9836989093636388e-05; Time/iteration: 0.388m; Time so far/epoch: 1.095h
2024-05-01 17:39:45,465 - trainer - INFO - Train Epoch: 1 dl0 [96768/321526 (30%)] Loss: 1.931468; lr: 2.9834995747962775e-05; Time/iteration: 0.396m; Time so far/epoch: 1.102h
2024-05-01 17:40:09,789 - trainer - INFO - Train Epoch: 1 dl0 [97344/321526 (30%)] Loss: 1.863101; lr: 2.9832990356714058e-05; Time/iteration: 0.405m; Time so far/epoch: 1.108h
2024-05-01 17:40:32,404 - trainer - INFO - Train Epoch: 1 dl0 [97920/321526 (30%)] Loss: 1.956083; lr: 2.9830972921535183e-05; Time/iteration: 0.377m; Time so far/epoch: 1.115h
2024-05-01 17:40:55,577 - trainer - INFO - Train Epoch: 1 dl0 [98496/321526 (31%)] Loss: 2.017422; lr: 2.9828943444080983e-05; Time/iteration: 0.386m; Time so far/epoch: 1.121h
2024-05-01 17:41:18,700 - trainer - INFO - Train Epoch: 1 dl0 [99072/321526 (31%)] Loss: 1.919905; lr: 2.982690192601616e-05; Time/iteration: 0.385m; Time so far/epoch: 1.128h
2024-05-01 17:41:42,631 - trainer - INFO - Train Epoch: 1 dl0 [99648/321526 (31%)] Loss: 1.937015; lr: 2.9824848369015305e-05; Time/iteration: 0.399m; Time so far/epoch: 1.134h
2024-05-01 17:45:15,051 - trainer - INFO - EgoClip_HOI epoch 1, Verb-Neg, Acc: 55.0;    EgoClip_HOI epoch 1, Noun-Neg, Acc: 69.0;    EgoClip_HOI epoch 1, HOI-Neg, Acc: 40.4;    
2024-05-01 17:45:15,060 - trainer - INFO -     epoch          : 1
2024-05-01 17:45:15,062 - trainer - INFO -     loss_0         : 0.6288539725357889
2024-05-01 17:45:15,062 - trainer - INFO -     val_loss_0     : 0.0
2024-05-01 17:45:15,062 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 54.97706985473633
2024-05-01 17:45:15,062 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 68.97761535644531
2024-05-01 17:45:15,062 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 40.43363952636719
2024-05-01 17:45:15,982 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch1.pth ...
2024-05-01 17:45:17,972 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-01 17:46:34,353 - trainer - INFO - Train Epoch: 2 dl0 [0/321526 (0%)] Loss: 2.009427; lr: 2.9823817076439876e-05; Time/iteration: 1.273m; Time so far/epoch: 0.021h
2024-05-01 17:46:59,626 - trainer - INFO - Train Epoch: 2 dl0 [576/321526 (0%)] Loss: 2.000241; lr: 2.9821745464196413e-05; Time/iteration: 0.421m; Time so far/epoch: 0.028h
2024-05-01 17:47:28,776 - trainer - INFO - Train Epoch: 2 dl0 [1152/321526 (0%)] Loss: 1.929335; lr: 2.981966181724658e-05; Time/iteration: 0.486m; Time so far/epoch: 0.036h
2024-05-01 17:47:55,045 - trainer - INFO - Train Epoch: 2 dl0 [1728/321526 (1%)] Loss: 1.875404; lr: 2.9817566137299512e-05; Time/iteration: 0.438m; Time so far/epoch: 0.044h
2024-05-01 17:48:21,391 - trainer - INFO - Train Epoch: 2 dl0 [2304/321526 (1%)] Loss: 2.038754; lr: 2.9815458426074223e-05; Time/iteration: 0.439m; Time so far/epoch: 0.051h
2024-05-01 17:48:54,157 - trainer - INFO - Train Epoch: 2 dl0 [2880/321526 (1%)] Loss: 1.865998; lr: 2.9813338685299587e-05; Time/iteration: 0.546m; Time so far/epoch: 0.060h
2024-05-01 17:49:19,634 - trainer - INFO - Train Epoch: 2 dl0 [3456/321526 (1%)] Loss: 2.023197; lr: 2.981120691671436e-05; Time/iteration: 0.425m; Time so far/epoch: 0.067h
2024-05-01 17:49:45,679 - trainer - INFO - Train Epoch: 2 dl0 [4032/321526 (1%)] Loss: 1.952366; lr: 2.9809063122067152e-05; Time/iteration: 0.434m; Time so far/epoch: 0.074h
2024-05-01 17:50:11,282 - trainer - INFO - Train Epoch: 2 dl0 [4608/321526 (1%)] Loss: 2.058854; lr: 2.9806907303116436e-05; Time/iteration: 0.427m; Time so far/epoch: 0.081h
2024-05-01 17:50:37,734 - trainer - INFO - Train Epoch: 2 dl0 [5184/321526 (2%)] Loss: 1.899972; lr: 2.980473946163056e-05; Time/iteration: 0.441m; Time so far/epoch: 0.089h
2024-05-01 17:51:02,913 - trainer - INFO - Train Epoch: 2 dl0 [5760/321526 (2%)] Loss: 1.898718; lr: 2.9802559599387723e-05; Time/iteration: 0.420m; Time so far/epoch: 0.096h
2024-05-01 17:51:28,380 - trainer - INFO - Train Epoch: 2 dl0 [6336/321526 (2%)] Loss: 2.046895; lr: 2.9800367718175987e-05; Time/iteration: 0.424m; Time so far/epoch: 0.103h
2024-05-01 17:51:52,961 - trainer - INFO - Train Epoch: 2 dl0 [6912/321526 (2%)] Loss: 2.084843; lr: 2.979816381979328e-05; Time/iteration: 0.409m; Time so far/epoch: 0.110h
2024-05-01 17:52:17,470 - trainer - INFO - Train Epoch: 2 dl0 [7488/321526 (2%)] Loss: 2.088357; lr: 2.979594790604737e-05; Time/iteration: 0.408m; Time so far/epoch: 0.117h
2024-05-01 17:52:42,663 - trainer - INFO - Train Epoch: 2 dl0 [8064/321526 (3%)] Loss: 1.956262; lr: 2.97937199787559e-05; Time/iteration: 0.420m; Time so far/epoch: 0.124h
2024-05-01 17:53:06,612 - trainer - INFO - Train Epoch: 2 dl0 [8640/321526 (3%)] Loss: 1.977353; lr: 2.9791480039746357e-05; Time/iteration: 0.399m; Time so far/epoch: 0.130h
2024-05-01 17:53:30,412 - trainer - INFO - Train Epoch: 2 dl0 [9216/321526 (3%)] Loss: 2.011042; lr: 2.9789228090856077e-05; Time/iteration: 0.397m; Time so far/epoch: 0.137h
2024-05-01 17:53:53,818 - trainer - INFO - Train Epoch: 2 dl0 [9792/321526 (3%)] Loss: 1.969741; lr: 2.9786964133932263e-05; Time/iteration: 0.390m; Time so far/epoch: 0.143h
2024-05-01 17:54:18,611 - trainer - INFO - Train Epoch: 2 dl0 [10368/321526 (3%)] Loss: 1.910241; lr: 2.9784688170831946e-05; Time/iteration: 0.413m; Time so far/epoch: 0.150h
2024-05-01 17:54:43,371 - trainer - INFO - Train Epoch: 2 dl0 [10944/321526 (3%)] Loss: 2.020074; lr: 2.9782400203422025e-05; Time/iteration: 0.413m; Time so far/epoch: 0.157h
2024-05-01 17:55:07,152 - trainer - INFO - Train Epoch: 2 dl0 [11520/321526 (4%)] Loss: 1.992539; lr: 2.978010023357924e-05; Time/iteration: 0.396m; Time so far/epoch: 0.164h
2024-05-01 17:55:30,383 - trainer - INFO - Train Epoch: 2 dl0 [12096/321526 (4%)] Loss: 1.931318; lr: 2.9777788263190167e-05; Time/iteration: 0.387m; Time so far/epoch: 0.170h
2024-05-01 17:55:53,803 - trainer - INFO - Train Epoch: 2 dl0 [12672/321526 (4%)] Loss: 1.987062; lr: 2.977546429415123e-05; Time/iteration: 0.390m; Time so far/epoch: 0.177h
2024-05-01 17:56:18,157 - trainer - INFO - Train Epoch: 2 dl0 [13248/321526 (4%)] Loss: 1.884490; lr: 2.9773128328368705e-05; Time/iteration: 0.406m; Time so far/epoch: 0.183h
2024-05-01 17:56:42,411 - trainer - INFO - Train Epoch: 2 dl0 [13824/321526 (4%)] Loss: 1.978594; lr: 2.9770780367758702e-05; Time/iteration: 0.404m; Time so far/epoch: 0.190h
2024-05-01 17:57:06,392 - trainer - INFO - Train Epoch: 2 dl0 [14400/321526 (4%)] Loss: 1.944976; lr: 2.976842041424716e-05; Time/iteration: 0.400m; Time so far/epoch: 0.197h
2024-05-01 17:57:30,202 - trainer - INFO - Train Epoch: 2 dl0 [14976/321526 (5%)] Loss: 2.003587; lr: 2.976604846976987e-05; Time/iteration: 0.397m; Time so far/epoch: 0.203h
2024-05-01 17:57:54,163 - trainer - INFO - Train Epoch: 2 dl0 [15552/321526 (5%)] Loss: 1.988749; lr: 2.9763664536272452e-05; Time/iteration: 0.399m; Time so far/epoch: 0.210h
2024-05-01 17:58:18,317 - trainer - INFO - Train Epoch: 2 dl0 [16128/321526 (5%)] Loss: 2.070009; lr: 2.9761268615710365e-05; Time/iteration: 0.402m; Time so far/epoch: 0.217h
2024-05-01 17:58:42,299 - trainer - INFO - Train Epoch: 2 dl0 [16704/321526 (5%)] Loss: 2.012759; lr: 2.9758860710048886e-05; Time/iteration: 0.400m; Time so far/epoch: 0.223h
2024-05-01 17:59:06,392 - trainer - INFO - Train Epoch: 2 dl0 [17280/321526 (5%)] Loss: 1.980843; lr: 2.9756440821263143e-05; Time/iteration: 0.402m; Time so far/epoch: 0.230h
2024-05-01 17:59:30,194 - trainer - INFO - Train Epoch: 2 dl0 [17856/321526 (6%)] Loss: 2.132415; lr: 2.9754008951338084e-05; Time/iteration: 0.397m; Time so far/epoch: 0.237h
2024-05-01 17:59:54,391 - trainer - INFO - Train Epoch: 2 dl0 [18432/321526 (6%)] Loss: 1.891981; lr: 2.9751565102268477e-05; Time/iteration: 0.403m; Time so far/epoch: 0.243h
2024-05-01 18:00:18,588 - trainer - INFO - Train Epoch: 2 dl0 [19008/321526 (6%)] Loss: 2.131886; lr: 2.974910927605893e-05; Time/iteration: 0.403m; Time so far/epoch: 0.250h
2024-05-01 18:00:43,066 - trainer - INFO - Train Epoch: 2 dl0 [19584/321526 (6%)] Loss: 2.052433; lr: 2.9746641474723874e-05; Time/iteration: 0.408m; Time so far/epoch: 0.257h
2024-05-01 18:01:07,694 - trainer - INFO - Train Epoch: 2 dl0 [20160/321526 (6%)] Loss: 1.981239; lr: 2.9744161700287544e-05; Time/iteration: 0.410m; Time so far/epoch: 0.264h
2024-05-01 18:01:31,365 - trainer - INFO - Train Epoch: 2 dl0 [20736/321526 (6%)] Loss: 1.863706; lr: 2.974166995478402e-05; Time/iteration: 0.395m; Time so far/epoch: 0.270h
2024-05-01 18:01:54,863 - trainer - INFO - Train Epoch: 2 dl0 [21312/321526 (7%)] Loss: 1.952164; lr: 2.973916624025719e-05; Time/iteration: 0.392m; Time so far/epoch: 0.277h
2024-05-01 18:02:18,385 - trainer - INFO - Train Epoch: 2 dl0 [21888/321526 (7%)] Loss: 2.026145; lr: 2.973665055876076e-05; Time/iteration: 0.392m; Time so far/epoch: 0.283h
2024-05-01 18:02:42,693 - trainer - INFO - Train Epoch: 2 dl0 [22464/321526 (7%)] Loss: 2.024772; lr: 2.9734122912358257e-05; Time/iteration: 0.405m; Time so far/epoch: 0.290h
2024-05-01 18:03:07,295 - trainer - INFO - Train Epoch: 2 dl0 [23040/321526 (7%)] Loss: 1.940398; lr: 2.973158330312301e-05; Time/iteration: 0.410m; Time so far/epoch: 0.297h
2024-05-01 18:03:30,625 - trainer - INFO - Train Epoch: 2 dl0 [23616/321526 (7%)] Loss: 1.978122; lr: 2.9729031733138174e-05; Time/iteration: 0.389m; Time so far/epoch: 0.304h
2024-05-01 18:03:54,423 - trainer - INFO - Train Epoch: 2 dl0 [24192/321526 (8%)] Loss: 1.919444; lr: 2.972646820449671e-05; Time/iteration: 0.397m; Time so far/epoch: 0.310h
2024-05-01 18:04:17,948 - trainer - INFO - Train Epoch: 2 dl0 [24768/321526 (8%)] Loss: 2.045272; lr: 2.9723892719301392e-05; Time/iteration: 0.392m; Time so far/epoch: 0.317h
2024-05-01 18:04:42,040 - trainer - INFO - Train Epoch: 2 dl0 [25344/321526 (8%)] Loss: 1.974783; lr: 2.9721305279664797e-05; Time/iteration: 0.402m; Time so far/epoch: 0.323h
2024-05-01 18:05:07,713 - trainer - INFO - Train Epoch: 2 dl0 [25920/321526 (8%)] Loss: 1.963417; lr: 2.9718705887709307e-05; Time/iteration: 0.428m; Time so far/epoch: 0.330h
2024-05-01 18:05:31,202 - trainer - INFO - Train Epoch: 2 dl0 [26496/321526 (8%)] Loss: 1.919841; lr: 2.971609454556711e-05; Time/iteration: 0.391m; Time so far/epoch: 0.337h
2024-05-01 18:05:54,685 - trainer - INFO - Train Epoch: 2 dl0 [27072/321526 (8%)] Loss: 1.820053; lr: 2.9713471255380193e-05; Time/iteration: 0.391m; Time so far/epoch: 0.344h
2024-05-01 18:06:17,899 - trainer - INFO - Train Epoch: 2 dl0 [27648/321526 (9%)] Loss: 1.890091; lr: 2.9710836019300356e-05; Time/iteration: 0.387m; Time so far/epoch: 0.350h
2024-05-01 18:06:42,429 - trainer - INFO - Train Epoch: 2 dl0 [28224/321526 (9%)] Loss: 2.047225; lr: 2.970818883948918e-05; Time/iteration: 0.409m; Time so far/epoch: 0.357h
2024-05-01 18:07:06,350 - trainer - INFO - Train Epoch: 2 dl0 [28800/321526 (9%)] Loss: 1.939027; lr: 2.9705529718118054e-05; Time/iteration: 0.399m; Time so far/epoch: 0.363h
2024-05-01 18:07:30,065 - trainer - INFO - Train Epoch: 2 dl0 [29376/321526 (9%)] Loss: 2.043496; lr: 2.970285865736816e-05; Time/iteration: 0.395m; Time so far/epoch: 0.370h
2024-05-01 18:07:53,718 - trainer - INFO - Train Epoch: 2 dl0 [29952/321526 (9%)] Loss: 1.909308; lr: 2.9700175659430476e-05; Time/iteration: 0.394m; Time so far/epoch: 0.377h
2024-05-01 18:08:16,988 - trainer - INFO - Train Epoch: 2 dl0 [30528/321526 (9%)] Loss: 2.043670; lr: 2.9697480726505766e-05; Time/iteration: 0.388m; Time so far/epoch: 0.383h
2024-05-01 18:08:41,147 - trainer - INFO - Train Epoch: 2 dl0 [31104/321526 (10%)] Loss: 1.957864; lr: 2.969477386080459e-05; Time/iteration: 0.403m; Time so far/epoch: 0.390h
2024-05-01 18:09:04,895 - trainer - INFO - Train Epoch: 2 dl0 [31680/321526 (10%)] Loss: 2.023994; lr: 2.969205506454729e-05; Time/iteration: 0.396m; Time so far/epoch: 0.396h
2024-05-01 18:09:29,041 - trainer - INFO - Train Epoch: 2 dl0 [32256/321526 (10%)] Loss: 1.839716; lr: 2.9689324339963988e-05; Time/iteration: 0.402m; Time so far/epoch: 0.403h
2024-05-01 18:09:52,757 - trainer - INFO - Train Epoch: 2 dl0 [32832/321526 (10%)] Loss: 2.003255; lr: 2.968658168929462e-05; Time/iteration: 0.395m; Time so far/epoch: 0.410h
2024-05-01 18:10:16,205 - trainer - INFO - Train Epoch: 2 dl0 [33408/321526 (10%)] Loss: 2.011102; lr: 2.9683827114788867e-05; Time/iteration: 0.391m; Time so far/epoch: 0.416h
2024-05-01 18:10:40,635 - trainer - INFO - Train Epoch: 2 dl0 [33984/321526 (11%)] Loss: 1.917056; lr: 2.9681060618706214e-05; Time/iteration: 0.407m; Time so far/epoch: 0.423h
2024-05-01 18:11:04,857 - trainer - INFO - Train Epoch: 2 dl0 [34560/321526 (11%)] Loss: 1.963833; lr: 2.9678282203315918e-05; Time/iteration: 0.404m; Time so far/epoch: 0.430h
2024-05-01 18:11:29,238 - trainer - INFO - Train Epoch: 2 dl0 [35136/321526 (11%)] Loss: 1.937811; lr: 2.9675491870897016e-05; Time/iteration: 0.406m; Time so far/epoch: 0.436h
2024-05-01 18:11:52,602 - trainer - INFO - Train Epoch: 2 dl0 [35712/321526 (11%)] Loss: 1.997098; lr: 2.967268962373831e-05; Time/iteration: 0.389m; Time so far/epoch: 0.443h
2024-05-01 18:12:16,236 - trainer - INFO - Train Epoch: 2 dl0 [36288/321526 (11%)] Loss: 2.017872; lr: 2.9669875464138392e-05; Time/iteration: 0.394m; Time so far/epoch: 0.450h
2024-05-01 18:12:39,850 - trainer - INFO - Train Epoch: 2 dl0 [36864/321526 (11%)] Loss: 1.946534; lr: 2.966704939440561e-05; Time/iteration: 0.394m; Time so far/epoch: 0.456h
2024-05-01 18:13:03,975 - trainer - INFO - Train Epoch: 2 dl0 [37440/321526 (12%)] Loss: 2.018240; lr: 2.9664211416858086e-05; Time/iteration: 0.402m; Time so far/epoch: 0.463h
2024-05-01 18:13:28,513 - trainer - INFO - Train Epoch: 2 dl0 [38016/321526 (12%)] Loss: 1.955948; lr: 2.966136153382372e-05; Time/iteration: 0.409m; Time so far/epoch: 0.470h
2024-05-01 18:13:51,807 - trainer - INFO - Train Epoch: 2 dl0 [38592/321526 (12%)] Loss: 2.070945; lr: 2.9658499747640158e-05; Time/iteration: 0.388m; Time so far/epoch: 0.476h
2024-05-01 18:14:15,724 - trainer - INFO - Train Epoch: 2 dl0 [39168/321526 (12%)] Loss: 1.970551; lr: 2.965562606065483e-05; Time/iteration: 0.399m; Time so far/epoch: 0.483h
2024-05-01 18:14:39,458 - trainer - INFO - Train Epoch: 2 dl0 [39744/321526 (12%)] Loss: 2.002871; lr: 2.9652740475224912e-05; Time/iteration: 0.396m; Time so far/epoch: 0.489h
2024-05-01 18:15:04,186 - trainer - INFO - Train Epoch: 2 dl0 [40320/321526 (13%)] Loss: 2.157151; lr: 2.964984299371735e-05; Time/iteration: 0.412m; Time so far/epoch: 0.496h
2024-05-01 18:15:28,571 - trainer - INFO - Train Epoch: 2 dl0 [40896/321526 (13%)] Loss: 1.904971; lr: 2.964693361850884e-05; Time/iteration: 0.406m; Time so far/epoch: 0.503h
2024-05-01 18:15:53,109 - trainer - INFO - Train Epoch: 2 dl0 [41472/321526 (13%)] Loss: 1.923428; lr: 2.9644012351985845e-05; Time/iteration: 0.409m; Time so far/epoch: 0.510h
2024-05-01 18:16:16,805 - trainer - INFO - Train Epoch: 2 dl0 [42048/321526 (13%)] Loss: 2.122125; lr: 2.9641079196544565e-05; Time/iteration: 0.395m; Time so far/epoch: 0.516h
2024-05-01 18:16:40,204 - trainer - INFO - Train Epoch: 2 dl0 [42624/321526 (13%)] Loss: 2.013139; lr: 2.963813415459097e-05; Time/iteration: 0.390m; Time so far/epoch: 0.523h
2024-05-01 18:17:04,197 - trainer - INFO - Train Epoch: 2 dl0 [43200/321526 (13%)] Loss: 2.090044; lr: 2.963517722854077e-05; Time/iteration: 0.400m; Time so far/epoch: 0.530h
2024-05-01 18:17:28,987 - trainer - INFO - Train Epoch: 2 dl0 [43776/321526 (14%)] Loss: 2.048224; lr: 2.963220842081943e-05; Time/iteration: 0.413m; Time so far/epoch: 0.536h
2024-05-01 18:17:53,608 - trainer - INFO - Train Epoch: 2 dl0 [44352/321526 (14%)] Loss: 1.943757; lr: 2.9629227733862144e-05; Time/iteration: 0.410m; Time so far/epoch: 0.543h
2024-05-01 18:18:18,191 - trainer - INFO - Train Epoch: 2 dl0 [44928/321526 (14%)] Loss: 2.103980; lr: 2.9626235170113876e-05; Time/iteration: 0.410m; Time so far/epoch: 0.550h
2024-05-01 18:18:41,592 - trainer - INFO - Train Epoch: 2 dl0 [45504/321526 (14%)] Loss: 2.020452; lr: 2.9623230732029312e-05; Time/iteration: 0.390m; Time so far/epoch: 0.557h
2024-05-01 18:19:05,581 - trainer - INFO - Train Epoch: 2 dl0 [46080/321526 (14%)] Loss: 1.863042; lr: 2.9620214422072882e-05; Time/iteration: 0.400m; Time so far/epoch: 0.563h
2024-05-01 18:19:29,396 - trainer - INFO - Train Epoch: 2 dl0 [46656/321526 (15%)] Loss: 1.985739; lr: 2.9617186242718765e-05; Time/iteration: 0.397m; Time so far/epoch: 0.570h
2024-05-01 18:19:54,177 - trainer - INFO - Train Epoch: 2 dl0 [47232/321526 (15%)] Loss: 1.927621; lr: 2.9614146196450858e-05; Time/iteration: 0.413m; Time so far/epoch: 0.577h
2024-05-01 18:20:18,606 - trainer - INFO - Train Epoch: 2 dl0 [47808/321526 (15%)] Loss: 1.928165; lr: 2.9611094285762816e-05; Time/iteration: 0.407m; Time so far/epoch: 0.584h
2024-05-01 18:20:42,643 - trainer - INFO - Train Epoch: 2 dl0 [48384/321526 (15%)] Loss: 1.862952; lr: 2.9608030513157998e-05; Time/iteration: 0.401m; Time so far/epoch: 0.590h
2024-05-01 18:21:06,701 - trainer - INFO - Train Epoch: 2 dl0 [48960/321526 (15%)] Loss: 1.846866; lr: 2.9604954881149513e-05; Time/iteration: 0.401m; Time so far/epoch: 0.597h
2024-05-01 18:21:30,396 - trainer - INFO - Train Epoch: 2 dl0 [49536/321526 (15%)] Loss: 1.918901; lr: 2.9601867392260187e-05; Time/iteration: 0.395m; Time so far/epoch: 0.603h
2024-05-01 18:21:55,224 - trainer - INFO - Train Epoch: 2 dl0 [50112/321526 (16%)] Loss: 1.958382; lr: 2.9598768049022585e-05; Time/iteration: 0.414m; Time so far/epoch: 0.610h
2024-05-01 18:22:19,997 - trainer - INFO - Train Epoch: 2 dl0 [50688/321526 (16%)] Loss: 2.051217; lr: 2.959565685397898e-05; Time/iteration: 0.413m; Time so far/epoch: 0.617h
2024-05-01 18:22:43,932 - trainer - INFO - Train Epoch: 2 dl0 [51264/321526 (16%)] Loss: 1.854360; lr: 2.9592533809681378e-05; Time/iteration: 0.399m; Time so far/epoch: 0.624h
2024-05-01 18:23:07,710 - trainer - INFO - Train Epoch: 2 dl0 [51840/321526 (16%)] Loss: 1.986140; lr: 2.9589398918691494e-05; Time/iteration: 0.396m; Time so far/epoch: 0.630h
2024-05-01 18:23:31,555 - trainer - INFO - Train Epoch: 2 dl0 [52416/321526 (16%)] Loss: 1.849614; lr: 2.958625218358077e-05; Time/iteration: 0.397m; Time so far/epoch: 0.637h
2024-05-01 18:23:55,462 - trainer - INFO - Train Epoch: 2 dl0 [52992/321526 (16%)] Loss: 1.958986; lr: 2.9583093606930365e-05; Time/iteration: 0.398m; Time so far/epoch: 0.644h
2024-05-01 18:24:19,661 - trainer - INFO - Train Epoch: 2 dl0 [53568/321526 (17%)] Loss: 1.992187; lr: 2.9579923191331137e-05; Time/iteration: 0.403m; Time so far/epoch: 0.650h
2024-05-01 18:24:45,167 - trainer - INFO - Train Epoch: 2 dl0 [54144/321526 (17%)] Loss: 2.119143; lr: 2.9576740939383673e-05; Time/iteration: 0.425m; Time so far/epoch: 0.658h
2024-05-01 18:25:08,354 - trainer - INFO - Train Epoch: 2 dl0 [54720/321526 (17%)] Loss: 1.985007; lr: 2.9573546853698253e-05; Time/iteration: 0.386m; Time so far/epoch: 0.664h
2024-05-01 18:25:32,371 - trainer - INFO - Train Epoch: 2 dl0 [55296/321526 (17%)] Loss: 1.957612; lr: 2.9570340936894872e-05; Time/iteration: 0.400m; Time so far/epoch: 0.671h
2024-05-01 18:25:55,898 - trainer - INFO - Train Epoch: 2 dl0 [55872/321526 (17%)] Loss: 1.988190; lr: 2.9567123191603233e-05; Time/iteration: 0.392m; Time so far/epoch: 0.677h
2024-05-01 18:26:19,668 - trainer - INFO - Train Epoch: 2 dl0 [56448/321526 (18%)] Loss: 1.890405; lr: 2.956389362046273e-05; Time/iteration: 0.396m; Time so far/epoch: 0.684h
2024-05-01 18:26:43,998 - trainer - INFO - Train Epoch: 2 dl0 [57024/321526 (18%)] Loss: 1.943019; lr: 2.956065222612247e-05; Time/iteration: 0.406m; Time so far/epoch: 0.691h
2024-05-01 18:27:07,504 - trainer - INFO - Train Epoch: 2 dl0 [57600/321526 (18%)] Loss: 1.943733; lr: 2.9557399011241255e-05; Time/iteration: 0.392m; Time so far/epoch: 0.697h
2024-05-01 18:27:31,063 - trainer - INFO - Train Epoch: 2 dl0 [58176/321526 (18%)] Loss: 1.957351; lr: 2.955413397848757e-05; Time/iteration: 0.393m; Time so far/epoch: 0.704h
2024-05-01 18:27:54,755 - trainer - INFO - Train Epoch: 2 dl0 [58752/321526 (18%)] Loss: 2.069406; lr: 2.9550857130539616e-05; Time/iteration: 0.395m; Time so far/epoch: 0.710h
2024-05-01 18:28:19,442 - trainer - INFO - Train Epoch: 2 dl0 [59328/321526 (18%)] Loss: 2.091794; lr: 2.9547568470085268e-05; Time/iteration: 0.411m; Time so far/epoch: 0.717h
2024-05-01 18:28:43,876 - trainer - INFO - Train Epoch: 2 dl0 [59904/321526 (19%)] Loss: 1.950320; lr: 2.9544267999822093e-05; Time/iteration: 0.407m; Time so far/epoch: 0.724h
2024-05-01 18:29:07,323 - trainer - INFO - Train Epoch: 2 dl0 [60480/321526 (19%)] Loss: 1.951252; lr: 2.9540955722457353e-05; Time/iteration: 0.391m; Time so far/epoch: 0.730h
2024-05-01 18:29:31,536 - trainer - INFO - Train Epoch: 2 dl0 [61056/321526 (19%)] Loss: 2.041020; lr: 2.953763164070799e-05; Time/iteration: 0.404m; Time so far/epoch: 0.737h
2024-05-01 18:29:55,155 - trainer - INFO - Train Epoch: 2 dl0 [61632/321526 (19%)] Loss: 1.883762; lr: 2.9534295757300627e-05; Time/iteration: 0.394m; Time so far/epoch: 0.744h
2024-05-01 18:30:19,573 - trainer - INFO - Train Epoch: 2 dl0 [62208/321526 (19%)] Loss: 1.913267; lr: 2.953094807497157e-05; Time/iteration: 0.407m; Time so far/epoch: 0.750h
2024-05-01 18:30:44,465 - trainer - INFO - Train Epoch: 2 dl0 [62784/321526 (20%)] Loss: 2.019160; lr: 2.9527588596466807e-05; Time/iteration: 0.415m; Time so far/epoch: 0.757h
2024-05-01 18:31:08,112 - trainer - INFO - Train Epoch: 2 dl0 [63360/321526 (20%)] Loss: 1.887330; lr: 2.9524217324541993e-05; Time/iteration: 0.394m; Time so far/epoch: 0.764h
2024-05-01 18:31:31,691 - trainer - INFO - Train Epoch: 2 dl0 [63936/321526 (20%)] Loss: 1.973572; lr: 2.952083426196246e-05; Time/iteration: 0.393m; Time so far/epoch: 0.770h
2024-05-01 18:31:55,452 - trainer - INFO - Train Epoch: 2 dl0 [64512/321526 (20%)] Loss: 2.046035; lr: 2.9517439411503215e-05; Time/iteration: 0.396m; Time so far/epoch: 0.777h
2024-05-01 18:32:20,160 - trainer - INFO - Train Epoch: 2 dl0 [65088/321526 (20%)] Loss: 1.889990; lr: 2.9514032775948933e-05; Time/iteration: 0.412m; Time so far/epoch: 0.784h
2024-05-01 18:32:44,300 - trainer - INFO - Train Epoch: 2 dl0 [65664/321526 (20%)] Loss: 2.008033; lr: 2.9510614358093956e-05; Time/iteration: 0.402m; Time so far/epoch: 0.791h
2024-05-01 18:33:08,154 - trainer - INFO - Train Epoch: 2 dl0 [66240/321526 (21%)] Loss: 1.880286; lr: 2.950718416074228e-05; Time/iteration: 0.398m; Time so far/epoch: 0.797h
2024-05-01 18:33:32,184 - trainer - INFO - Train Epoch: 2 dl0 [66816/321526 (21%)] Loss: 1.887650; lr: 2.9503742186707588e-05; Time/iteration: 0.400m; Time so far/epoch: 0.804h
2024-05-01 18:33:55,927 - trainer - INFO - Train Epoch: 2 dl0 [67392/321526 (21%)] Loss: 1.954765; lr: 2.95002884388132e-05; Time/iteration: 0.396m; Time so far/epoch: 0.811h
2024-05-01 18:34:19,917 - trainer - INFO - Train Epoch: 2 dl0 [67968/321526 (21%)] Loss: 1.887325; lr: 2.94968229198921e-05; Time/iteration: 0.400m; Time so far/epoch: 0.817h
2024-05-01 18:34:43,862 - trainer - INFO - Train Epoch: 2 dl0 [68544/321526 (21%)] Loss: 2.030101; lr: 2.949334563278693e-05; Time/iteration: 0.399m; Time so far/epoch: 0.824h
2024-05-01 18:35:08,571 - trainer - INFO - Train Epoch: 2 dl0 [69120/321526 (21%)] Loss: 2.050184; lr: 2.9489856580349984e-05; Time/iteration: 0.412m; Time so far/epoch: 0.831h
2024-05-01 18:35:32,250 - trainer - INFO - Train Epoch: 2 dl0 [69696/321526 (22%)] Loss: 1.858985; lr: 2.9486355765443213e-05; Time/iteration: 0.395m; Time so far/epoch: 0.837h
2024-05-01 18:35:55,595 - trainer - INFO - Train Epoch: 2 dl0 [70272/321526 (22%)] Loss: 1.886504; lr: 2.9482843190938197e-05; Time/iteration: 0.389m; Time so far/epoch: 0.844h
2024-05-01 18:36:20,051 - trainer - INFO - Train Epoch: 2 dl0 [70848/321526 (22%)] Loss: 2.001820; lr: 2.9479318859716185e-05; Time/iteration: 0.408m; Time so far/epoch: 0.851h
2024-05-01 18:36:44,602 - trainer - INFO - Train Epoch: 2 dl0 [71424/321526 (22%)] Loss: 2.014230; lr: 2.9475782774668054e-05; Time/iteration: 0.409m; Time so far/epoch: 0.857h
2024-05-01 18:37:08,534 - trainer - INFO - Train Epoch: 2 dl0 [72000/321526 (22%)] Loss: 1.889392; lr: 2.947223493869433e-05; Time/iteration: 0.399m; Time so far/epoch: 0.864h
2024-05-01 18:37:32,110 - trainer - INFO - Train Epoch: 2 dl0 [72576/321526 (23%)] Loss: 2.056212; lr: 2.9468675354705177e-05; Time/iteration: 0.393m; Time so far/epoch: 0.871h
2024-05-01 18:37:55,866 - trainer - INFO - Train Epoch: 2 dl0 [73152/321526 (23%)] Loss: 1.944419; lr: 2.9465104025620393e-05; Time/iteration: 0.396m; Time so far/epoch: 0.877h
2024-05-01 18:38:20,026 - trainer - INFO - Train Epoch: 2 dl0 [73728/321526 (23%)] Loss: 1.962794; lr: 2.9461520954369403e-05; Time/iteration: 0.403m; Time so far/epoch: 0.884h
2024-05-01 18:38:44,511 - trainer - INFO - Train Epoch: 2 dl0 [74304/321526 (23%)] Loss: 1.903968; lr: 2.9457926143891286e-05; Time/iteration: 0.408m; Time so far/epoch: 0.891h
2024-05-01 18:39:09,061 - trainer - INFO - Train Epoch: 2 dl0 [74880/321526 (23%)] Loss: 2.069075; lr: 2.945431959713473e-05; Time/iteration: 0.409m; Time so far/epoch: 0.898h
2024-05-01 18:39:32,723 - trainer - INFO - Train Epoch: 2 dl0 [75456/321526 (23%)] Loss: 1.932764; lr: 2.945070131705805e-05; Time/iteration: 0.394m; Time so far/epoch: 0.904h
2024-05-01 18:39:56,277 - trainer - INFO - Train Epoch: 2 dl0 [76032/321526 (24%)] Loss: 2.001125; lr: 2.9447071306629202e-05; Time/iteration: 0.393m; Time so far/epoch: 0.911h
2024-05-01 18:40:20,359 - trainer - INFO - Train Epoch: 2 dl0 [76608/321526 (24%)] Loss: 1.930618; lr: 2.9443429568825744e-05; Time/iteration: 0.401m; Time so far/epoch: 0.917h
2024-05-01 18:40:44,638 - trainer - INFO - Train Epoch: 2 dl0 [77184/321526 (24%)] Loss: 1.956121; lr: 2.9439776106634865e-05; Time/iteration: 0.405m; Time so far/epoch: 0.924h
2024-05-01 18:41:08,351 - trainer - INFO - Train Epoch: 2 dl0 [77760/321526 (24%)] Loss: 1.831258; lr: 2.9436110923053377e-05; Time/iteration: 0.395m; Time so far/epoch: 0.931h
2024-05-01 18:41:32,387 - trainer - INFO - Train Epoch: 2 dl0 [78336/321526 (24%)] Loss: 1.906933; lr: 2.9432434021087687e-05; Time/iteration: 0.401m; Time so far/epoch: 0.937h
2024-05-01 18:41:55,934 - trainer - INFO - Train Epoch: 2 dl0 [78912/321526 (25%)] Loss: 1.988023; lr: 2.942874540375383e-05; Time/iteration: 0.392m; Time so far/epoch: 0.944h
2024-05-01 18:42:19,518 - trainer - INFO - Train Epoch: 2 dl0 [79488/321526 (25%)] Loss: 2.041135; lr: 2.9425045074077453e-05; Time/iteration: 0.393m; Time so far/epoch: 0.950h
2024-05-01 18:42:44,052 - trainer - INFO - Train Epoch: 2 dl0 [80064/321526 (25%)] Loss: 1.908795; lr: 2.9421333035093797e-05; Time/iteration: 0.409m; Time so far/epoch: 0.957h
2024-05-01 18:43:08,267 - trainer - INFO - Train Epoch: 2 dl0 [80640/321526 (25%)] Loss: 1.871730; lr: 2.941760928984771e-05; Time/iteration: 0.404m; Time so far/epoch: 0.964h
2024-05-01 18:43:32,400 - trainer - INFO - Train Epoch: 2 dl0 [81216/321526 (25%)] Loss: 1.925675; lr: 2.941387384139366e-05; Time/iteration: 0.402m; Time so far/epoch: 0.971h
2024-05-01 18:43:55,992 - trainer - INFO - Train Epoch: 2 dl0 [81792/321526 (25%)] Loss: 1.941491; lr: 2.9410126692795687e-05; Time/iteration: 0.393m; Time so far/epoch: 0.977h
2024-05-01 18:44:19,322 - trainer - INFO - Train Epoch: 2 dl0 [82368/321526 (26%)] Loss: 1.929064; lr: 2.9406367847127452e-05; Time/iteration: 0.389m; Time so far/epoch: 0.984h
2024-05-01 18:44:43,321 - trainer - INFO - Train Epoch: 2 dl0 [82944/321526 (26%)] Loss: 1.884513; lr: 2.9402597307472198e-05; Time/iteration: 0.400m; Time so far/epoch: 0.990h
2024-05-01 18:45:07,880 - trainer - INFO - Train Epoch: 2 dl0 [83520/321526 (26%)] Loss: 1.918194; lr: 2.939881507692276e-05; Time/iteration: 0.409m; Time so far/epoch: 0.997h
2024-05-01 18:45:32,157 - trainer - INFO - Train Epoch: 2 dl0 [84096/321526 (26%)] Loss: 1.973850; lr: 2.9395021158581572e-05; Time/iteration: 0.405m; Time so far/epoch: 1.004h
2024-05-01 18:45:55,640 - trainer - INFO - Train Epoch: 2 dl0 [84672/321526 (26%)] Loss: 2.090114; lr: 2.9391215555560648e-05; Time/iteration: 0.391m; Time so far/epoch: 1.010h
2024-05-01 18:46:19,230 - trainer - INFO - Train Epoch: 2 dl0 [85248/321526 (27%)] Loss: 2.067340; lr: 2.9387398270981585e-05; Time/iteration: 0.393m; Time so far/epoch: 1.017h
2024-05-01 18:46:43,208 - trainer - INFO - Train Epoch: 2 dl0 [85824/321526 (27%)] Loss: 1.870211; lr: 2.9383569307975565e-05; Time/iteration: 0.400m; Time so far/epoch: 1.024h
2024-05-01 18:47:07,742 - trainer - INFO - Train Epoch: 2 dl0 [86400/321526 (27%)] Loss: 1.936522; lr: 2.937972866968335e-05; Time/iteration: 0.409m; Time so far/epoch: 1.030h
2024-05-01 18:47:31,264 - trainer - INFO - Train Epoch: 2 dl0 [86976/321526 (27%)] Loss: 1.852501; lr: 2.9375876359255278e-05; Time/iteration: 0.392m; Time so far/epoch: 1.037h
2024-05-01 18:47:54,615 - trainer - INFO - Train Epoch: 2 dl0 [87552/321526 (27%)] Loss: 1.896558; lr: 2.937201237985126e-05; Time/iteration: 0.389m; Time so far/epoch: 1.044h
2024-05-01 18:48:18,771 - trainer - INFO - Train Epoch: 2 dl0 [88128/321526 (27%)] Loss: 1.905449; lr: 2.9368136734640782e-05; Time/iteration: 0.403m; Time so far/epoch: 1.050h
2024-05-01 18:48:43,181 - trainer - INFO - Train Epoch: 2 dl0 [88704/321526 (28%)] Loss: 2.033935; lr: 2.9364249426802894e-05; Time/iteration: 0.407m; Time so far/epoch: 1.057h
2024-05-01 18:49:07,294 - trainer - INFO - Train Epoch: 2 dl0 [89280/321526 (28%)] Loss: 1.912800; lr: 2.9360350459526217e-05; Time/iteration: 0.402m; Time so far/epoch: 1.064h
2024-05-01 18:49:31,223 - trainer - INFO - Train Epoch: 2 dl0 [89856/321526 (28%)] Loss: 1.913014; lr: 2.935643983600893e-05; Time/iteration: 0.399m; Time so far/epoch: 1.070h
2024-05-01 18:49:54,529 - trainer - INFO - Train Epoch: 2 dl0 [90432/321526 (28%)] Loss: 2.030045; lr: 2.9352517559458784e-05; Time/iteration: 0.388m; Time so far/epoch: 1.077h
2024-05-01 18:50:18,573 - trainer - INFO - Train Epoch: 2 dl0 [91008/321526 (28%)] Loss: 1.851341; lr: 2.9348583633093074e-05; Time/iteration: 0.401m; Time so far/epoch: 1.083h
2024-05-01 18:50:42,716 - trainer - INFO - Train Epoch: 2 dl0 [91584/321526 (28%)] Loss: 1.986376; lr: 2.934463806013867e-05; Time/iteration: 0.402m; Time so far/epoch: 1.090h
2024-05-01 18:51:07,200 - trainer - INFO - Train Epoch: 2 dl0 [92160/321526 (29%)] Loss: 2.056429; lr: 2.934068084383197e-05; Time/iteration: 0.408m; Time so far/epoch: 1.097h
2024-05-01 18:51:32,569 - trainer - INFO - Train Epoch: 2 dl0 [92736/321526 (29%)] Loss: 1.942187; lr: 2.9336711987418944e-05; Time/iteration: 0.423m; Time so far/epoch: 1.104h
2024-05-01 18:51:56,323 - trainer - INFO - Train Epoch: 2 dl0 [93312/321526 (29%)] Loss: 1.933959; lr: 2.93327314941551e-05; Time/iteration: 0.396m; Time so far/epoch: 1.111h
2024-05-01 18:52:20,118 - trainer - INFO - Train Epoch: 2 dl0 [93888/321526 (29%)] Loss: 2.096698; lr: 2.9328739367305503e-05; Time/iteration: 0.397m; Time so far/epoch: 1.117h
2024-05-01 18:52:44,436 - trainer - INFO - Train Epoch: 2 dl0 [94464/321526 (29%)] Loss: 2.024549; lr: 2.9324735610144733e-05; Time/iteration: 0.405m; Time so far/epoch: 1.124h
2024-05-01 18:53:09,520 - trainer - INFO - Train Epoch: 2 dl0 [95040/321526 (30%)] Loss: 2.026327; lr: 2.932072022595695e-05; Time/iteration: 0.418m; Time so far/epoch: 1.131h
2024-05-01 18:53:33,884 - trainer - INFO - Train Epoch: 2 dl0 [95616/321526 (30%)] Loss: 1.951077; lr: 2.931669321803581e-05; Time/iteration: 0.406m; Time so far/epoch: 1.138h
2024-05-01 18:53:57,579 - trainer - INFO - Train Epoch: 2 dl0 [96192/321526 (30%)] Loss: 2.008493; lr: 2.9312654589684537e-05; Time/iteration: 0.395m; Time so far/epoch: 1.144h
2024-05-01 18:54:22,146 - trainer - INFO - Train Epoch: 2 dl0 [96768/321526 (30%)] Loss: 2.031862; lr: 2.9308604344215864e-05; Time/iteration: 0.409m; Time so far/epoch: 1.151h
2024-05-01 18:54:45,615 - trainer - INFO - Train Epoch: 2 dl0 [97344/321526 (30%)] Loss: 1.997975; lr: 2.9304542484952067e-05; Time/iteration: 0.391m; Time so far/epoch: 1.158h
2024-05-01 18:55:10,662 - trainer - INFO - Train Epoch: 2 dl0 [97920/321526 (30%)] Loss: 1.965057; lr: 2.9300469015224943e-05; Time/iteration: 0.417m; Time so far/epoch: 1.165h
2024-05-01 18:55:34,779 - trainer - INFO - Train Epoch: 2 dl0 [98496/321526 (31%)] Loss: 1.898514; lr: 2.9296383938375815e-05; Time/iteration: 0.402m; Time so far/epoch: 1.171h
2024-05-01 18:55:58,256 - trainer - INFO - Train Epoch: 2 dl0 [99072/321526 (31%)] Loss: 2.001862; lr: 2.9292287257755516e-05; Time/iteration: 0.391m; Time so far/epoch: 1.178h
2024-05-01 18:56:22,737 - trainer - INFO - Train Epoch: 2 dl0 [99648/321526 (31%)] Loss: 1.936571; lr: 2.9288178976724417e-05; Time/iteration: 0.408m; Time so far/epoch: 1.185h
2024-05-01 18:59:58,909 - trainer - INFO - EgoClip_HOI epoch 2, Verb-Neg, Acc: 55.6;    EgoClip_HOI epoch 2, Noun-Neg, Acc: 69.0;    EgoClip_HOI epoch 2, HOI-Neg, Acc: 41.0;    
2024-05-01 18:59:58,918 - trainer - INFO -     epoch          : 2
2024-05-01 18:59:58,919 - trainer - INFO -     loss_0         : 0.610067470667344
2024-05-01 18:59:58,919 - trainer - INFO -     val_loss_0     : 0.0
2024-05-01 18:59:58,919 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 55.560428619384766
2024-05-01 18:59:58,919 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 68.96074676513672
2024-05-01 18:59:58,919 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.00687789916992
2024-05-01 18:59:59,967 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch2.pth ...
2024-05-01 19:00:01,727 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-01 19:01:07,117 - trainer - INFO - Train Epoch: 3 dl0 [0/321526 (0%)] Loss: 1.980322; lr: 2.928612048710753e-05; Time/iteration: 1.090m; Time so far/epoch: 0.018h
2024-05-01 19:01:48,468 - trainer - INFO - Train Epoch: 3 dl0 [576/321526 (0%)] Loss: 1.942686; lr: 2.928199481178171e-05; Time/iteration: 0.689m; Time so far/epoch: 0.030h
2024-05-01 19:02:14,241 - trainer - INFO - Train Epoch: 3 dl0 [1152/321526 (0%)] Loss: 2.018695; lr: 2.9277857544487614e-05; Time/iteration: 0.429m; Time so far/epoch: 0.037h
2024-05-01 19:02:40,499 - trainer - INFO - Train Epoch: 3 dl0 [1728/321526 (1%)] Loss: 1.992738; lr: 2.9273708688618886e-05; Time/iteration: 0.438m; Time so far/epoch: 0.044h
2024-05-01 19:03:06,535 - trainer - INFO - Train Epoch: 3 dl0 [2304/321526 (1%)] Loss: 2.005903; lr: 2.926954824757869e-05; Time/iteration: 0.434m; Time so far/epoch: 0.051h
2024-05-01 19:03:32,986 - trainer - INFO - Train Epoch: 3 dl0 [2880/321526 (1%)] Loss: 1.947331; lr: 2.9265376224779678e-05; Time/iteration: 0.441m; Time so far/epoch: 0.059h
2024-05-01 19:03:58,694 - trainer - INFO - Train Epoch: 3 dl0 [3456/321526 (1%)] Loss: 1.817414; lr: 2.926119262364402e-05; Time/iteration: 0.428m; Time so far/epoch: 0.066h
2024-05-01 19:04:31,770 - trainer - INFO - Train Epoch: 3 dl0 [4032/321526 (1%)] Loss: 1.932542; lr: 2.925699744760337e-05; Time/iteration: 0.551m; Time so far/epoch: 0.075h
2024-05-01 19:04:58,881 - trainer - INFO - Train Epoch: 3 dl0 [4608/321526 (1%)] Loss: 1.996457; lr: 2.9252790700098882e-05; Time/iteration: 0.452m; Time so far/epoch: 0.083h
2024-05-01 19:05:25,136 - trainer - INFO - Train Epoch: 3 dl0 [5184/321526 (2%)] Loss: 1.930669; lr: 2.9248572384581195e-05; Time/iteration: 0.438m; Time so far/epoch: 0.090h
2024-05-01 19:05:50,750 - trainer - INFO - Train Epoch: 3 dl0 [5760/321526 (2%)] Loss: 1.925731; lr: 2.924434250451045e-05; Time/iteration: 0.427m; Time so far/epoch: 0.097h
2024-05-01 19:06:16,619 - trainer - INFO - Train Epoch: 3 dl0 [6336/321526 (2%)] Loss: 1.874529; lr: 2.9240101063356253e-05; Time/iteration: 0.431m; Time so far/epoch: 0.104h
2024-05-01 19:06:42,433 - trainer - INFO - Train Epoch: 3 dl0 [6912/321526 (2%)] Loss: 1.896684; lr: 2.923584806459772e-05; Time/iteration: 0.430m; Time so far/epoch: 0.111h
2024-05-01 19:07:07,061 - trainer - INFO - Train Epoch: 3 dl0 [7488/321526 (2%)] Loss: 1.985233; lr: 2.923158351172343e-05; Time/iteration: 0.410m; Time so far/epoch: 0.118h
2024-05-01 19:07:30,403 - trainer - INFO - Train Epoch: 3 dl0 [8064/321526 (3%)] Loss: 1.936482; lr: 2.9227307408231435e-05; Time/iteration: 0.389m; Time so far/epoch: 0.125h
2024-05-01 19:07:54,791 - trainer - INFO - Train Epoch: 3 dl0 [8640/321526 (3%)] Loss: 1.994280; lr: 2.9223019757629277e-05; Time/iteration: 0.406m; Time so far/epoch: 0.131h
2024-05-01 19:08:19,015 - trainer - INFO - Train Epoch: 3 dl0 [9216/321526 (3%)] Loss: 2.125611; lr: 2.9218720563433957e-05; Time/iteration: 0.404m; Time so far/epoch: 0.138h
2024-05-01 19:08:43,320 - trainer - INFO - Train Epoch: 3 dl0 [9792/321526 (3%)] Loss: 1.883501; lr: 2.9214409829171954e-05; Time/iteration: 0.405m; Time so far/epoch: 0.145h
2024-05-01 19:09:07,101 - trainer - INFO - Train Epoch: 3 dl0 [10368/321526 (3%)] Loss: 1.875916; lr: 2.9210087558379204e-05; Time/iteration: 0.396m; Time so far/epoch: 0.151h
2024-05-01 19:09:30,812 - trainer - INFO - Train Epoch: 3 dl0 [10944/321526 (3%)] Loss: 1.871113; lr: 2.9205753754601116e-05; Time/iteration: 0.395m; Time so far/epoch: 0.158h
2024-05-01 19:09:54,381 - trainer - INFO - Train Epoch: 3 dl0 [11520/321526 (4%)] Loss: 2.036170; lr: 2.9201408421392552e-05; Time/iteration: 0.393m; Time so far/epoch: 0.165h
2024-05-01 19:10:18,819 - trainer - INFO - Train Epoch: 3 dl0 [12096/321526 (4%)] Loss: 1.868415; lr: 2.919705156231783e-05; Time/iteration: 0.407m; Time so far/epoch: 0.171h
2024-05-01 19:10:43,900 - trainer - INFO - Train Epoch: 3 dl0 [12672/321526 (4%)] Loss: 1.974900; lr: 2.9192683180950726e-05; Time/iteration: 0.418m; Time so far/epoch: 0.178h
2024-05-01 19:11:09,074 - trainer - INFO - Train Epoch: 3 dl0 [13248/321526 (4%)] Loss: 1.988462; lr: 2.9188303280874473e-05; Time/iteration: 0.420m; Time so far/epoch: 0.185h
2024-05-01 19:11:33,130 - trainer - INFO - Train Epoch: 3 dl0 [13824/321526 (4%)] Loss: 1.888732; lr: 2.9183911865681737e-05; Time/iteration: 0.401m; Time so far/epoch: 0.192h
2024-05-01 19:11:56,397 - trainer - INFO - Train Epoch: 3 dl0 [14400/321526 (4%)] Loss: 1.978096; lr: 2.917950893897464e-05; Time/iteration: 0.388m; Time so far/epoch: 0.199h
2024-05-01 19:12:20,316 - trainer - INFO - Train Epoch: 3 dl0 [14976/321526 (5%)] Loss: 1.911156; lr: 2.917509450436475e-05; Time/iteration: 0.399m; Time so far/epoch: 0.205h
2024-05-01 19:12:45,165 - trainer - INFO - Train Epoch: 3 dl0 [15552/321526 (5%)] Loss: 1.935394; lr: 2.9170668565473064e-05; Time/iteration: 0.414m; Time so far/epoch: 0.212h
2024-05-01 19:13:09,548 - trainer - INFO - Train Epoch: 3 dl0 [16128/321526 (5%)] Loss: 1.918545; lr: 2.9166231125930025e-05; Time/iteration: 0.406m; Time so far/epoch: 0.219h
2024-05-01 19:13:33,485 - trainer - INFO - Train Epoch: 3 dl0 [16704/321526 (5%)] Loss: 1.933398; lr: 2.9161782189375503e-05; Time/iteration: 0.399m; Time so far/epoch: 0.225h
2024-05-01 19:13:56,812 - trainer - INFO - Train Epoch: 3 dl0 [17280/321526 (5%)] Loss: 1.956379; lr: 2.91573217594588e-05; Time/iteration: 0.389m; Time so far/epoch: 0.232h
2024-05-01 19:14:21,585 - trainer - INFO - Train Epoch: 3 dl0 [17856/321526 (6%)] Loss: 2.018505; lr: 2.915284983983865e-05; Time/iteration: 0.413m; Time so far/epoch: 0.239h
2024-05-01 19:14:45,531 - trainer - INFO - Train Epoch: 3 dl0 [18432/321526 (6%)] Loss: 1.955617; lr: 2.91483664341832e-05; Time/iteration: 0.399m; Time so far/epoch: 0.245h
2024-05-01 19:15:09,324 - trainer - INFO - Train Epoch: 3 dl0 [19008/321526 (6%)] Loss: 1.880051; lr: 2.9143871546170037e-05; Time/iteration: 0.397m; Time so far/epoch: 0.252h
2024-05-01 19:15:34,107 - trainer - INFO - Train Epoch: 3 dl0 [19584/321526 (6%)] Loss: 1.886666; lr: 2.9139365179486155e-05; Time/iteration: 0.413m; Time so far/epoch: 0.259h
2024-05-01 19:15:57,494 - trainer - INFO - Train Epoch: 3 dl0 [20160/321526 (6%)] Loss: 1.932922; lr: 2.9134847337827957e-05; Time/iteration: 0.390m; Time so far/epoch: 0.265h
2024-05-01 19:16:21,107 - trainer - INFO - Train Epoch: 3 dl0 [20736/321526 (6%)] Loss: 1.836169; lr: 2.913031802490128e-05; Time/iteration: 0.394m; Time so far/epoch: 0.272h
2024-05-01 19:16:45,229 - trainer - INFO - Train Epoch: 3 dl0 [21312/321526 (7%)] Loss: 1.939692; lr: 2.9125777244421344e-05; Time/iteration: 0.402m; Time so far/epoch: 0.279h
2024-05-01 19:17:10,908 - trainer - INFO - Train Epoch: 3 dl0 [21888/321526 (7%)] Loss: 1.937765; lr: 2.9121225000112788e-05; Time/iteration: 0.428m; Time so far/epoch: 0.286h
2024-05-01 19:17:36,027 - trainer - INFO - Train Epoch: 3 dl0 [22464/321526 (7%)] Loss: 1.841947; lr: 2.9116661295709666e-05; Time/iteration: 0.419m; Time so far/epoch: 0.293h
2024-05-01 19:18:00,237 - trainer - INFO - Train Epoch: 3 dl0 [23040/321526 (7%)] Loss: 2.136412; lr: 2.9112086134955412e-05; Time/iteration: 0.404m; Time so far/epoch: 0.300h
2024-05-01 19:18:24,535 - trainer - INFO - Train Epoch: 3 dl0 [23616/321526 (7%)] Loss: 2.005505; lr: 2.9107499521602868e-05; Time/iteration: 0.405m; Time so far/epoch: 0.306h
2024-05-01 19:18:47,855 - trainer - INFO - Train Epoch: 3 dl0 [24192/321526 (8%)] Loss: 1.940054; lr: 2.910290145941427e-05; Time/iteration: 0.389m; Time so far/epoch: 0.313h
2024-05-01 19:19:11,727 - trainer - INFO - Train Epoch: 3 dl0 [24768/321526 (8%)] Loss: 1.982342; lr: 2.909829195216124e-05; Time/iteration: 0.398m; Time so far/epoch: 0.319h
2024-05-01 19:19:36,221 - trainer - INFO - Train Epoch: 3 dl0 [25344/321526 (8%)] Loss: 1.931041; lr: 2.90936710036248e-05; Time/iteration: 0.408m; Time so far/epoch: 0.326h
2024-05-01 19:20:00,755 - trainer - INFO - Train Epoch: 3 dl0 [25920/321526 (8%)] Loss: 1.905134; lr: 2.9089038617595333e-05; Time/iteration: 0.409m; Time so far/epoch: 0.333h
2024-05-01 19:20:25,638 - trainer - INFO - Train Epoch: 3 dl0 [26496/321526 (8%)] Loss: 1.910407; lr: 2.9084394797872638e-05; Time/iteration: 0.415m; Time so far/epoch: 0.340h
2024-05-01 19:20:49,123 - trainer - INFO - Train Epoch: 3 dl0 [27072/321526 (8%)] Loss: 1.862127; lr: 2.907973954826586e-05; Time/iteration: 0.391m; Time so far/epoch: 0.346h
2024-05-01 19:21:13,262 - trainer - INFO - Train Epoch: 3 dl0 [27648/321526 (9%)] Loss: 2.012361; lr: 2.9075072872593534e-05; Time/iteration: 0.402m; Time so far/epoch: 0.353h
2024-05-01 19:21:36,502 - trainer - INFO - Train Epoch: 3 dl0 [28224/321526 (9%)] Loss: 1.972742; lr: 2.9070394774683573e-05; Time/iteration: 0.387m; Time so far/epoch: 0.360h
2024-05-01 19:22:00,517 - trainer - INFO - Train Epoch: 3 dl0 [28800/321526 (9%)] Loss: 1.876567; lr: 2.9065705258373247e-05; Time/iteration: 0.400m; Time so far/epoch: 0.366h
2024-05-01 19:22:24,093 - trainer - INFO - Train Epoch: 3 dl0 [29376/321526 (9%)] Loss: 1.940854; lr: 2.9061004327509205e-05; Time/iteration: 0.393m; Time so far/epoch: 0.373h
2024-05-01 19:22:48,628 - trainer - INFO - Train Epoch: 3 dl0 [29952/321526 (9%)] Loss: 1.883634; lr: 2.9056291985947442e-05; Time/iteration: 0.409m; Time so far/epoch: 0.380h
2024-05-01 19:23:12,400 - trainer - INFO - Train Epoch: 3 dl0 [30528/321526 (9%)] Loss: 1.908674; lr: 2.9051568237553328e-05; Time/iteration: 0.396m; Time so far/epoch: 0.386h
2024-05-01 19:23:36,621 - trainer - INFO - Train Epoch: 3 dl0 [31104/321526 (10%)] Loss: 1.905744; lr: 2.9046833086201592e-05; Time/iteration: 0.404m; Time so far/epoch: 0.393h
2024-05-01 19:24:00,060 - trainer - INFO - Train Epoch: 3 dl0 [31680/321526 (10%)] Loss: 1.978210; lr: 2.9042086535776297e-05; Time/iteration: 0.391m; Time so far/epoch: 0.400h
2024-05-01 19:24:24,389 - trainer - INFO - Train Epoch: 3 dl0 [32256/321526 (10%)] Loss: 1.935284; lr: 2.903732859017087e-05; Time/iteration: 0.405m; Time so far/epoch: 0.406h
2024-05-01 19:24:48,738 - trainer - INFO - Train Epoch: 3 dl0 [32832/321526 (10%)] Loss: 2.043475; lr: 2.9032559253288088e-05; Time/iteration: 0.406m; Time so far/epoch: 0.413h
2024-05-01 19:25:13,413 - trainer - INFO - Train Epoch: 3 dl0 [33408/321526 (10%)] Loss: 1.832986; lr: 2.9027778529040062e-05; Time/iteration: 0.411m; Time so far/epoch: 0.420h
2024-05-01 19:25:37,534 - trainer - INFO - Train Epoch: 3 dl0 [33984/321526 (11%)] Loss: 1.941515; lr: 2.9022986421348254e-05; Time/iteration: 0.402m; Time so far/epoch: 0.427h
2024-05-01 19:26:01,142 - trainer - INFO - Train Epoch: 3 dl0 [34560/321526 (11%)] Loss: 2.005713; lr: 2.9018182934143452e-05; Time/iteration: 0.393m; Time so far/epoch: 0.433h
2024-05-01 19:26:24,660 - trainer - INFO - Train Epoch: 3 dl0 [35136/321526 (11%)] Loss: 2.011104; lr: 2.901336807136579e-05; Time/iteration: 0.392m; Time so far/epoch: 0.440h
2024-05-01 19:26:49,183 - trainer - INFO - Train Epoch: 3 dl0 [35712/321526 (11%)] Loss: 2.125808; lr: 2.9008541836964718e-05; Time/iteration: 0.409m; Time so far/epoch: 0.447h
2024-05-01 19:27:13,502 - trainer - INFO - Train Epoch: 3 dl0 [36288/321526 (11%)] Loss: 1.959591; lr: 2.9003704234899037e-05; Time/iteration: 0.405m; Time so far/epoch: 0.453h
2024-05-01 19:27:38,615 - trainer - INFO - Train Epoch: 3 dl0 [36864/321526 (11%)] Loss: 1.941964; lr: 2.8998855269136843e-05; Time/iteration: 0.419m; Time so far/epoch: 0.460h
2024-05-01 19:28:02,355 - trainer - INFO - Train Epoch: 3 dl0 [37440/321526 (12%)] Loss: 2.003121; lr: 2.899399494365558e-05; Time/iteration: 0.396m; Time so far/epoch: 0.467h
2024-05-01 19:28:26,394 - trainer - INFO - Train Epoch: 3 dl0 [38016/321526 (12%)] Loss: 1.884396; lr: 2.8989123262441998e-05; Time/iteration: 0.401m; Time so far/epoch: 0.474h
2024-05-01 19:28:50,771 - trainer - INFO - Train Epoch: 3 dl0 [38592/321526 (12%)] Loss: 1.991955; lr: 2.8984240229492154e-05; Time/iteration: 0.406m; Time so far/epoch: 0.480h
2024-05-01 19:29:15,155 - trainer - INFO - Train Epoch: 3 dl0 [39168/321526 (12%)] Loss: 1.925201; lr: 2.897934584881143e-05; Time/iteration: 0.406m; Time so far/epoch: 0.487h
2024-05-01 19:29:39,300 - trainer - INFO - Train Epoch: 3 dl0 [39744/321526 (12%)] Loss: 1.989110; lr: 2.897444012441451e-05; Time/iteration: 0.402m; Time so far/epoch: 0.494h
2024-05-01 19:30:02,713 - trainer - INFO - Train Epoch: 3 dl0 [40320/321526 (13%)] Loss: 1.902204; lr: 2.896952306032539e-05; Time/iteration: 0.390m; Time so far/epoch: 0.500h
2024-05-01 19:30:26,627 - trainer - INFO - Train Epoch: 3 dl0 [40896/321526 (13%)] Loss: 2.025144; lr: 2.8964594660577354e-05; Time/iteration: 0.399m; Time so far/epoch: 0.507h
2024-05-01 19:30:50,699 - trainer - INFO - Train Epoch: 3 dl0 [41472/321526 (13%)] Loss: 1.946579; lr: 2.8959654929212986e-05; Time/iteration: 0.401m; Time so far/epoch: 0.514h
2024-05-01 19:31:14,752 - trainer - INFO - Train Epoch: 3 dl0 [42048/321526 (13%)] Loss: 1.844580; lr: 2.8954703870284182e-05; Time/iteration: 0.401m; Time so far/epoch: 0.520h
2024-05-01 19:31:38,779 - trainer - INFO - Train Epoch: 3 dl0 [42624/321526 (13%)] Loss: 2.077076; lr: 2.8949741487852116e-05; Time/iteration: 0.400m; Time so far/epoch: 0.527h
2024-05-01 19:32:02,116 - trainer - INFO - Train Epoch: 3 dl0 [43200/321526 (13%)] Loss: 1.963446; lr: 2.8944767785987246e-05; Time/iteration: 0.389m; Time so far/epoch: 0.533h
2024-05-01 19:32:26,354 - trainer - INFO - Train Epoch: 3 dl0 [43776/321526 (14%)] Loss: 1.937502; lr: 2.8939782768769327e-05; Time/iteration: 0.404m; Time so far/epoch: 0.540h
2024-05-01 19:32:49,491 - trainer - INFO - Train Epoch: 3 dl0 [44352/321526 (14%)] Loss: 1.883009; lr: 2.8934786440287385e-05; Time/iteration: 0.386m; Time so far/epoch: 0.547h
2024-05-01 19:33:13,776 - trainer - INFO - Train Epoch: 3 dl0 [44928/321526 (14%)] Loss: 1.896722; lr: 2.8929778804639733e-05; Time/iteration: 0.405m; Time so far/epoch: 0.553h
2024-05-01 19:33:38,111 - trainer - INFO - Train Epoch: 3 dl0 [45504/321526 (14%)] Loss: 2.018875; lr: 2.8924759865933955e-05; Time/iteration: 0.406m; Time so far/epoch: 0.560h
2024-05-01 19:34:02,505 - trainer - INFO - Train Epoch: 3 dl0 [46080/321526 (14%)] Loss: 2.005143; lr: 2.89197296282869e-05; Time/iteration: 0.407m; Time so far/epoch: 0.567h
2024-05-01 19:34:26,758 - trainer - INFO - Train Epoch: 3 dl0 [46656/321526 (15%)] Loss: 1.938047; lr: 2.8914688095824702e-05; Time/iteration: 0.404m; Time so far/epoch: 0.574h
2024-05-01 19:34:50,594 - trainer - INFO - Train Epoch: 3 dl0 [47232/321526 (15%)] Loss: 1.813859; lr: 2.8909635272682743e-05; Time/iteration: 0.397m; Time so far/epoch: 0.580h
2024-05-01 19:35:15,819 - trainer - INFO - Train Epoch: 3 dl0 [47808/321526 (15%)] Loss: 1.969911; lr: 2.890457116300567e-05; Time/iteration: 0.420m; Time so far/epoch: 0.587h
2024-05-01 19:35:40,282 - trainer - INFO - Train Epoch: 3 dl0 [48384/321526 (15%)] Loss: 1.906612; lr: 2.8899495770947396e-05; Time/iteration: 0.408m; Time so far/epoch: 0.594h
2024-05-01 19:36:04,483 - trainer - INFO - Train Epoch: 3 dl0 [48960/321526 (15%)] Loss: 1.870261; lr: 2.889440910067108e-05; Time/iteration: 0.403m; Time so far/epoch: 0.601h
2024-05-01 19:36:28,800 - trainer - INFO - Train Epoch: 3 dl0 [49536/321526 (15%)] Loss: 2.055262; lr: 2.8889311156349134e-05; Time/iteration: 0.405m; Time so far/epoch: 0.608h
2024-05-01 19:36:52,402 - trainer - INFO - Train Epoch: 3 dl0 [50112/321526 (16%)] Loss: 1.908499; lr: 2.888420194216322e-05; Time/iteration: 0.393m; Time so far/epoch: 0.614h
2024-05-01 19:37:16,061 - trainer - INFO - Train Epoch: 3 dl0 [50688/321526 (16%)] Loss: 2.036129; lr: 2.887908146230424e-05; Time/iteration: 0.394m; Time so far/epoch: 0.621h
2024-05-01 19:37:39,588 - trainer - INFO - Train Epoch: 3 dl0 [51264/321526 (16%)] Loss: 1.998423; lr: 2.8873949720972353e-05; Time/iteration: 0.392m; Time so far/epoch: 0.627h
2024-05-01 19:38:03,874 - trainer - INFO - Train Epoch: 3 dl0 [51840/321526 (16%)] Loss: 1.958628; lr: 2.8868806722376925e-05; Time/iteration: 0.405m; Time so far/epoch: 0.634h
2024-05-01 19:38:28,457 - trainer - INFO - Train Epoch: 3 dl0 [52416/321526 (16%)] Loss: 1.925009; lr: 2.8863652470736583e-05; Time/iteration: 0.410m; Time so far/epoch: 0.641h
2024-05-01 19:38:53,088 - trainer - INFO - Train Epoch: 3 dl0 [52992/321526 (16%)] Loss: 2.001598; lr: 2.8858486970279172e-05; Time/iteration: 0.411m; Time so far/epoch: 0.648h
2024-05-01 19:39:17,412 - trainer - INFO - Train Epoch: 3 dl0 [53568/321526 (17%)] Loss: 2.025894; lr: 2.8853310225241766e-05; Time/iteration: 0.405m; Time so far/epoch: 0.654h
2024-05-01 19:39:40,878 - trainer - INFO - Train Epoch: 3 dl0 [54144/321526 (17%)] Loss: 1.882635; lr: 2.884812223987067e-05; Time/iteration: 0.391m; Time so far/epoch: 0.661h
2024-05-01 19:40:04,801 - trainer - INFO - Train Epoch: 3 dl0 [54720/321526 (17%)] Loss: 2.032688; lr: 2.8842923018421392e-05; Time/iteration: 0.399m; Time so far/epoch: 0.668h
2024-05-01 19:40:29,156 - trainer - INFO - Train Epoch: 3 dl0 [55296/321526 (17%)] Loss: 1.950456; lr: 2.883771256515867e-05; Time/iteration: 0.406m; Time so far/epoch: 0.674h
2024-05-01 19:40:53,581 - trainer - INFO - Train Epoch: 3 dl0 [55872/321526 (17%)] Loss: 1.952565; lr: 2.8832490884356456e-05; Time/iteration: 0.407m; Time so far/epoch: 0.681h
2024-05-01 19:41:17,522 - trainer - INFO - Train Epoch: 3 dl0 [56448/321526 (18%)] Loss: 1.928535; lr: 2.8827257980297905e-05; Time/iteration: 0.399m; Time so far/epoch: 0.688h
2024-05-01 19:41:41,149 - trainer - INFO - Train Epoch: 3 dl0 [57024/321526 (18%)] Loss: 2.055299; lr: 2.8822013857275376e-05; Time/iteration: 0.394m; Time so far/epoch: 0.694h
2024-05-01 19:42:05,199 - trainer - INFO - Train Epoch: 3 dl0 [57600/321526 (18%)] Loss: 2.086642; lr: 2.8816758519590444e-05; Time/iteration: 0.401m; Time so far/epoch: 0.701h
2024-05-01 19:42:29,580 - trainer - INFO - Train Epoch: 3 dl0 [58176/321526 (18%)] Loss: 2.059691; lr: 2.881149197155387e-05; Time/iteration: 0.406m; Time so far/epoch: 0.708h
2024-05-01 19:42:54,016 - trainer - INFO - Train Epoch: 3 dl0 [58752/321526 (18%)] Loss: 1.932028; lr: 2.880621421748561e-05; Time/iteration: 0.407m; Time so far/epoch: 0.715h
2024-05-01 19:43:19,116 - trainer - INFO - Train Epoch: 3 dl0 [59328/321526 (18%)] Loss: 2.001241; lr: 2.880092526171482e-05; Time/iteration: 0.418m; Time so far/epoch: 0.721h
2024-05-01 19:43:42,755 - trainer - INFO - Train Epoch: 3 dl0 [59904/321526 (19%)] Loss: 1.882509; lr: 2.879562510857984e-05; Time/iteration: 0.394m; Time so far/epoch: 0.728h
2024-05-01 19:44:06,845 - trainer - INFO - Train Epoch: 3 dl0 [60480/321526 (19%)] Loss: 1.841415; lr: 2.87903137624282e-05; Time/iteration: 0.401m; Time so far/epoch: 0.735h
2024-05-01 19:44:30,707 - trainer - INFO - Train Epoch: 3 dl0 [61056/321526 (19%)] Loss: 1.916933; lr: 2.8784991227616596e-05; Time/iteration: 0.398m; Time so far/epoch: 0.741h
2024-05-01 19:44:55,532 - trainer - INFO - Train Epoch: 3 dl0 [61632/321526 (19%)] Loss: 1.876386; lr: 2.877965750851092e-05; Time/iteration: 0.414m; Time so far/epoch: 0.748h
2024-05-01 19:45:19,789 - trainer - INFO - Train Epoch: 3 dl0 [62208/321526 (19%)] Loss: 2.018734; lr: 2.8774312609486236e-05; Time/iteration: 0.404m; Time so far/epoch: 0.755h
2024-05-01 19:45:43,634 - trainer - INFO - Train Epoch: 3 dl0 [62784/321526 (20%)] Loss: 1.830433; lr: 2.876895653492676e-05; Time/iteration: 0.397m; Time so far/epoch: 0.762h
2024-05-01 19:46:07,580 - trainer - INFO - Train Epoch: 3 dl0 [63360/321526 (20%)] Loss: 1.877515; lr: 2.876358928922589e-05; Time/iteration: 0.399m; Time so far/epoch: 0.768h
2024-05-01 19:46:31,193 - trainer - INFO - Train Epoch: 3 dl0 [63936/321526 (20%)] Loss: 1.958661; lr: 2.8758210876786195e-05; Time/iteration: 0.394m; Time so far/epoch: 0.775h
2024-05-01 19:46:55,080 - trainer - INFO - Train Epoch: 3 dl0 [64512/321526 (20%)] Loss: 1.849561; lr: 2.875282130201939e-05; Time/iteration: 0.398m; Time so far/epoch: 0.781h
2024-05-01 19:47:19,304 - trainer - INFO - Train Epoch: 3 dl0 [65088/321526 (20%)] Loss: 1.867483; lr: 2.874742056934634e-05; Time/iteration: 0.404m; Time so far/epoch: 0.788h
2024-05-01 19:47:43,596 - trainer - INFO - Train Epoch: 3 dl0 [65664/321526 (20%)] Loss: 2.078522; lr: 2.8742008683197086e-05; Time/iteration: 0.405m; Time so far/epoch: 0.795h
2024-05-01 19:48:08,169 - trainer - INFO - Train Epoch: 3 dl0 [66240/321526 (21%)] Loss: 1.842234; lr: 2.8736585648010797e-05; Time/iteration: 0.410m; Time so far/epoch: 0.802h
2024-05-01 19:48:32,218 - trainer - INFO - Train Epoch: 3 dl0 [66816/321526 (21%)] Loss: 1.862797; lr: 2.8731151468235795e-05; Time/iteration: 0.401m; Time so far/epoch: 0.808h
2024-05-01 19:48:56,303 - trainer - INFO - Train Epoch: 3 dl0 [67392/321526 (21%)] Loss: 2.025081; lr: 2.8725706148329538e-05; Time/iteration: 0.401m; Time so far/epoch: 0.815h
2024-05-01 19:49:20,112 - trainer - INFO - Train Epoch: 3 dl0 [67968/321526 (21%)] Loss: 1.978907; lr: 2.8720249692758636e-05; Time/iteration: 0.397m; Time so far/epoch: 0.822h
2024-05-01 19:49:45,448 - trainer - INFO - Train Epoch: 3 dl0 [68544/321526 (21%)] Loss: 1.865857; lr: 2.871478210599882e-05; Time/iteration: 0.422m; Time so far/epoch: 0.829h
2024-05-01 19:50:09,805 - trainer - INFO - Train Epoch: 3 dl0 [69120/321526 (21%)] Loss: 2.028730; lr: 2.870930339253495e-05; Time/iteration: 0.406m; Time so far/epoch: 0.836h
2024-05-01 19:50:34,318 - trainer - INFO - Train Epoch: 3 dl0 [69696/321526 (22%)] Loss: 1.935454; lr: 2.8703813556861025e-05; Time/iteration: 0.409m; Time so far/epoch: 0.842h
2024-05-01 19:50:58,649 - trainer - INFO - Train Epoch: 3 dl0 [70272/321526 (22%)] Loss: 1.946345; lr: 2.8698312603480155e-05; Time/iteration: 0.406m; Time so far/epoch: 0.849h
2024-05-01 19:51:22,735 - trainer - INFO - Train Epoch: 3 dl0 [70848/321526 (22%)] Loss: 1.952843; lr: 2.8692800536904577e-05; Time/iteration: 0.401m; Time so far/epoch: 0.856h
2024-05-01 19:51:47,655 - trainer - INFO - Train Epoch: 3 dl0 [71424/321526 (22%)] Loss: 2.046162; lr: 2.8687277361655648e-05; Time/iteration: 0.415m; Time so far/epoch: 0.863h
2024-05-01 19:52:13,004 - trainer - INFO - Train Epoch: 3 dl0 [72000/321526 (22%)] Loss: 2.042011; lr: 2.8681743082263817e-05; Time/iteration: 0.422m; Time so far/epoch: 0.870h
2024-05-01 19:52:37,740 - trainer - INFO - Train Epoch: 3 dl0 [72576/321526 (23%)] Loss: 1.944054; lr: 2.867619770326866e-05; Time/iteration: 0.412m; Time so far/epoch: 0.877h
2024-05-01 19:53:01,298 - trainer - INFO - Train Epoch: 3 dl0 [73152/321526 (23%)] Loss: 1.973797; lr: 2.8670641229218857e-05; Time/iteration: 0.393m; Time so far/epoch: 0.883h
2024-05-01 19:53:24,437 - trainer - INFO - Train Epoch: 3 dl0 [73728/321526 (23%)] Loss: 1.824921; lr: 2.8665073664672185e-05; Time/iteration: 0.386m; Time so far/epoch: 0.890h
2024-05-01 19:53:48,452 - trainer - INFO - Train Epoch: 3 dl0 [74304/321526 (23%)] Loss: 1.908728; lr: 2.8659495014195512e-05; Time/iteration: 0.400m; Time so far/epoch: 0.896h
2024-05-01 19:54:12,455 - trainer - INFO - Train Epoch: 3 dl0 [74880/321526 (23%)] Loss: 1.829763; lr: 2.8653905282364807e-05; Time/iteration: 0.400m; Time so far/epoch: 0.903h
2024-05-01 19:54:37,721 - trainer - INFO - Train Epoch: 3 dl0 [75456/321526 (23%)] Loss: 1.946069; lr: 2.8648304473765123e-05; Time/iteration: 0.421m; Time so far/epoch: 0.910h
2024-05-01 19:55:01,838 - trainer - INFO - Train Epoch: 3 dl0 [76032/321526 (24%)] Loss: 2.059892; lr: 2.864269259299061e-05; Time/iteration: 0.402m; Time so far/epoch: 0.917h
2024-05-01 19:55:26,049 - trainer - INFO - Train Epoch: 3 dl0 [76608/321526 (24%)] Loss: 1.918944; lr: 2.863706964464449e-05; Time/iteration: 0.404m; Time so far/epoch: 0.923h
2024-05-01 19:55:49,755 - trainer - INFO - Train Epoch: 3 dl0 [77184/321526 (24%)] Loss: 2.085606; lr: 2.8631435633339058e-05; Time/iteration: 0.395m; Time so far/epoch: 0.930h
2024-05-01 19:56:13,656 - trainer - INFO - Train Epoch: 3 dl0 [77760/321526 (24%)] Loss: 1.988726; lr: 2.8625790563695702e-05; Time/iteration: 0.398m; Time so far/epoch: 0.937h
2024-05-01 19:56:38,958 - trainer - INFO - Train Epoch: 3 dl0 [78336/321526 (24%)] Loss: 1.830774; lr: 2.862013444034486e-05; Time/iteration: 0.422m; Time so far/epoch: 0.944h
2024-05-01 19:57:03,761 - trainer - INFO - Train Epoch: 3 dl0 [78912/321526 (25%)] Loss: 1.947414; lr: 2.8614467267926054e-05; Time/iteration: 0.413m; Time so far/epoch: 0.951h
2024-05-01 19:57:28,069 - trainer - INFO - Train Epoch: 3 dl0 [79488/321526 (25%)] Loss: 1.931499; lr: 2.860878905108786e-05; Time/iteration: 0.405m; Time so far/epoch: 0.957h
2024-05-01 19:57:51,420 - trainer - INFO - Train Epoch: 3 dl0 [80064/321526 (25%)] Loss: 1.853295; lr: 2.860309979448792e-05; Time/iteration: 0.389m; Time so far/epoch: 0.964h
2024-05-01 19:58:15,092 - trainer - INFO - Train Epoch: 3 dl0 [80640/321526 (25%)] Loss: 1.961570; lr: 2.8597399502792922e-05; Time/iteration: 0.395m; Time so far/epoch: 0.970h
2024-05-01 19:58:38,737 - trainer - INFO - Train Epoch: 3 dl0 [81216/321526 (25%)] Loss: 1.912227; lr: 2.859168818067861e-05; Time/iteration: 0.394m; Time so far/epoch: 0.977h
2024-05-01 19:59:02,993 - trainer - INFO - Train Epoch: 3 dl0 [81792/321526 (25%)] Loss: 1.974577; lr: 2.8585965832829778e-05; Time/iteration: 0.404m; Time so far/epoch: 0.984h
2024-05-01 19:59:27,620 - trainer - INFO - Train Epoch: 3 dl0 [82368/321526 (26%)] Loss: 1.976853; lr: 2.8580232463940263e-05; Time/iteration: 0.410m; Time so far/epoch: 0.991h
2024-05-01 19:59:51,591 - trainer - INFO - Train Epoch: 3 dl0 [82944/321526 (26%)] Loss: 1.900944; lr: 2.857448807871294e-05; Time/iteration: 0.400m; Time so far/epoch: 0.997h
2024-05-01 20:00:15,720 - trainer - INFO - Train Epoch: 3 dl0 [83520/321526 (26%)] Loss: 1.961346; lr: 2.8568732681859727e-05; Time/iteration: 0.402m; Time so far/epoch: 1.004h
2024-05-01 20:00:39,444 - trainer - INFO - Train Epoch: 3 dl0 [84096/321526 (26%)] Loss: 1.956262; lr: 2.856296627810157e-05; Time/iteration: 0.395m; Time so far/epoch: 1.010h
2024-05-01 20:01:04,525 - trainer - INFO - Train Epoch: 3 dl0 [84672/321526 (26%)] Loss: 1.835564; lr: 2.8557188872168432e-05; Time/iteration: 0.418m; Time so far/epoch: 1.017h
2024-05-01 20:01:29,168 - trainer - INFO - Train Epoch: 3 dl0 [85248/321526 (27%)] Loss: 1.933814; lr: 2.8551400468799325e-05; Time/iteration: 0.411m; Time so far/epoch: 1.024h
2024-05-01 20:01:53,386 - trainer - INFO - Train Epoch: 3 dl0 [85824/321526 (27%)] Loss: 1.878644; lr: 2.8545601072742257e-05; Time/iteration: 0.404m; Time so far/epoch: 1.031h
2024-05-01 20:02:17,132 - trainer - INFO - Train Epoch: 3 dl0 [86400/321526 (27%)] Loss: 1.921510; lr: 2.8539790688754274e-05; Time/iteration: 0.396m; Time so far/epoch: 1.038h
2024-05-01 20:02:40,385 - trainer - INFO - Train Epoch: 3 dl0 [86976/321526 (27%)] Loss: 1.976667; lr: 2.8533969321601422e-05; Time/iteration: 0.388m; Time so far/epoch: 1.044h
2024-05-01 20:03:04,746 - trainer - INFO - Train Epoch: 3 dl0 [87552/321526 (27%)] Loss: 1.970802; lr: 2.852813697605876e-05; Time/iteration: 0.406m; Time so far/epoch: 1.051h
2024-05-01 20:03:28,135 - trainer - INFO - Train Epoch: 3 dl0 [88128/321526 (27%)] Loss: 2.082805; lr: 2.852229365691035e-05; Time/iteration: 0.390m; Time so far/epoch: 1.057h
2024-05-01 20:03:52,579 - trainer - INFO - Train Epoch: 3 dl0 [88704/321526 (28%)] Loss: 1.943396; lr: 2.851643936894926e-05; Time/iteration: 0.407m; Time so far/epoch: 1.064h
2024-05-01 20:04:17,565 - trainer - INFO - Train Epoch: 3 dl0 [89280/321526 (28%)] Loss: 1.959375; lr: 2.851057411697755e-05; Time/iteration: 0.416m; Time so far/epoch: 1.071h
2024-05-01 20:04:41,909 - trainer - INFO - Train Epoch: 3 dl0 [89856/321526 (28%)] Loss: 1.957030; lr: 2.8504697905806273e-05; Time/iteration: 0.406m; Time so far/epoch: 1.078h
2024-05-01 20:05:05,956 - trainer - INFO - Train Epoch: 3 dl0 [90432/321526 (28%)] Loss: 1.973299; lr: 2.8498810740255486e-05; Time/iteration: 0.401m; Time so far/epoch: 1.085h
2024-05-01 20:05:29,348 - trainer - INFO - Train Epoch: 3 dl0 [91008/321526 (28%)] Loss: 1.861104; lr: 2.84929126251542e-05; Time/iteration: 0.390m; Time so far/epoch: 1.091h
2024-05-01 20:05:53,907 - trainer - INFO - Train Epoch: 3 dl0 [91584/321526 (28%)] Loss: 1.875975; lr: 2.848700356534045e-05; Time/iteration: 0.409m; Time so far/epoch: 1.098h
2024-05-01 20:06:18,720 - trainer - INFO - Train Epoch: 3 dl0 [92160/321526 (29%)] Loss: 1.869936; lr: 2.8481083565661207e-05; Time/iteration: 0.414m; Time so far/epoch: 1.105h
2024-05-01 20:06:42,725 - trainer - INFO - Train Epoch: 3 dl0 [92736/321526 (29%)] Loss: 2.042538; lr: 2.8475152630972444e-05; Time/iteration: 0.400m; Time so far/epoch: 1.111h
2024-05-01 20:07:06,573 - trainer - INFO - Train Epoch: 3 dl0 [93312/321526 (29%)] Loss: 1.836113; lr: 2.846921076613909e-05; Time/iteration: 0.397m; Time so far/epoch: 1.118h
2024-05-01 20:07:30,996 - trainer - INFO - Train Epoch: 3 dl0 [93888/321526 (29%)] Loss: 1.839495; lr: 2.8463257976035043e-05; Time/iteration: 0.407m; Time so far/epoch: 1.125h
2024-05-01 20:07:56,112 - trainer - INFO - Train Epoch: 3 dl0 [94464/321526 (29%)] Loss: 1.968139; lr: 2.8457294265543172e-05; Time/iteration: 0.419m; Time so far/epoch: 1.132h
2024-05-01 20:08:20,411 - trainer - INFO - Train Epoch: 3 dl0 [95040/321526 (30%)] Loss: 2.000009; lr: 2.845131963955528e-05; Time/iteration: 0.405m; Time so far/epoch: 1.139h
2024-05-01 20:08:44,875 - trainer - INFO - Train Epoch: 3 dl0 [95616/321526 (30%)] Loss: 1.944141; lr: 2.8445334102972152e-05; Time/iteration: 0.408m; Time so far/epoch: 1.145h
2024-05-01 20:09:08,963 - trainer - INFO - Train Epoch: 3 dl0 [96192/321526 (30%)] Loss: 2.004802; lr: 2.8439337660703502e-05; Time/iteration: 0.401m; Time so far/epoch: 1.152h
2024-05-01 20:09:32,334 - trainer - INFO - Train Epoch: 3 dl0 [96768/321526 (30%)] Loss: 1.900809; lr: 2.8433330317667994e-05; Time/iteration: 0.390m; Time so far/epoch: 1.159h
2024-05-01 20:09:55,701 - trainer - INFO - Train Epoch: 3 dl0 [97344/321526 (30%)] Loss: 1.890651; lr: 2.8427312078793245e-05; Time/iteration: 0.389m; Time so far/epoch: 1.165h
2024-05-01 20:10:19,765 - trainer - INFO - Train Epoch: 3 dl0 [97920/321526 (30%)] Loss: 1.860726; lr: 2.842128294901579e-05; Time/iteration: 0.401m; Time so far/epoch: 1.172h
2024-05-01 20:10:44,611 - trainer - INFO - Train Epoch: 3 dl0 [98496/321526 (31%)] Loss: 2.087136; lr: 2.8415242933281115e-05; Time/iteration: 0.414m; Time so far/epoch: 1.179h
2024-05-01 20:11:09,282 - trainer - INFO - Train Epoch: 3 dl0 [99072/321526 (31%)] Loss: 1.829818; lr: 2.8409192036543624e-05; Time/iteration: 0.411m; Time so far/epoch: 1.185h
2024-05-01 20:11:33,958 - trainer - INFO - Train Epoch: 3 dl0 [99648/321526 (31%)] Loss: 1.806908; lr: 2.8403130263766654e-05; Time/iteration: 0.411m; Time so far/epoch: 1.192h
2024-05-01 20:15:08,714 - trainer - INFO - EgoClip_HOI epoch 3, Verb-Neg, Acc: 55.8;    EgoClip_HOI epoch 3, Noun-Neg, Acc: 69.0;    EgoClip_HOI epoch 3, HOI-Neg, Acc: 41.1;    
2024-05-01 20:15:08,723 - trainer - INFO -     epoch          : 3
2024-05-01 20:15:08,724 - trainer - INFO -     loss_0         : 0.6040729301903636
2024-05-01 20:15:08,724 - trainer - INFO -     val_loss_0     : 0.0
2024-05-01 20:15:08,724 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 55.81669616699219
2024-05-01 20:15:08,724 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 69.03156280517578
2024-05-01 20:15:08,724 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.10466384887695
2024-05-01 20:15:09,877 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch3.pth ...
2024-05-01 20:15:11,714 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-01 20:16:23,601 - trainer - INFO - Train Epoch: 4 dl0 [0/321526 (0%)] Loss: 2.016217; lr: 2.8400095300416846e-05; Time/iteration: 1.198m; Time so far/epoch: 0.020h
2024-05-01 20:16:55,989 - trainer - INFO - Train Epoch: 4 dl0 [576/321526 (0%)] Loss: 1.905378; lr: 2.839401722290642e-05; Time/iteration: 0.540m; Time so far/epoch: 0.029h
2024-05-01 20:17:21,437 - trainer - INFO - Train Epoch: 4 dl0 [1152/321526 (0%)] Loss: 1.981867; lr: 2.8387928281803863e-05; Time/iteration: 0.424m; Time so far/epoch: 0.036h
2024-05-01 20:17:48,402 - trainer - INFO - Train Epoch: 4 dl0 [1728/321526 (1%)] Loss: 1.924485; lr: 2.8381828482103726e-05; Time/iteration: 0.449m; Time so far/epoch: 0.044h
2024-05-01 20:18:18,800 - trainer - INFO - Train Epoch: 4 dl0 [2304/321526 (1%)] Loss: 1.978174; lr: 2.837571782880945e-05; Time/iteration: 0.507m; Time so far/epoch: 0.052h
2024-05-01 20:18:50,203 - trainer - INFO - Train Epoch: 4 dl0 [2880/321526 (1%)] Loss: 2.002578; lr: 2.836959632693339e-05; Time/iteration: 0.523m; Time so far/epoch: 0.061h
2024-05-01 20:19:15,885 - trainer - INFO - Train Epoch: 4 dl0 [3456/321526 (1%)] Loss: 1.953756; lr: 2.836346398149678e-05; Time/iteration: 0.428m; Time so far/epoch: 0.068h
2024-05-01 20:19:41,422 - trainer - INFO - Train Epoch: 4 dl0 [4032/321526 (1%)] Loss: 1.993565; lr: 2.8357320797529775e-05; Time/iteration: 0.425m; Time so far/epoch: 0.075h
2024-05-01 20:20:08,761 - trainer - INFO - Train Epoch: 4 dl0 [4608/321526 (1%)] Loss: 1.965250; lr: 2.8351166780071406e-05; Time/iteration: 0.456m; Time so far/epoch: 0.083h
2024-05-01 20:20:34,533 - trainer - INFO - Train Epoch: 4 dl0 [5184/321526 (2%)] Loss: 1.925479; lr: 2.8345001934169595e-05; Time/iteration: 0.429m; Time so far/epoch: 0.090h
2024-05-01 20:21:01,270 - trainer - INFO - Train Epoch: 4 dl0 [5760/321526 (2%)] Loss: 2.009488; lr: 2.8338826264881136e-05; Time/iteration: 0.445m; Time so far/epoch: 0.097h
2024-05-01 20:21:27,039 - trainer - INFO - Train Epoch: 4 dl0 [6336/321526 (2%)] Loss: 1.891851; lr: 2.8332639777271717e-05; Time/iteration: 0.429m; Time so far/epoch: 0.104h
2024-05-01 20:21:52,236 - trainer - INFO - Train Epoch: 4 dl0 [6912/321526 (2%)] Loss: 1.949677; lr: 2.832644247641589e-05; Time/iteration: 0.420m; Time so far/epoch: 0.111h
2024-05-01 20:22:18,063 - trainer - INFO - Train Epoch: 4 dl0 [7488/321526 (2%)] Loss: 1.936836; lr: 2.8320234367397078e-05; Time/iteration: 0.430m; Time so far/epoch: 0.118h
2024-05-01 20:22:42,621 - trainer - INFO - Train Epoch: 4 dl0 [8064/321526 (3%)] Loss: 1.952876; lr: 2.8314015455307563e-05; Time/iteration: 0.409m; Time so far/epoch: 0.125h
2024-05-01 20:23:07,255 - trainer - INFO - Train Epoch: 4 dl0 [8640/321526 (3%)] Loss: 1.942815; lr: 2.830778574524851e-05; Time/iteration: 0.411m; Time so far/epoch: 0.132h
2024-05-01 20:23:31,001 - trainer - INFO - Train Epoch: 4 dl0 [9216/321526 (3%)] Loss: 1.878864; lr: 2.8301545242329912e-05; Time/iteration: 0.396m; Time so far/epoch: 0.139h
2024-05-01 20:23:55,448 - trainer - INFO - Train Epoch: 4 dl0 [9792/321526 (3%)] Loss: 1.912002; lr: 2.829529395167064e-05; Time/iteration: 0.407m; Time so far/epoch: 0.145h
2024-05-01 20:24:20,193 - trainer - INFO - Train Epoch: 4 dl0 [10368/321526 (3%)] Loss: 2.052662; lr: 2.8289031878398402e-05; Time/iteration: 0.412m; Time so far/epoch: 0.152h
2024-05-01 20:24:43,781 - trainer - INFO - Train Epoch: 4 dl0 [10944/321526 (3%)] Loss: 1.982739; lr: 2.8282759027649748e-05; Time/iteration: 0.393m; Time so far/epoch: 0.159h
2024-05-01 20:25:08,796 - trainer - INFO - Train Epoch: 4 dl0 [11520/321526 (4%)] Loss: 2.031863; lr: 2.8276475404570072e-05; Time/iteration: 0.417m; Time so far/epoch: 0.166h
2024-05-01 20:25:31,993 - trainer - INFO - Train Epoch: 4 dl0 [12096/321526 (4%)] Loss: 1.879313; lr: 2.8270181014313607e-05; Time/iteration: 0.387m; Time so far/epoch: 0.172h
2024-05-01 20:25:56,289 - trainer - INFO - Train Epoch: 4 dl0 [12672/321526 (4%)] Loss: 1.963444; lr: 2.8263875862043415e-05; Time/iteration: 0.405m; Time so far/epoch: 0.179h
2024-05-01 20:26:20,748 - trainer - INFO - Train Epoch: 4 dl0 [13248/321526 (4%)] Loss: 1.872671; lr: 2.825755995293139e-05; Time/iteration: 0.407m; Time so far/epoch: 0.186h
2024-05-01 20:26:45,501 - trainer - INFO - Train Epoch: 4 dl0 [13824/321526 (4%)] Loss: 1.909607; lr: 2.825123329215824e-05; Time/iteration: 0.412m; Time so far/epoch: 0.193h
2024-05-01 20:27:11,321 - trainer - INFO - Train Epoch: 4 dl0 [14400/321526 (4%)] Loss: 1.880365; lr: 2.8244895884913495e-05; Time/iteration: 0.430m; Time so far/epoch: 0.200h
2024-05-01 20:27:35,107 - trainer - INFO - Train Epoch: 4 dl0 [14976/321526 (5%)] Loss: 1.939965; lr: 2.8238547736395512e-05; Time/iteration: 0.396m; Time so far/epoch: 0.206h
2024-05-01 20:27:59,104 - trainer - INFO - Train Epoch: 4 dl0 [15552/321526 (5%)] Loss: 1.863414; lr: 2.8232188851811444e-05; Time/iteration: 0.400m; Time so far/epoch: 0.213h
2024-05-01 20:28:22,156 - trainer - INFO - Train Epoch: 4 dl0 [16128/321526 (5%)] Loss: 2.010357; lr: 2.8225819236377258e-05; Time/iteration: 0.384m; Time so far/epoch: 0.220h
2024-05-01 20:28:45,607 - trainer - INFO - Train Epoch: 4 dl0 [16704/321526 (5%)] Loss: 1.962918; lr: 2.821943889531772e-05; Time/iteration: 0.391m; Time so far/epoch: 0.226h
2024-05-01 20:29:09,777 - trainer - INFO - Train Epoch: 4 dl0 [17280/321526 (5%)] Loss: 1.917893; lr: 2.8213047833866394e-05; Time/iteration: 0.403m; Time so far/epoch: 0.233h
2024-05-01 20:29:33,651 - trainer - INFO - Train Epoch: 4 dl0 [17856/321526 (6%)] Loss: 2.015323; lr: 2.820664605726564e-05; Time/iteration: 0.398m; Time so far/epoch: 0.239h
2024-05-01 20:29:59,095 - trainer - INFO - Train Epoch: 4 dl0 [18432/321526 (6%)] Loss: 2.009639; lr: 2.82002335707666e-05; Time/iteration: 0.424m; Time so far/epoch: 0.246h
2024-05-01 20:30:22,153 - trainer - INFO - Train Epoch: 4 dl0 [19008/321526 (6%)] Loss: 1.896004; lr: 2.8193810379629215e-05; Time/iteration: 0.384m; Time so far/epoch: 0.253h
2024-05-01 20:30:46,037 - trainer - INFO - Train Epoch: 4 dl0 [19584/321526 (6%)] Loss: 1.883825; lr: 2.8187376489122196e-05; Time/iteration: 0.398m; Time so far/epoch: 0.260h
2024-05-01 20:31:10,163 - trainer - INFO - Train Epoch: 4 dl0 [20160/321526 (6%)] Loss: 1.911195; lr: 2.818093190452303e-05; Time/iteration: 0.402m; Time so far/epoch: 0.266h
2024-05-01 20:31:34,670 - trainer - INFO - Train Epoch: 4 dl0 [20736/321526 (6%)] Loss: 1.987286; lr: 2.8174476631117978e-05; Time/iteration: 0.408m; Time so far/epoch: 0.273h
2024-05-01 20:32:00,019 - trainer - INFO - Train Epoch: 4 dl0 [21312/321526 (7%)] Loss: 1.950555; lr: 2.816801067420207e-05; Time/iteration: 0.422m; Time so far/epoch: 0.280h
2024-05-01 20:32:23,145 - trainer - INFO - Train Epoch: 4 dl0 [21888/321526 (7%)] Loss: 1.880173; lr: 2.81615340390791e-05; Time/iteration: 0.385m; Time so far/epoch: 0.287h
2024-05-01 20:32:47,345 - trainer - INFO - Train Epoch: 4 dl0 [22464/321526 (7%)] Loss: 1.892850; lr: 2.815504673106162e-05; Time/iteration: 0.403m; Time so far/epoch: 0.293h
2024-05-01 20:33:10,924 - trainer - INFO - Train Epoch: 4 dl0 [23040/321526 (7%)] Loss: 1.942793; lr: 2.8148548755470933e-05; Time/iteration: 0.393m; Time so far/epoch: 0.300h
2024-05-01 20:33:35,478 - trainer - INFO - Train Epoch: 4 dl0 [23616/321526 (7%)] Loss: 1.948191; lr: 2.8142040117637103e-05; Time/iteration: 0.409m; Time so far/epoch: 0.307h
2024-05-01 20:34:00,414 - trainer - INFO - Train Epoch: 4 dl0 [24192/321526 (8%)] Loss: 1.873257; lr: 2.813552082289892e-05; Time/iteration: 0.416m; Time so far/epoch: 0.314h
2024-05-01 20:34:24,133 - trainer - INFO - Train Epoch: 4 dl0 [24768/321526 (8%)] Loss: 1.975376; lr: 2.812899087660393e-05; Time/iteration: 0.395m; Time so far/epoch: 0.320h
2024-05-01 20:34:48,724 - trainer - INFO - Train Epoch: 4 dl0 [25344/321526 (8%)] Loss: 1.904902; lr: 2.812245028410842e-05; Time/iteration: 0.410m; Time so far/epoch: 0.327h
2024-05-01 20:35:12,322 - trainer - INFO - Train Epoch: 4 dl0 [25920/321526 (8%)] Loss: 2.002071; lr: 2.8115899050777406e-05; Time/iteration: 0.393m; Time so far/epoch: 0.334h
2024-05-01 20:35:37,255 - trainer - INFO - Train Epoch: 4 dl0 [26496/321526 (8%)] Loss: 1.963601; lr: 2.810933718198462e-05; Time/iteration: 0.416m; Time so far/epoch: 0.340h
2024-05-01 20:36:01,318 - trainer - INFO - Train Epoch: 4 dl0 [27072/321526 (8%)] Loss: 1.810631; lr: 2.810276468311253e-05; Time/iteration: 0.401m; Time so far/epoch: 0.347h
2024-05-01 20:36:25,244 - trainer - INFO - Train Epoch: 4 dl0 [27648/321526 (9%)] Loss: 1.970160; lr: 2.809618155955232e-05; Time/iteration: 0.399m; Time so far/epoch: 0.354h
2024-05-01 20:36:48,864 - trainer - INFO - Train Epoch: 4 dl0 [28224/321526 (9%)] Loss: 1.934273; lr: 2.80895878167039e-05; Time/iteration: 0.394m; Time so far/epoch: 0.360h
2024-05-01 20:37:12,358 - trainer - INFO - Train Epoch: 4 dl0 [28800/321526 (9%)] Loss: 1.908148; lr: 2.808298345997587e-05; Time/iteration: 0.392m; Time so far/epoch: 0.367h
2024-05-01 20:37:37,705 - trainer - INFO - Train Epoch: 4 dl0 [29376/321526 (9%)] Loss: 1.935087; lr: 2.807636849478555e-05; Time/iteration: 0.422m; Time so far/epoch: 0.374h
2024-05-01 20:38:01,722 - trainer - INFO - Train Epoch: 4 dl0 [29952/321526 (9%)] Loss: 1.891089; lr: 2.8069742926558958e-05; Time/iteration: 0.400m; Time so far/epoch: 0.381h
2024-05-01 20:38:26,552 - trainer - INFO - Train Epoch: 4 dl0 [30528/321526 (9%)] Loss: 2.012486; lr: 2.8063106760730812e-05; Time/iteration: 0.414m; Time so far/epoch: 0.387h
2024-05-01 20:38:50,464 - trainer - INFO - Train Epoch: 4 dl0 [31104/321526 (10%)] Loss: 1.944268; lr: 2.8056460002744518e-05; Time/iteration: 0.399m; Time so far/epoch: 0.394h
2024-05-01 20:39:14,125 - trainer - INFO - Train Epoch: 4 dl0 [31680/321526 (10%)] Loss: 1.864998; lr: 2.804980265805218e-05; Time/iteration: 0.394m; Time so far/epoch: 0.401h
2024-05-01 20:39:38,941 - trainer - INFO - Train Epoch: 4 dl0 [32256/321526 (10%)] Loss: 1.952139; lr: 2.8043134732114567e-05; Time/iteration: 0.414m; Time so far/epoch: 0.408h
2024-05-01 20:40:03,126 - trainer - INFO - Train Epoch: 4 dl0 [32832/321526 (10%)] Loss: 2.022135; lr: 2.803645623040115e-05; Time/iteration: 0.403m; Time so far/epoch: 0.414h
2024-05-01 20:40:27,814 - trainer - INFO - Train Epoch: 4 dl0 [33408/321526 (10%)] Loss: 1.969849; lr: 2.8029767158390055e-05; Time/iteration: 0.411m; Time so far/epoch: 0.421h
2024-05-01 20:40:50,703 - trainer - INFO - Train Epoch: 4 dl0 [33984/321526 (11%)] Loss: 1.900677; lr: 2.80230675215681e-05; Time/iteration: 0.381m; Time so far/epoch: 0.427h
2024-05-01 20:41:14,731 - trainer - INFO - Train Epoch: 4 dl0 [34560/321526 (11%)] Loss: 1.947012; lr: 2.8016357325430747e-05; Time/iteration: 0.400m; Time so far/epoch: 0.434h
2024-05-01 20:41:39,378 - trainer - INFO - Train Epoch: 4 dl0 [35136/321526 (11%)] Loss: 1.838877; lr: 2.8009636575482128e-05; Time/iteration: 0.411m; Time so far/epoch: 0.441h
2024-05-01 20:42:04,109 - trainer - INFO - Train Epoch: 4 dl0 [35712/321526 (11%)] Loss: 1.994959; lr: 2.8002905277235035e-05; Time/iteration: 0.412m; Time so far/epoch: 0.448h
2024-05-01 20:42:28,718 - trainer - INFO - Train Epoch: 4 dl0 [36288/321526 (11%)] Loss: 1.878506; lr: 2.7996163436210923e-05; Time/iteration: 0.410m; Time so far/epoch: 0.455h
2024-05-01 20:42:51,975 - trainer - INFO - Train Epoch: 4 dl0 [36864/321526 (11%)] Loss: 1.859784; lr: 2.7989411057939866e-05; Time/iteration: 0.388m; Time so far/epoch: 0.461h
2024-05-01 20:43:16,831 - trainer - INFO - Train Epoch: 4 dl0 [37440/321526 (12%)] Loss: 1.989666; lr: 2.79826481479606e-05; Time/iteration: 0.414m; Time so far/epoch: 0.468h
2024-05-01 20:43:41,080 - trainer - INFO - Train Epoch: 4 dl0 [38016/321526 (12%)] Loss: 1.912770; lr: 2.7975874711820502e-05; Time/iteration: 0.404m; Time so far/epoch: 0.475h
2024-05-01 20:44:05,871 - trainer - INFO - Train Epoch: 4 dl0 [38592/321526 (12%)] Loss: 1.885958; lr: 2.7969090755075577e-05; Time/iteration: 0.413m; Time so far/epoch: 0.482h
2024-05-01 20:44:30,567 - trainer - INFO - Train Epoch: 4 dl0 [39168/321526 (12%)] Loss: 1.864985; lr: 2.796229628329046e-05; Time/iteration: 0.412m; Time so far/epoch: 0.489h
2024-05-01 20:44:54,335 - trainer - INFO - Train Epoch: 4 dl0 [39744/321526 (12%)] Loss: 1.984294; lr: 2.795549130203842e-05; Time/iteration: 0.396m; Time so far/epoch: 0.495h
2024-05-01 20:45:18,283 - trainer - INFO - Train Epoch: 4 dl0 [40320/321526 (13%)] Loss: 1.978793; lr: 2.7948675816901326e-05; Time/iteration: 0.399m; Time so far/epoch: 0.502h
2024-05-01 20:45:41,440 - trainer - INFO - Train Epoch: 4 dl0 [40896/321526 (13%)] Loss: 1.908146; lr: 2.7941849833469688e-05; Time/iteration: 0.386m; Time so far/epoch: 0.508h
2024-05-01 20:46:05,202 - trainer - INFO - Train Epoch: 4 dl0 [41472/321526 (13%)] Loss: 1.957368; lr: 2.7935013357342606e-05; Time/iteration: 0.396m; Time so far/epoch: 0.515h
2024-05-01 20:46:28,748 - trainer - INFO - Train Epoch: 4 dl0 [42048/321526 (13%)] Loss: 2.003856; lr: 2.7928166394127803e-05; Time/iteration: 0.392m; Time so far/epoch: 0.521h
2024-05-01 20:46:53,465 - trainer - INFO - Train Epoch: 4 dl0 [42624/321526 (13%)] Loss: 1.907236; lr: 2.7921308949441597e-05; Time/iteration: 0.412m; Time so far/epoch: 0.528h
2024-05-01 20:47:18,165 - trainer - INFO - Train Epoch: 4 dl0 [43200/321526 (13%)] Loss: 1.905041; lr: 2.7914441028908896e-05; Time/iteration: 0.412m; Time so far/epoch: 0.535h
2024-05-01 20:47:41,868 - trainer - INFO - Train Epoch: 4 dl0 [43776/321526 (14%)] Loss: 1.795824; lr: 2.7907562638163214e-05; Time/iteration: 0.395m; Time so far/epoch: 0.542h
2024-05-01 20:48:05,991 - trainer - INFO - Train Epoch: 4 dl0 [44352/321526 (14%)] Loss: 1.907004; lr: 2.7900673782846652e-05; Time/iteration: 0.402m; Time so far/epoch: 0.548h
2024-05-01 20:48:29,211 - trainer - INFO - Train Epoch: 4 dl0 [44928/321526 (14%)] Loss: 1.860284; lr: 2.7893774468609885e-05; Time/iteration: 0.387m; Time so far/epoch: 0.555h
2024-05-01 20:48:53,536 - trainer - INFO - Train Epoch: 4 dl0 [45504/321526 (14%)] Loss: 1.923465; lr: 2.7886864701112176e-05; Time/iteration: 0.405m; Time so far/epoch: 0.562h
2024-05-01 20:49:17,805 - trainer - INFO - Train Epoch: 4 dl0 [46080/321526 (14%)] Loss: 2.009924; lr: 2.7879944486021357e-05; Time/iteration: 0.404m; Time so far/epoch: 0.568h
2024-05-01 20:49:41,857 - trainer - INFO - Train Epoch: 4 dl0 [46656/321526 (15%)] Loss: 1.955182; lr: 2.7873013829013834e-05; Time/iteration: 0.401m; Time so far/epoch: 0.575h
2024-05-01 20:50:06,499 - trainer - INFO - Train Epoch: 4 dl0 [47232/321526 (15%)] Loss: 1.924671; lr: 2.7866072735774574e-05; Time/iteration: 0.411m; Time so far/epoch: 0.582h
2024-05-01 20:50:30,083 - trainer - INFO - Train Epoch: 4 dl0 [47808/321526 (15%)] Loss: 2.024791; lr: 2.7859121211997107e-05; Time/iteration: 0.393m; Time so far/epoch: 0.588h
2024-05-01 20:50:54,569 - trainer - INFO - Train Epoch: 4 dl0 [48384/321526 (15%)] Loss: 1.963473; lr: 2.7852159263383525e-05; Time/iteration: 0.408m; Time so far/epoch: 0.595h
2024-05-01 20:51:19,223 - trainer - INFO - Train Epoch: 4 dl0 [48960/321526 (15%)] Loss: 1.935052; lr: 2.7845186895644457e-05; Time/iteration: 0.411m; Time so far/epoch: 0.602h
2024-05-01 20:51:43,315 - trainer - INFO - Train Epoch: 4 dl0 [49536/321526 (15%)] Loss: 1.999312; lr: 2.783820411449909e-05; Time/iteration: 0.402m; Time so far/epoch: 0.609h
2024-05-01 20:52:07,385 - trainer - INFO - Train Epoch: 4 dl0 [50112/321526 (16%)] Loss: 1.904046; lr: 2.7831210925675145e-05; Time/iteration: 0.401m; Time so far/epoch: 0.615h
2024-05-01 20:52:31,185 - trainer - INFO - Train Epoch: 4 dl0 [50688/321526 (16%)] Loss: 1.989962; lr: 2.782420733490889e-05; Time/iteration: 0.397m; Time so far/epoch: 0.622h
2024-05-01 20:52:56,628 - trainer - INFO - Train Epoch: 4 dl0 [51264/321526 (16%)] Loss: 1.920050; lr: 2.7817193347945108e-05; Time/iteration: 0.424m; Time so far/epoch: 0.629h
2024-05-01 20:53:20,547 - trainer - INFO - Train Epoch: 4 dl0 [51840/321526 (16%)] Loss: 2.043680; lr: 2.7810168970537137e-05; Time/iteration: 0.399m; Time so far/epoch: 0.636h
2024-05-01 20:53:44,962 - trainer - INFO - Train Epoch: 4 dl0 [52416/321526 (16%)] Loss: 1.874085; lr: 2.7803134208446807e-05; Time/iteration: 0.407m; Time so far/epoch: 0.643h
2024-05-01 20:54:08,889 - trainer - INFO - Train Epoch: 4 dl0 [52992/321526 (16%)] Loss: 1.844574; lr: 2.779608906744449e-05; Time/iteration: 0.399m; Time so far/epoch: 0.649h
2024-05-01 20:54:32,837 - trainer - INFO - Train Epoch: 4 dl0 [53568/321526 (17%)] Loss: 1.804350; lr: 2.7789033553309058e-05; Time/iteration: 0.399m; Time so far/epoch: 0.656h
2024-05-01 20:54:57,665 - trainer - INFO - Train Epoch: 4 dl0 [54144/321526 (17%)] Loss: 1.883742; lr: 2.7781967671827898e-05; Time/iteration: 0.414m; Time so far/epoch: 0.663h
2024-05-01 20:55:21,798 - trainer - INFO - Train Epoch: 4 dl0 [54720/321526 (17%)] Loss: 1.786703; lr: 2.77748914287969e-05; Time/iteration: 0.402m; Time so far/epoch: 0.669h
2024-05-01 20:55:46,418 - trainer - INFO - Train Epoch: 4 dl0 [55296/321526 (17%)] Loss: 1.950818; lr: 2.7767804830020453e-05; Time/iteration: 0.410m; Time so far/epoch: 0.676h
2024-05-01 20:56:10,072 - trainer - INFO - Train Epoch: 4 dl0 [55872/321526 (17%)] Loss: 1.975921; lr: 2.776070788131143e-05; Time/iteration: 0.394m; Time so far/epoch: 0.683h
2024-05-01 20:56:33,670 - trainer - INFO - Train Epoch: 4 dl0 [56448/321526 (18%)] Loss: 1.776581; lr: 2.775360058849122e-05; Time/iteration: 0.393m; Time so far/epoch: 0.689h
2024-05-01 20:56:57,956 - trainer - INFO - Train Epoch: 4 dl0 [57024/321526 (18%)] Loss: 1.904949; lr: 2.774648295738967e-05; Time/iteration: 0.405m; Time so far/epoch: 0.696h
2024-05-01 20:57:22,183 - trainer - INFO - Train Epoch: 4 dl0 [57600/321526 (18%)] Loss: 1.858010; lr: 2.773935499384511e-05; Time/iteration: 0.404m; Time so far/epoch: 0.703h
2024-05-01 20:57:47,091 - trainer - INFO - Train Epoch: 4 dl0 [58176/321526 (18%)] Loss: 1.865525; lr: 2.7732216703704367e-05; Time/iteration: 0.415m; Time so far/epoch: 0.710h
2024-05-01 20:58:11,188 - trainer - INFO - Train Epoch: 4 dl0 [58752/321526 (18%)] Loss: 1.908075; lr: 2.7725068092822718e-05; Time/iteration: 0.402m; Time so far/epoch: 0.717h
2024-05-01 20:58:35,419 - trainer - INFO - Train Epoch: 4 dl0 [59328/321526 (18%)] Loss: 1.929037; lr: 2.7717909167063916e-05; Time/iteration: 0.404m; Time so far/epoch: 0.723h
2024-05-01 20:58:58,611 - trainer - INFO - Train Epoch: 4 dl0 [59904/321526 (19%)] Loss: 1.889807; lr: 2.7710739932300165e-05; Time/iteration: 0.387m; Time so far/epoch: 0.730h
2024-05-01 20:59:22,310 - trainer - INFO - Train Epoch: 4 dl0 [60480/321526 (19%)] Loss: 1.936196; lr: 2.770356039441213e-05; Time/iteration: 0.395m; Time so far/epoch: 0.736h
2024-05-01 20:59:46,148 - trainer - INFO - Train Epoch: 4 dl0 [61056/321526 (19%)] Loss: 1.920053; lr: 2.7696370559288936e-05; Time/iteration: 0.397m; Time so far/epoch: 0.743h
2024-05-01 21:00:11,070 - trainer - INFO - Train Epoch: 4 dl0 [61632/321526 (19%)] Loss: 1.783837; lr: 2.768917043282814e-05; Time/iteration: 0.415m; Time so far/epoch: 0.750h
2024-05-01 21:00:35,834 - trainer - INFO - Train Epoch: 4 dl0 [62208/321526 (19%)] Loss: 1.862318; lr: 2.768196002093576e-05; Time/iteration: 0.413m; Time so far/epoch: 0.757h
2024-05-01 21:00:58,815 - trainer - INFO - Train Epoch: 4 dl0 [62784/321526 (20%)] Loss: 1.936095; lr: 2.7674739329526216e-05; Time/iteration: 0.383m; Time so far/epoch: 0.763h
2024-05-01 21:01:22,550 - trainer - INFO - Train Epoch: 4 dl0 [63360/321526 (20%)] Loss: 1.959023; lr: 2.7667508364522402e-05; Time/iteration: 0.396m; Time so far/epoch: 0.770h
2024-05-01 21:01:46,549 - trainer - INFO - Train Epoch: 4 dl0 [63936/321526 (20%)] Loss: 1.948354; lr: 2.7660267131855606e-05; Time/iteration: 0.400m; Time so far/epoch: 0.776h
2024-05-01 21:02:11,321 - trainer - INFO - Train Epoch: 4 dl0 [64512/321526 (20%)] Loss: 1.868330; lr: 2.765301563746556e-05; Time/iteration: 0.413m; Time so far/epoch: 0.783h
2024-05-01 21:02:35,481 - trainer - INFO - Train Epoch: 4 dl0 [65088/321526 (20%)] Loss: 1.937210; lr: 2.7645753887300403e-05; Time/iteration: 0.403m; Time so far/epoch: 0.790h
2024-05-01 21:02:58,811 - trainer - INFO - Train Epoch: 4 dl0 [65664/321526 (20%)] Loss: 1.992117; lr: 2.763848188731668e-05; Time/iteration: 0.389m; Time so far/epoch: 0.796h
2024-05-01 21:03:22,635 - trainer - INFO - Train Epoch: 4 dl0 [66240/321526 (21%)] Loss: 1.883889; lr: 2.7631199643479364e-05; Time/iteration: 0.397m; Time so far/epoch: 0.803h
2024-05-01 21:03:46,465 - trainer - INFO - Train Epoch: 4 dl0 [66816/321526 (21%)] Loss: 1.783996; lr: 2.7623907161761813e-05; Time/iteration: 0.397m; Time so far/epoch: 0.810h
2024-05-01 21:04:11,349 - trainer - INFO - Train Epoch: 4 dl0 [67392/321526 (21%)] Loss: 1.840292; lr: 2.7616604448145786e-05; Time/iteration: 0.415m; Time so far/epoch: 0.817h
2024-05-01 21:04:35,788 - trainer - INFO - Train Epoch: 4 dl0 [67968/321526 (21%)] Loss: 1.825648; lr: 2.760929150862144e-05; Time/iteration: 0.407m; Time so far/epoch: 0.823h
2024-05-01 21:04:59,800 - trainer - INFO - Train Epoch: 4 dl0 [68544/321526 (21%)] Loss: 2.020136; lr: 2.7601968349187317e-05; Time/iteration: 0.400m; Time so far/epoch: 0.830h
2024-05-01 21:05:24,541 - trainer - INFO - Train Epoch: 4 dl0 [69120/321526 (21%)] Loss: 1.926833; lr: 2.7594634975850336e-05; Time/iteration: 0.412m; Time so far/epoch: 0.837h
2024-05-01 21:05:47,933 - trainer - INFO - Train Epoch: 4 dl0 [69696/321526 (22%)] Loss: 1.851792; lr: 2.7587291394625807e-05; Time/iteration: 0.390m; Time so far/epoch: 0.843h
2024-05-01 21:06:13,011 - trainer - INFO - Train Epoch: 4 dl0 [70272/321526 (22%)] Loss: 1.920990; lr: 2.7579937611537403e-05; Time/iteration: 0.418m; Time so far/epoch: 0.850h
2024-05-01 21:06:37,732 - trainer - INFO - Train Epoch: 4 dl0 [70848/321526 (22%)] Loss: 1.895916; lr: 2.757257363261717e-05; Time/iteration: 0.412m; Time so far/epoch: 0.857h
2024-05-01 21:07:02,480 - trainer - INFO - Train Epoch: 4 dl0 [71424/321526 (22%)] Loss: 1.922843; lr: 2.756519946390551e-05; Time/iteration: 0.412m; Time so far/epoch: 0.864h
2024-05-01 21:07:26,062 - trainer - INFO - Train Epoch: 4 dl0 [72000/321526 (22%)] Loss: 1.900508; lr: 2.7557815111451196e-05; Time/iteration: 0.393m; Time so far/epoch: 0.871h
2024-05-01 21:07:50,023 - trainer - INFO - Train Epoch: 4 dl0 [72576/321526 (23%)] Loss: 1.819733; lr: 2.755042058131135e-05; Time/iteration: 0.399m; Time so far/epoch: 0.877h
2024-05-01 21:08:15,552 - trainer - INFO - Train Epoch: 4 dl0 [73152/321526 (23%)] Loss: 1.991308; lr: 2.754301587955143e-05; Time/iteration: 0.425m; Time so far/epoch: 0.884h
2024-05-01 21:08:39,091 - trainer - INFO - Train Epoch: 4 dl0 [73728/321526 (23%)] Loss: 1.958407; lr: 2.7535601012245258e-05; Time/iteration: 0.392m; Time so far/epoch: 0.891h
2024-05-01 21:09:03,340 - trainer - INFO - Train Epoch: 4 dl0 [74304/321526 (23%)] Loss: 1.970959; lr: 2.7528175985474973e-05; Time/iteration: 0.404m; Time so far/epoch: 0.898h
2024-05-01 21:09:26,587 - trainer - INFO - Train Epoch: 4 dl0 [74880/321526 (23%)] Loss: 1.922711; lr: 2.752074080533106e-05; Time/iteration: 0.387m; Time so far/epoch: 0.904h
2024-05-01 21:09:51,225 - trainer - INFO - Train Epoch: 4 dl0 [75456/321526 (23%)] Loss: 1.969187; lr: 2.7513295477912336e-05; Time/iteration: 0.411m; Time so far/epoch: 0.911h
2024-05-01 21:10:15,673 - trainer - INFO - Train Epoch: 4 dl0 [76032/321526 (24%)] Loss: 1.965718; lr: 2.7505840009325937e-05; Time/iteration: 0.407m; Time so far/epoch: 0.918h
2024-05-01 21:10:39,407 - trainer - INFO - Train Epoch: 4 dl0 [76608/321526 (24%)] Loss: 1.902384; lr: 2.749837440568731e-05; Time/iteration: 0.396m; Time so far/epoch: 0.924h
2024-05-01 21:11:04,307 - trainer - INFO - Train Epoch: 4 dl0 [77184/321526 (24%)] Loss: 1.860126; lr: 2.7490898673120226e-05; Time/iteration: 0.415m; Time so far/epoch: 0.931h
2024-05-01 21:11:27,676 - trainer - INFO - Train Epoch: 4 dl0 [77760/321526 (24%)] Loss: 1.980440; lr: 2.7483412817756756e-05; Time/iteration: 0.389m; Time so far/epoch: 0.938h
2024-05-01 21:11:51,518 - trainer - INFO - Train Epoch: 4 dl0 [78336/321526 (24%)] Loss: 1.833439; lr: 2.7475916845737278e-05; Time/iteration: 0.397m; Time so far/epoch: 0.944h
2024-05-01 21:12:16,013 - trainer - INFO - Train Epoch: 4 dl0 [78912/321526 (25%)] Loss: 2.012372; lr: 2.7468410763210475e-05; Time/iteration: 0.408m; Time so far/epoch: 0.951h
2024-05-01 21:12:41,142 - trainer - INFO - Train Epoch: 4 dl0 [79488/321526 (25%)] Loss: 1.941174; lr: 2.7460894576333317e-05; Time/iteration: 0.419m; Time so far/epoch: 0.958h
2024-05-01 21:13:06,392 - trainer - INFO - Train Epoch: 4 dl0 [80064/321526 (25%)] Loss: 1.993588; lr: 2.7453368291271055e-05; Time/iteration: 0.421m; Time so far/epoch: 0.965h
2024-05-01 21:13:30,215 - trainer - INFO - Train Epoch: 4 dl0 [80640/321526 (25%)] Loss: 1.768211; lr: 2.7445831914197238e-05; Time/iteration: 0.397m; Time so far/epoch: 0.972h
2024-05-01 21:13:54,124 - trainer - INFO - Train Epoch: 4 dl0 [81216/321526 (25%)] Loss: 1.905087; lr: 2.7438285451293683e-05; Time/iteration: 0.398m; Time so far/epoch: 0.978h
2024-05-01 21:14:17,902 - trainer - INFO - Train Epoch: 4 dl0 [81792/321526 (25%)] Loss: 1.919517; lr: 2.743072890875048e-05; Time/iteration: 0.396m; Time so far/epoch: 0.985h
2024-05-01 21:14:42,495 - trainer - INFO - Train Epoch: 4 dl0 [82368/321526 (26%)] Loss: 1.902263; lr: 2.7423162292765996e-05; Time/iteration: 0.410m; Time so far/epoch: 0.992h
2024-05-01 21:15:06,906 - trainer - INFO - Train Epoch: 4 dl0 [82944/321526 (26%)] Loss: 1.795201; lr: 2.7415585609546845e-05; Time/iteration: 0.407m; Time so far/epoch: 0.999h
2024-05-01 21:15:30,893 - trainer - INFO - Train Epoch: 4 dl0 [83520/321526 (26%)] Loss: 1.902499; lr: 2.740799886530792e-05; Time/iteration: 0.400m; Time so far/epoch: 1.005h
2024-05-01 21:15:55,064 - trainer - INFO - Train Epoch: 4 dl0 [84096/321526 (26%)] Loss: 1.963244; lr: 2.740040206627235e-05; Time/iteration: 0.403m; Time so far/epoch: 1.012h
2024-05-01 21:16:18,719 - trainer - INFO - Train Epoch: 4 dl0 [84672/321526 (26%)] Loss: 1.910293; lr: 2.7392795218671512e-05; Time/iteration: 0.394m; Time so far/epoch: 1.019h
2024-05-01 21:16:43,088 - trainer - INFO - Train Epoch: 4 dl0 [85248/321526 (27%)] Loss: 1.927976; lr: 2.7385178328745037e-05; Time/iteration: 0.406m; Time so far/epoch: 1.025h
2024-05-01 21:17:07,541 - trainer - INFO - Train Epoch: 4 dl0 [85824/321526 (27%)] Loss: 2.009743; lr: 2.737755140274078e-05; Time/iteration: 0.408m; Time so far/epoch: 1.032h
2024-05-01 21:17:32,790 - trainer - INFO - Train Epoch: 4 dl0 [86400/321526 (27%)] Loss: 1.941402; lr: 2.7369914446914843e-05; Time/iteration: 0.421m; Time so far/epoch: 1.039h
2024-05-01 21:17:56,326 - trainer - INFO - Train Epoch: 4 dl0 [86976/321526 (27%)] Loss: 1.997851; lr: 2.7362267467531538e-05; Time/iteration: 0.392m; Time so far/epoch: 1.046h
2024-05-01 21:18:19,876 - trainer - INFO - Train Epoch: 4 dl0 [87552/321526 (27%)] Loss: 1.943794; lr: 2.7354610470863414e-05; Time/iteration: 0.392m; Time so far/epoch: 1.052h
2024-05-01 21:18:44,360 - trainer - INFO - Train Epoch: 4 dl0 [88128/321526 (27%)] Loss: 2.073220; lr: 2.7346943463191234e-05; Time/iteration: 0.408m; Time so far/epoch: 1.059h
2024-05-01 21:19:08,259 - trainer - INFO - Train Epoch: 4 dl0 [88704/321526 (28%)] Loss: 1.988489; lr: 2.733926645080396e-05; Time/iteration: 0.398m; Time so far/epoch: 1.066h
2024-05-01 21:19:33,053 - trainer - INFO - Train Epoch: 4 dl0 [89280/321526 (28%)] Loss: 1.936855; lr: 2.733157943999877e-05; Time/iteration: 0.413m; Time so far/epoch: 1.073h
2024-05-01 21:19:57,354 - trainer - INFO - Train Epoch: 4 dl0 [89856/321526 (28%)] Loss: 1.860407; lr: 2.7323882437081054e-05; Time/iteration: 0.405m; Time so far/epoch: 1.079h
2024-05-01 21:20:20,851 - trainer - INFO - Train Epoch: 4 dl0 [90432/321526 (28%)] Loss: 1.887748; lr: 2.7316175448364374e-05; Time/iteration: 0.392m; Time so far/epoch: 1.086h
2024-05-01 21:20:45,142 - trainer - INFO - Train Epoch: 4 dl0 [91008/321526 (28%)] Loss: 2.003643; lr: 2.7308458480170502e-05; Time/iteration: 0.405m; Time so far/epoch: 1.093h
2024-05-01 21:21:08,990 - trainer - INFO - Train Epoch: 4 dl0 [91584/321526 (28%)] Loss: 1.983227; lr: 2.7300731538829397e-05; Time/iteration: 0.397m; Time so far/epoch: 1.099h
2024-05-01 21:21:33,811 - trainer - INFO - Train Epoch: 4 dl0 [92160/321526 (29%)] Loss: 1.979731; lr: 2.7292994630679182e-05; Time/iteration: 0.414m; Time so far/epoch: 1.106h
2024-05-01 21:21:58,305 - trainer - INFO - Train Epoch: 4 dl0 [92736/321526 (29%)] Loss: 2.010926; lr: 2.7285247762066167e-05; Time/iteration: 0.408m; Time so far/epoch: 1.113h
2024-05-01 21:22:22,768 - trainer - INFO - Train Epoch: 4 dl0 [93312/321526 (29%)] Loss: 1.924690; lr: 2.7277490939344838e-05; Time/iteration: 0.408m; Time so far/epoch: 1.120h
2024-05-01 21:22:46,313 - trainer - INFO - Train Epoch: 4 dl0 [93888/321526 (29%)] Loss: 1.832651; lr: 2.7269724168877827e-05; Time/iteration: 0.392m; Time so far/epoch: 1.126h
2024-05-01 21:23:10,026 - trainer - INFO - Train Epoch: 4 dl0 [94464/321526 (29%)] Loss: 1.931096; lr: 2.7261947457035945e-05; Time/iteration: 0.395m; Time so far/epoch: 1.133h
2024-05-01 21:23:34,239 - trainer - INFO - Train Epoch: 4 dl0 [95040/321526 (30%)] Loss: 1.839723; lr: 2.7254160810198145e-05; Time/iteration: 0.404m; Time so far/epoch: 1.140h
2024-05-01 21:23:58,450 - trainer - INFO - Train Epoch: 4 dl0 [95616/321526 (30%)] Loss: 1.828233; lr: 2.7246364234751534e-05; Time/iteration: 0.404m; Time so far/epoch: 1.146h
2024-05-01 21:24:23,105 - trainer - INFO - Train Epoch: 4 dl0 [96192/321526 (30%)] Loss: 1.933357; lr: 2.7238557737091374e-05; Time/iteration: 0.411m; Time so far/epoch: 1.153h
2024-05-01 21:24:47,181 - trainer - INFO - Train Epoch: 4 dl0 [96768/321526 (30%)] Loss: 1.958076; lr: 2.723074132362104e-05; Time/iteration: 0.401m; Time so far/epoch: 1.160h
2024-05-01 21:25:11,080 - trainer - INFO - Train Epoch: 4 dl0 [97344/321526 (30%)] Loss: 1.949905; lr: 2.722291500075206e-05; Time/iteration: 0.398m; Time so far/epoch: 1.166h
2024-05-01 21:25:35,475 - trainer - INFO - Train Epoch: 4 dl0 [97920/321526 (30%)] Loss: 1.999421; lr: 2.7215078774904087e-05; Time/iteration: 0.406m; Time so far/epoch: 1.173h
2024-05-01 21:25:59,451 - trainer - INFO - Train Epoch: 4 dl0 [98496/321526 (31%)] Loss: 1.868728; lr: 2.7207232652504906e-05; Time/iteration: 0.400m; Time so far/epoch: 1.180h
2024-05-01 21:26:24,172 - trainer - INFO - Train Epoch: 4 dl0 [99072/321526 (31%)] Loss: 1.867062; lr: 2.719937663999039e-05; Time/iteration: 0.412m; Time so far/epoch: 1.187h
2024-05-01 21:26:47,936 - trainer - INFO - Train Epoch: 4 dl0 [99648/321526 (31%)] Loss: 1.913491; lr: 2.719151074380456e-05; Time/iteration: 0.396m; Time so far/epoch: 1.193h
2024-05-01 21:30:26,382 - trainer - INFO - EgoClip_HOI epoch 4, Verb-Neg, Acc: 56.0;    EgoClip_HOI epoch 4, Noun-Neg, Acc: 68.9;    EgoClip_HOI epoch 4, HOI-Neg, Acc: 41.4;    
2024-05-01 21:30:26,391 - trainer - INFO -     epoch          : 4
2024-05-01 21:30:26,392 - trainer - INFO -     loss_0         : 0.6013150838421857
2024-05-01 21:30:26,392 - trainer - INFO -     val_loss_0     : 0.0
2024-05-01 21:30:26,392 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 55.95832443237305
2024-05-01 21:30:26,392 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 68.86970520019531
2024-05-01 21:30:26,392 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.36431121826172
2024-05-01 21:30:27,530 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch4.pth ...
2024-05-01 21:30:29,525 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-01 21:31:38,844 - trainer - INFO - Train Epoch: 5 dl0 [0/321526 (0%)] Loss: 1.943326; lr: 2.718757409135087e-05; Time/iteration: 1.155m; Time so far/epoch: 0.019h
2024-05-01 21:32:05,211 - trainer - INFO - Train Epoch: 5 dl0 [576/321526 (0%)] Loss: 1.989958; lr: 2.71796933817583e-05; Time/iteration: 0.439m; Time so far/epoch: 0.027h
2024-05-01 21:32:36,327 - trainer - INFO - Train Epoch: 5 dl0 [1152/321526 (0%)] Loss: 1.858193; lr: 2.7171802804639882e-05; Time/iteration: 0.519m; Time so far/epoch: 0.035h
2024-05-01 21:33:04,028 - trainer - INFO - Train Epoch: 5 dl0 [1728/321526 (1%)] Loss: 1.931287; lr: 2.716390236646797e-05; Time/iteration: 0.462m; Time so far/epoch: 0.043h
2024-05-01 21:33:35,712 - trainer - INFO - Train Epoch: 5 dl0 [2304/321526 (1%)] Loss: 1.881938; lr: 2.7155992073723014e-05; Time/iteration: 0.528m; Time so far/epoch: 0.052h
2024-05-01 21:34:02,096 - trainer - INFO - Train Epoch: 5 dl0 [2880/321526 (1%)] Loss: 1.993720; lr: 2.7148071932893542e-05; Time/iteration: 0.440m; Time so far/epoch: 0.059h
2024-05-01 21:34:29,053 - trainer - INFO - Train Epoch: 5 dl0 [3456/321526 (1%)] Loss: 1.901155; lr: 2.714014195047616e-05; Time/iteration: 0.449m; Time so far/epoch: 0.067h
2024-05-01 21:34:56,499 - trainer - INFO - Train Epoch: 5 dl0 [4032/321526 (1%)] Loss: 1.930345; lr: 2.713220213297555e-05; Time/iteration: 0.457m; Time so far/epoch: 0.074h
2024-05-01 21:35:22,551 - trainer - INFO - Train Epoch: 5 dl0 [4608/321526 (1%)] Loss: 1.883728; lr: 2.7124252486904454e-05; Time/iteration: 0.434m; Time so far/epoch: 0.081h
2024-05-01 21:35:48,624 - trainer - INFO - Train Epoch: 5 dl0 [5184/321526 (2%)] Loss: 1.844471; lr: 2.711629301878369e-05; Time/iteration: 0.435m; Time so far/epoch: 0.089h
2024-05-01 21:36:14,691 - trainer - INFO - Train Epoch: 5 dl0 [5760/321526 (2%)] Loss: 1.998272; lr: 2.710832373514212e-05; Time/iteration: 0.434m; Time so far/epoch: 0.096h
2024-05-01 21:36:41,332 - trainer - INFO - Train Epoch: 5 dl0 [6336/321526 (2%)] Loss: 1.904405; lr: 2.710034464251666e-05; Time/iteration: 0.444m; Time so far/epoch: 0.103h
2024-05-01 21:37:06,571 - trainer - INFO - Train Epoch: 5 dl0 [6912/321526 (2%)] Loss: 1.995349; lr: 2.7092355747452276e-05; Time/iteration: 0.421m; Time so far/epoch: 0.110h
2024-05-01 21:37:32,741 - trainer - INFO - Train Epoch: 5 dl0 [7488/321526 (2%)] Loss: 1.910962; lr: 2.7084357056501966e-05; Time/iteration: 0.436m; Time so far/epoch: 0.118h
2024-05-01 21:37:57,286 - trainer - INFO - Train Epoch: 5 dl0 [8064/321526 (3%)] Loss: 1.937143; lr: 2.707634857622678e-05; Time/iteration: 0.409m; Time so far/epoch: 0.124h
2024-05-01 21:38:21,169 - trainer - INFO - Train Epoch: 5 dl0 [8640/321526 (3%)] Loss: 1.958345; lr: 2.7068330313195777e-05; Time/iteration: 0.398m; Time so far/epoch: 0.131h
2024-05-01 21:38:45,750 - trainer - INFO - Train Epoch: 5 dl0 [9216/321526 (3%)] Loss: 1.965906; lr: 2.7060302273986056e-05; Time/iteration: 0.410m; Time so far/epoch: 0.138h
2024-05-01 21:39:09,161 - trainer - INFO - Train Epoch: 5 dl0 [9792/321526 (3%)] Loss: 1.957781; lr: 2.7052264465182722e-05; Time/iteration: 0.390m; Time so far/epoch: 0.144h
2024-05-01 21:39:34,419 - trainer - INFO - Train Epoch: 5 dl0 [10368/321526 (3%)] Loss: 2.060807; lr: 2.7044216893378912e-05; Time/iteration: 0.421m; Time so far/epoch: 0.151h
2024-05-01 21:39:58,943 - trainer - INFO - Train Epoch: 5 dl0 [10944/321526 (3%)] Loss: 1.937028; lr: 2.703615956517576e-05; Time/iteration: 0.409m; Time so far/epoch: 0.158h
2024-05-01 21:40:23,370 - trainer - INFO - Train Epoch: 5 dl0 [11520/321526 (4%)] Loss: 1.833868; lr: 2.7028092487182388e-05; Time/iteration: 0.407m; Time so far/epoch: 0.165h
2024-05-01 21:40:46,616 - trainer - INFO - Train Epoch: 5 dl0 [12096/321526 (4%)] Loss: 1.949353; lr: 2.702001566601595e-05; Time/iteration: 0.387m; Time so far/epoch: 0.171h
2024-05-01 21:41:09,895 - trainer - INFO - Train Epoch: 5 dl0 [12672/321526 (4%)] Loss: 1.919133; lr: 2.701192910830156e-05; Time/iteration: 0.388m; Time so far/epoch: 0.178h
2024-05-01 21:41:34,193 - trainer - INFO - Train Epoch: 5 dl0 [13248/321526 (4%)] Loss: 1.883641; lr: 2.7003832820672335e-05; Time/iteration: 0.405m; Time so far/epoch: 0.185h
2024-05-01 21:41:59,609 - trainer - INFO - Train Epoch: 5 dl0 [13824/321526 (4%)] Loss: 1.860843; lr: 2.6995726809769367e-05; Time/iteration: 0.424m; Time so far/epoch: 0.192h
2024-05-01 21:42:24,422 - trainer - INFO - Train Epoch: 5 dl0 [14400/321526 (4%)] Loss: 2.008206; lr: 2.6987611082241728e-05; Time/iteration: 0.414m; Time so far/epoch: 0.199h
2024-05-01 21:42:47,918 - trainer - INFO - Train Epoch: 5 dl0 [14976/321526 (5%)] Loss: 1.902054; lr: 2.697948564474646e-05; Time/iteration: 0.392m; Time so far/epoch: 0.205h
2024-05-01 21:43:12,983 - trainer - INFO - Train Epoch: 5 dl0 [15552/321526 (5%)] Loss: 1.903190; lr: 2.6971350503948568e-05; Time/iteration: 0.418m; Time so far/epoch: 0.212h
2024-05-01 21:43:37,307 - trainer - INFO - Train Epoch: 5 dl0 [16128/321526 (5%)] Loss: 1.882141; lr: 2.696320566652101e-05; Time/iteration: 0.405m; Time so far/epoch: 0.219h
2024-05-01 21:44:01,229 - trainer - INFO - Train Epoch: 5 dl0 [16704/321526 (5%)] Loss: 1.859721; lr: 2.6955051139144713e-05; Time/iteration: 0.399m; Time so far/epoch: 0.225h
2024-05-01 21:44:25,596 - trainer - INFO - Train Epoch: 5 dl0 [17280/321526 (5%)] Loss: 1.899843; lr: 2.6946886928508534e-05; Time/iteration: 0.406m; Time so far/epoch: 0.232h
2024-05-01 21:44:48,857 - trainer - INFO - Train Epoch: 5 dl0 [17856/321526 (6%)] Loss: 1.949686; lr: 2.6938713041309284e-05; Time/iteration: 0.388m; Time so far/epoch: 0.239h
2024-05-01 21:45:12,867 - trainer - INFO - Train Epoch: 5 dl0 [18432/321526 (6%)] Loss: 1.853079; lr: 2.6930529484251716e-05; Time/iteration: 0.400m; Time so far/epoch: 0.245h
2024-05-01 21:45:36,736 - trainer - INFO - Train Epoch: 5 dl0 [19008/321526 (6%)] Loss: 2.006546; lr: 2.69223362640485e-05; Time/iteration: 0.398m; Time so far/epoch: 0.252h
2024-05-01 21:46:01,059 - trainer - INFO - Train Epoch: 5 dl0 [19584/321526 (6%)] Loss: 1.923975; lr: 2.691413338742025e-05; Time/iteration: 0.405m; Time so far/epoch: 0.259h
2024-05-01 21:46:25,265 - trainer - INFO - Train Epoch: 5 dl0 [20160/321526 (6%)] Loss: 2.043714; lr: 2.6905920861095484e-05; Time/iteration: 0.403m; Time so far/epoch: 0.265h
2024-05-01 21:46:48,649 - trainer - INFO - Train Epoch: 5 dl0 [20736/321526 (6%)] Loss: 1.849501; lr: 2.6897698691810646e-05; Time/iteration: 0.390m; Time so far/epoch: 0.272h
2024-05-01 21:47:13,134 - trainer - INFO - Train Epoch: 5 dl0 [21312/321526 (7%)] Loss: 1.978856; lr: 2.688946688631008e-05; Time/iteration: 0.408m; Time so far/epoch: 0.279h
2024-05-01 21:47:36,857 - trainer - INFO - Train Epoch: 5 dl0 [21888/321526 (7%)] Loss: 2.022933; lr: 2.6881225451346047e-05; Time/iteration: 0.395m; Time so far/epoch: 0.285h
2024-05-01 21:48:02,012 - trainer - INFO - Train Epoch: 5 dl0 [22464/321526 (7%)] Loss: 1.908113; lr: 2.68729743936787e-05; Time/iteration: 0.419m; Time so far/epoch: 0.292h
2024-05-01 21:48:26,499 - trainer - INFO - Train Epoch: 5 dl0 [23040/321526 (7%)] Loss: 1.922356; lr: 2.686471372007608e-05; Time/iteration: 0.408m; Time so far/epoch: 0.299h
2024-05-01 21:48:50,013 - trainer - INFO - Train Epoch: 5 dl0 [23616/321526 (7%)] Loss: 1.931983; lr: 2.6856443437314132e-05; Time/iteration: 0.392m; Time so far/epoch: 0.306h
2024-05-01 21:49:15,246 - trainer - INFO - Train Epoch: 5 dl0 [24192/321526 (8%)] Loss: 1.922455; lr: 2.6848163552176662e-05; Time/iteration: 0.421m; Time so far/epoch: 0.313h
2024-05-01 21:49:39,280 - trainer - INFO - Train Epoch: 5 dl0 [24768/321526 (8%)] Loss: 1.891653; lr: 2.683987407145537e-05; Time/iteration: 0.401m; Time so far/epoch: 0.319h
2024-05-01 21:50:04,244 - trainer - INFO - Train Epoch: 5 dl0 [25344/321526 (8%)] Loss: 1.844398; lr: 2.6831575001949813e-05; Time/iteration: 0.416m; Time so far/epoch: 0.326h
2024-05-01 21:50:28,797 - trainer - INFO - Train Epoch: 5 dl0 [25920/321526 (8%)] Loss: 1.922809; lr: 2.6823266350467425e-05; Time/iteration: 0.409m; Time so far/epoch: 0.333h
2024-05-01 21:50:52,630 - trainer - INFO - Train Epoch: 5 dl0 [26496/321526 (8%)] Loss: 1.974998; lr: 2.681494812382349e-05; Time/iteration: 0.397m; Time so far/epoch: 0.340h
2024-05-01 21:51:16,387 - trainer - INFO - Train Epoch: 5 dl0 [27072/321526 (8%)] Loss: 1.896888; lr: 2.6806620328841158e-05; Time/iteration: 0.396m; Time so far/epoch: 0.346h
2024-05-01 21:51:39,938 - trainer - INFO - Train Epoch: 5 dl0 [27648/321526 (9%)] Loss: 1.924081; lr: 2.6798282972351416e-05; Time/iteration: 0.392m; Time so far/epoch: 0.353h
2024-05-01 21:52:04,460 - trainer - INFO - Train Epoch: 5 dl0 [28224/321526 (9%)] Loss: 1.864949; lr: 2.6789936061193093e-05; Time/iteration: 0.409m; Time so far/epoch: 0.360h
2024-05-01 21:52:28,198 - trainer - INFO - Train Epoch: 5 dl0 [28800/321526 (9%)] Loss: 1.860367; lr: 2.678157960221287e-05; Time/iteration: 0.396m; Time so far/epoch: 0.366h
2024-05-01 21:52:52,187 - trainer - INFO - Train Epoch: 5 dl0 [29376/321526 (9%)] Loss: 1.898085; lr: 2.6773213602265246e-05; Time/iteration: 0.400m; Time so far/epoch: 0.373h
2024-05-01 21:53:16,121 - trainer - INFO - Train Epoch: 5 dl0 [29952/321526 (9%)] Loss: 1.983853; lr: 2.6764838068212555e-05; Time/iteration: 0.399m; Time so far/epoch: 0.380h
2024-05-01 21:53:40,134 - trainer - INFO - Train Epoch: 5 dl0 [30528/321526 (9%)] Loss: 2.010334; lr: 2.6756453006924937e-05; Time/iteration: 0.400m; Time so far/epoch: 0.386h
2024-05-01 21:54:04,653 - trainer - INFO - Train Epoch: 5 dl0 [31104/321526 (10%)] Loss: 1.949157; lr: 2.6748058425280366e-05; Time/iteration: 0.409m; Time so far/epoch: 0.393h
2024-05-01 21:54:28,280 - trainer - INFO - Train Epoch: 5 dl0 [31680/321526 (10%)] Loss: 1.982901; lr: 2.6739654330164615e-05; Time/iteration: 0.394m; Time so far/epoch: 0.400h
2024-05-01 21:54:52,037 - trainer - INFO - Train Epoch: 5 dl0 [32256/321526 (10%)] Loss: 2.012294; lr: 2.6731240728471254e-05; Time/iteration: 0.396m; Time so far/epoch: 0.406h
2024-05-01 21:55:15,864 - trainer - INFO - Train Epoch: 5 dl0 [32832/321526 (10%)] Loss: 1.852138; lr: 2.6722817627101673e-05; Time/iteration: 0.397m; Time so far/epoch: 0.413h
2024-05-01 21:55:39,858 - trainer - INFO - Train Epoch: 5 dl0 [33408/321526 (10%)] Loss: 1.965809; lr: 2.6714385032965027e-05; Time/iteration: 0.400m; Time so far/epoch: 0.420h
2024-05-01 21:56:04,079 - trainer - INFO - Train Epoch: 5 dl0 [33984/321526 (11%)] Loss: 1.995445; lr: 2.6705942952978273e-05; Time/iteration: 0.404m; Time so far/epoch: 0.426h
2024-05-01 21:56:28,590 - trainer - INFO - Train Epoch: 5 dl0 [34560/321526 (11%)] Loss: 1.827166; lr: 2.669749139406615e-05; Time/iteration: 0.409m; Time so far/epoch: 0.433h
2024-05-01 21:56:52,973 - trainer - INFO - Train Epoch: 5 dl0 [35136/321526 (11%)] Loss: 1.936309; lr: 2.6689030363161168e-05; Time/iteration: 0.406m; Time so far/epoch: 0.440h
2024-05-01 21:57:16,384 - trainer - INFO - Train Epoch: 5 dl0 [35712/321526 (11%)] Loss: 1.900806; lr: 2.66805598672036e-05; Time/iteration: 0.390m; Time so far/epoch: 0.446h
2024-05-01 21:57:40,730 - trainer - INFO - Train Epoch: 5 dl0 [36288/321526 (11%)] Loss: 1.839193; lr: 2.66720799131415e-05; Time/iteration: 0.406m; Time so far/epoch: 0.453h
2024-05-01 21:58:04,712 - trainer - INFO - Train Epoch: 5 dl0 [36864/321526 (11%)] Loss: 1.860004; lr: 2.666359050793067e-05; Time/iteration: 0.400m; Time so far/epoch: 0.460h
2024-05-01 21:58:29,252 - trainer - INFO - Train Epoch: 5 dl0 [37440/321526 (12%)] Loss: 1.959573; lr: 2.6655091658534652e-05; Time/iteration: 0.409m; Time so far/epoch: 0.467h
2024-05-01 21:58:53,789 - trainer - INFO - Train Epoch: 5 dl0 [38016/321526 (12%)] Loss: 1.941989; lr: 2.6646583371924764e-05; Time/iteration: 0.409m; Time so far/epoch: 0.473h
2024-05-01 21:59:17,206 - trainer - INFO - Train Epoch: 5 dl0 [38592/321526 (12%)] Loss: 1.882377; lr: 2.6638065655080034e-05; Time/iteration: 0.390m; Time so far/epoch: 0.480h
2024-05-01 21:59:41,181 - trainer - INFO - Train Epoch: 5 dl0 [39168/321526 (12%)] Loss: 2.021949; lr: 2.6629538514987243e-05; Time/iteration: 0.400m; Time so far/epoch: 0.487h
2024-05-01 22:00:05,016 - trainer - INFO - Train Epoch: 5 dl0 [39744/321526 (12%)] Loss: 1.929026; lr: 2.6621001958640906e-05; Time/iteration: 0.397m; Time so far/epoch: 0.493h
2024-05-01 22:00:29,505 - trainer - INFO - Train Epoch: 5 dl0 [40320/321526 (13%)] Loss: 1.851775; lr: 2.6612455993043247e-05; Time/iteration: 0.408m; Time so far/epoch: 0.500h
2024-05-01 22:00:53,416 - trainer - INFO - Train Epoch: 5 dl0 [40896/321526 (13%)] Loss: 1.945442; lr: 2.6603900625204215e-05; Time/iteration: 0.398m; Time so far/epoch: 0.507h
2024-05-01 22:01:17,054 - trainer - INFO - Train Epoch: 5 dl0 [41472/321526 (13%)] Loss: 1.964839; lr: 2.6595335862141472e-05; Time/iteration: 0.394m; Time so far/epoch: 0.513h
2024-05-01 22:01:40,378 - trainer - INFO - Train Epoch: 5 dl0 [42048/321526 (13%)] Loss: 1.936325; lr: 2.6586761710880384e-05; Time/iteration: 0.389m; Time so far/epoch: 0.520h
2024-05-01 22:02:04,130 - trainer - INFO - Train Epoch: 5 dl0 [42624/321526 (13%)] Loss: 1.950007; lr: 2.6578178178454025e-05; Time/iteration: 0.396m; Time so far/epoch: 0.526h
2024-05-01 22:02:28,668 - trainer - INFO - Train Epoch: 5 dl0 [43200/321526 (13%)] Loss: 1.908503; lr: 2.6569585271903152e-05; Time/iteration: 0.409m; Time so far/epoch: 0.533h
2024-05-01 22:02:52,634 - trainer - INFO - Train Epoch: 5 dl0 [43776/321526 (14%)] Loss: 1.921272; lr: 2.6560982998276222e-05; Time/iteration: 0.399m; Time so far/epoch: 0.540h
2024-05-01 22:03:16,640 - trainer - INFO - Train Epoch: 5 dl0 [44352/321526 (14%)] Loss: 1.865475; lr: 2.6552371364629375e-05; Time/iteration: 0.400m; Time so far/epoch: 0.546h
2024-05-01 22:03:40,775 - trainer - INFO - Train Epoch: 5 dl0 [44928/321526 (14%)] Loss: 1.957718; lr: 2.6543750378026415e-05; Time/iteration: 0.402m; Time so far/epoch: 0.553h
2024-05-01 22:04:04,646 - trainer - INFO - Train Epoch: 5 dl0 [45504/321526 (14%)] Loss: 1.949704; lr: 2.6535120045538837e-05; Time/iteration: 0.398m; Time so far/epoch: 0.560h
2024-05-01 22:04:29,059 - trainer - INFO - Train Epoch: 5 dl0 [46080/321526 (14%)] Loss: 1.899153; lr: 2.652648037424579e-05; Time/iteration: 0.407m; Time so far/epoch: 0.567h
2024-05-01 22:04:53,321 - trainer - INFO - Train Epoch: 5 dl0 [46656/321526 (15%)] Loss: 1.855753; lr: 2.6517831371234087e-05; Time/iteration: 0.404m; Time so far/epoch: 0.573h
2024-05-01 22:05:17,234 - trainer - INFO - Train Epoch: 5 dl0 [47232/321526 (15%)] Loss: 1.806293; lr: 2.650917304359819e-05; Time/iteration: 0.399m; Time so far/epoch: 0.580h
2024-05-01 22:05:40,530 - trainer - INFO - Train Epoch: 5 dl0 [47808/321526 (15%)] Loss: 1.917862; lr: 2.6500505398440224e-05; Time/iteration: 0.388m; Time so far/epoch: 0.586h
2024-05-01 22:06:04,624 - trainer - INFO - Train Epoch: 5 dl0 [48384/321526 (15%)] Loss: 1.915967; lr: 2.649182844286994e-05; Time/iteration: 0.402m; Time so far/epoch: 0.593h
2024-05-01 22:06:29,931 - trainer - INFO - Train Epoch: 5 dl0 [48960/321526 (15%)] Loss: 1.856205; lr: 2.6483142184004734e-05; Time/iteration: 0.422m; Time so far/epoch: 0.600h
2024-05-01 22:06:53,876 - trainer - INFO - Train Epoch: 5 dl0 [49536/321526 (15%)] Loss: 1.858493; lr: 2.6474446628969632e-05; Time/iteration: 0.399m; Time so far/epoch: 0.607h
2024-05-01 22:07:18,203 - trainer - INFO - Train Epoch: 5 dl0 [50112/321526 (16%)] Loss: 1.946967; lr: 2.6465741784897292e-05; Time/iteration: 0.405m; Time so far/epoch: 0.614h
2024-05-01 22:07:41,454 - trainer - INFO - Train Epoch: 5 dl0 [50688/321526 (16%)] Loss: 1.925695; lr: 2.6457027658927975e-05; Time/iteration: 0.388m; Time so far/epoch: 0.620h
2024-05-01 22:08:05,377 - trainer - INFO - Train Epoch: 5 dl0 [51264/321526 (16%)] Loss: 1.947389; lr: 2.6448304258209578e-05; Time/iteration: 0.399m; Time so far/epoch: 0.627h
2024-05-01 22:08:29,475 - trainer - INFO - Train Epoch: 5 dl0 [51840/321526 (16%)] Loss: 1.889478; lr: 2.643957158989758e-05; Time/iteration: 0.402m; Time so far/epoch: 0.633h
2024-05-01 22:08:54,144 - trainer - INFO - Train Epoch: 5 dl0 [52416/321526 (16%)] Loss: 1.922858; lr: 2.643082966115509e-05; Time/iteration: 0.411m; Time so far/epoch: 0.640h
2024-05-01 22:09:19,090 - trainer - INFO - Train Epoch: 5 dl0 [52992/321526 (16%)] Loss: 1.917750; lr: 2.6422078479152788e-05; Time/iteration: 0.416m; Time so far/epoch: 0.647h
2024-05-01 22:09:42,773 - trainer - INFO - Train Epoch: 5 dl0 [53568/321526 (17%)] Loss: 1.911366; lr: 2.6413318051068957e-05; Time/iteration: 0.395m; Time so far/epoch: 0.654h
2024-05-01 22:10:06,964 - trainer - INFO - Train Epoch: 5 dl0 [54144/321526 (17%)] Loss: 2.019278; lr: 2.6404548384089464e-05; Time/iteration: 0.403m; Time so far/epoch: 0.660h
2024-05-01 22:10:31,213 - trainer - INFO - Train Epoch: 5 dl0 [54720/321526 (17%)] Loss: 1.922316; lr: 2.639576948540775e-05; Time/iteration: 0.404m; Time so far/epoch: 0.667h
2024-05-01 22:10:56,204 - trainer - INFO - Train Epoch: 5 dl0 [55296/321526 (17%)] Loss: 1.895758; lr: 2.6386981362224835e-05; Time/iteration: 0.417m; Time so far/epoch: 0.674h
2024-05-01 22:11:19,783 - trainer - INFO - Train Epoch: 5 dl0 [55872/321526 (17%)] Loss: 1.910812; lr: 2.6378184021749293e-05; Time/iteration: 0.393m; Time so far/epoch: 0.681h
2024-05-01 22:11:43,053 - trainer - INFO - Train Epoch: 5 dl0 [56448/321526 (18%)] Loss: 2.050581; lr: 2.6369377471197272e-05; Time/iteration: 0.388m; Time so far/epoch: 0.687h
2024-05-01 22:12:07,526 - trainer - INFO - Train Epoch: 5 dl0 [57024/321526 (18%)] Loss: 1.931933; lr: 2.636056171779247e-05; Time/iteration: 0.408m; Time so far/epoch: 0.694h
2024-05-01 22:12:31,024 - trainer - INFO - Train Epoch: 5 dl0 [57600/321526 (18%)] Loss: 1.946264; lr: 2.6351736768766133e-05; Time/iteration: 0.392m; Time so far/epoch: 0.700h
2024-05-01 22:12:55,466 - trainer - INFO - Train Epoch: 5 dl0 [58176/321526 (18%)] Loss: 1.880463; lr: 2.6342902631357044e-05; Time/iteration: 0.407m; Time so far/epoch: 0.707h
2024-05-01 22:13:19,304 - trainer - INFO - Train Epoch: 5 dl0 [58752/321526 (18%)] Loss: 1.880718; lr: 2.6334059312811538e-05; Time/iteration: 0.397m; Time so far/epoch: 0.714h
2024-05-01 22:13:43,160 - trainer - INFO - Train Epoch: 5 dl0 [59328/321526 (18%)] Loss: 1.836468; lr: 2.6325206820383464e-05; Time/iteration: 0.398m; Time so far/epoch: 0.720h
2024-05-01 22:14:06,589 - trainer - INFO - Train Epoch: 5 dl0 [59904/321526 (19%)] Loss: 1.995190; lr: 2.6316345161334214e-05; Time/iteration: 0.390m; Time so far/epoch: 0.727h
2024-05-01 22:14:29,752 - trainer - INFO - Train Epoch: 5 dl0 [60480/321526 (19%)] Loss: 1.883149; lr: 2.630747434293268e-05; Time/iteration: 0.386m; Time so far/epoch: 0.733h
2024-05-01 22:14:54,792 - trainer - INFO - Train Epoch: 5 dl0 [61056/321526 (19%)] Loss: 1.848468; lr: 2.6298594372455274e-05; Time/iteration: 0.417m; Time so far/epoch: 0.740h
2024-05-01 22:15:18,544 - trainer - INFO - Train Epoch: 5 dl0 [61632/321526 (19%)] Loss: 1.999468; lr: 2.628970525718593e-05; Time/iteration: 0.396m; Time so far/epoch: 0.747h
2024-05-01 22:15:42,788 - trainer - INFO - Train Epoch: 5 dl0 [62208/321526 (19%)] Loss: 2.051162; lr: 2.6280807004416054e-05; Time/iteration: 0.404m; Time so far/epoch: 0.754h
2024-05-01 22:16:06,916 - trainer - INFO - Train Epoch: 5 dl0 [62784/321526 (20%)] Loss: 2.069078; lr: 2.6271899621444576e-05; Time/iteration: 0.402m; Time so far/epoch: 0.760h
2024-05-01 22:16:30,515 - trainer - INFO - Train Epoch: 5 dl0 [63360/321526 (20%)] Loss: 1.925576; lr: 2.6262983115577896e-05; Time/iteration: 0.393m; Time so far/epoch: 0.767h
2024-05-01 22:16:55,203 - trainer - INFO - Train Epoch: 5 dl0 [63936/321526 (20%)] Loss: 2.045324; lr: 2.6254057494129906e-05; Time/iteration: 0.411m; Time so far/epoch: 0.774h
2024-05-01 22:17:19,566 - trainer - INFO - Train Epoch: 5 dl0 [64512/321526 (20%)] Loss: 1.743656; lr: 2.624512276442198e-05; Time/iteration: 0.406m; Time so far/epoch: 0.781h
2024-05-01 22:17:43,992 - trainer - INFO - Train Epoch: 5 dl0 [65088/321526 (20%)] Loss: 1.836744; lr: 2.623617893378294e-05; Time/iteration: 0.407m; Time so far/epoch: 0.787h
2024-05-01 22:18:07,636 - trainer - INFO - Train Epoch: 5 dl0 [65664/321526 (20%)] Loss: 1.941027; lr: 2.6227226009549107e-05; Time/iteration: 0.394m; Time so far/epoch: 0.794h
2024-05-01 22:18:31,852 - trainer - INFO - Train Epoch: 5 dl0 [66240/321526 (21%)] Loss: 1.966725; lr: 2.6218263999064233e-05; Time/iteration: 0.403m; Time so far/epoch: 0.801h
2024-05-01 22:18:57,149 - trainer - INFO - Train Epoch: 5 dl0 [66816/321526 (21%)] Loss: 2.058572; lr: 2.6209292909679533e-05; Time/iteration: 0.422m; Time so far/epoch: 0.808h
2024-05-01 22:19:21,284 - trainer - INFO - Train Epoch: 5 dl0 [67392/321526 (21%)] Loss: 1.861235; lr: 2.6200312748753673e-05; Time/iteration: 0.402m; Time so far/epoch: 0.814h
2024-05-01 22:19:45,402 - trainer - INFO - Train Epoch: 5 dl0 [67968/321526 (21%)] Loss: 1.916754; lr: 2.6191323523652753e-05; Time/iteration: 0.402m; Time so far/epoch: 0.821h
2024-05-01 22:20:08,528 - trainer - INFO - Train Epoch: 5 dl0 [68544/321526 (21%)] Loss: 1.894180; lr: 2.618232524175032e-05; Time/iteration: 0.385m; Time so far/epoch: 0.827h
2024-05-01 22:20:32,621 - trainer - INFO - Train Epoch: 5 dl0 [69120/321526 (21%)] Loss: 1.805733; lr: 2.6173317910427338e-05; Time/iteration: 0.402m; Time so far/epoch: 0.834h
2024-05-01 22:20:57,046 - trainer - INFO - Train Epoch: 5 dl0 [69696/321526 (22%)] Loss: 1.907050; lr: 2.6164301537072193e-05; Time/iteration: 0.407m; Time so far/epoch: 0.841h
2024-05-01 22:21:21,944 - trainer - INFO - Train Epoch: 5 dl0 [70272/321526 (22%)] Loss: 1.964895; lr: 2.6155276129080697e-05; Time/iteration: 0.415m; Time so far/epoch: 0.848h
2024-05-01 22:21:46,296 - trainer - INFO - Train Epoch: 5 dl0 [70848/321526 (22%)] Loss: 1.923256; lr: 2.614624169385607e-05; Time/iteration: 0.406m; Time so far/epoch: 0.855h
2024-05-01 22:22:10,008 - trainer - INFO - Train Epoch: 5 dl0 [71424/321526 (22%)] Loss: 1.876026; lr: 2.6137198238808927e-05; Time/iteration: 0.395m; Time so far/epoch: 0.861h
2024-05-01 22:22:33,807 - trainer - INFO - Train Epoch: 5 dl0 [72000/321526 (22%)] Loss: 1.956207; lr: 2.6128145771357304e-05; Time/iteration: 0.397m; Time so far/epoch: 0.868h
2024-05-01 22:22:58,191 - trainer - INFO - Train Epoch: 5 dl0 [72576/321526 (23%)] Loss: 1.909240; lr: 2.6119084298926602e-05; Time/iteration: 0.406m; Time so far/epoch: 0.875h
2024-05-01 22:23:23,141 - trainer - INFO - Train Epoch: 5 dl0 [73152/321526 (23%)] Loss: 1.938646; lr: 2.6110013828949625e-05; Time/iteration: 0.416m; Time so far/epoch: 0.882h
2024-05-01 22:23:47,412 - trainer - INFO - Train Epoch: 5 dl0 [73728/321526 (23%)] Loss: 2.029511; lr: 2.6100934368866557e-05; Time/iteration: 0.404m; Time so far/epoch: 0.888h
2024-05-01 22:24:10,907 - trainer - INFO - Train Epoch: 5 dl0 [74304/321526 (23%)] Loss: 1.844286; lr: 2.6091845926124953e-05; Time/iteration: 0.392m; Time so far/epoch: 0.895h
2024-05-01 22:24:35,320 - trainer - INFO - Train Epoch: 5 dl0 [74880/321526 (23%)] Loss: 2.068140; lr: 2.6082748508179732e-05; Time/iteration: 0.407m; Time so far/epoch: 0.902h
2024-05-01 22:24:59,241 - trainer - INFO - Train Epoch: 5 dl0 [75456/321526 (23%)] Loss: 2.068047; lr: 2.6073642122493184e-05; Time/iteration: 0.399m; Time so far/epoch: 0.908h
2024-05-01 22:25:23,593 - trainer - INFO - Train Epoch: 5 dl0 [76032/321526 (24%)] Loss: 1.923885; lr: 2.606452677653495e-05; Time/iteration: 0.406m; Time so far/epoch: 0.915h
2024-05-01 22:25:47,126 - trainer - INFO - Train Epoch: 5 dl0 [76608/321526 (24%)] Loss: 1.934628; lr: 2.605540247778202e-05; Time/iteration: 0.392m; Time so far/epoch: 0.922h
2024-05-01 22:26:11,004 - trainer - INFO - Train Epoch: 5 dl0 [77184/321526 (24%)] Loss: 1.852147; lr: 2.6046269233718725e-05; Time/iteration: 0.398m; Time so far/epoch: 0.928h
2024-05-01 22:26:34,920 - trainer - INFO - Train Epoch: 5 dl0 [77760/321526 (24%)] Loss: 1.958038; lr: 2.6037127051836745e-05; Time/iteration: 0.399m; Time so far/epoch: 0.935h
2024-05-01 22:26:59,045 - trainer - INFO - Train Epoch: 5 dl0 [78336/321526 (24%)] Loss: 1.958405; lr: 2.6027975939635082e-05; Time/iteration: 0.402m; Time so far/epoch: 0.942h
2024-05-01 22:27:24,121 - trainer - INFO - Train Epoch: 5 dl0 [78912/321526 (25%)] Loss: 1.995699; lr: 2.601881590462006e-05; Time/iteration: 0.418m; Time so far/epoch: 0.948h
2024-05-01 22:27:48,724 - trainer - INFO - Train Epoch: 5 dl0 [79488/321526 (25%)] Loss: 1.854311; lr: 2.600964695430533e-05; Time/iteration: 0.410m; Time so far/epoch: 0.955h
2024-05-01 22:28:12,622 - trainer - INFO - Train Epoch: 5 dl0 [80064/321526 (25%)] Loss: 1.994991; lr: 2.6000469096211858e-05; Time/iteration: 0.398m; Time so far/epoch: 0.962h
2024-05-01 22:28:36,859 - trainer - INFO - Train Epoch: 5 dl0 [80640/321526 (25%)] Loss: 1.951088; lr: 2.5991282337867907e-05; Time/iteration: 0.404m; Time so far/epoch: 0.969h
2024-05-01 22:29:01,519 - trainer - INFO - Train Epoch: 5 dl0 [81216/321526 (25%)] Loss: 2.045316; lr: 2.598208668680904e-05; Time/iteration: 0.411m; Time so far/epoch: 0.976h
2024-05-01 22:29:26,354 - trainer - INFO - Train Epoch: 5 dl0 [81792/321526 (25%)] Loss: 1.945938; lr: 2.597288215057813e-05; Time/iteration: 0.414m; Time so far/epoch: 0.982h
2024-05-01 22:29:50,107 - trainer - INFO - Train Epoch: 5 dl0 [82368/321526 (26%)] Loss: 1.979106; lr: 2.5963668736725323e-05; Time/iteration: 0.396m; Time so far/epoch: 0.989h
2024-05-01 22:30:14,072 - trainer - INFO - Train Epoch: 5 dl0 [82944/321526 (26%)] Loss: 1.862957; lr: 2.5954446452808048e-05; Time/iteration: 0.399m; Time so far/epoch: 0.996h
2024-05-01 22:30:37,788 - trainer - INFO - Train Epoch: 5 dl0 [83520/321526 (26%)] Loss: 1.889106; lr: 2.594521530639102e-05; Time/iteration: 0.395m; Time so far/epoch: 1.002h
2024-05-01 22:31:02,871 - trainer - INFO - Train Epoch: 5 dl0 [84096/321526 (26%)] Loss: 1.883937; lr: 2.5935975305046206e-05; Time/iteration: 0.418m; Time so far/epoch: 1.009h
2024-05-01 22:31:27,366 - trainer - INFO - Train Epoch: 5 dl0 [84672/321526 (26%)] Loss: 1.870547; lr: 2.5926726456352866e-05; Time/iteration: 0.408m; Time so far/epoch: 1.016h
2024-05-01 22:31:51,482 - trainer - INFO - Train Epoch: 5 dl0 [85248/321526 (27%)] Loss: 1.997107; lr: 2.5917468767897484e-05; Time/iteration: 0.402m; Time so far/epoch: 1.023h
2024-05-01 22:32:15,572 - trainer - INFO - Train Epoch: 5 dl0 [85824/321526 (27%)] Loss: 1.888267; lr: 2.5908202247273816e-05; Time/iteration: 0.401m; Time so far/epoch: 1.029h
2024-05-01 22:32:39,400 - trainer - INFO - Train Epoch: 5 dl0 [86400/321526 (27%)] Loss: 2.022025; lr: 2.5898926902082853e-05; Time/iteration: 0.397m; Time so far/epoch: 1.036h
2024-05-01 22:33:03,818 - trainer - INFO - Train Epoch: 5 dl0 [86976/321526 (27%)] Loss: 1.998219; lr: 2.588964273993283e-05; Time/iteration: 0.407m; Time so far/epoch: 1.043h
2024-05-01 22:33:27,972 - trainer - INFO - Train Epoch: 5 dl0 [87552/321526 (27%)] Loss: 2.028791; lr: 2.5880349768439214e-05; Time/iteration: 0.403m; Time so far/epoch: 1.050h
2024-05-01 22:33:52,532 - trainer - INFO - Train Epoch: 5 dl0 [88128/321526 (27%)] Loss: 1.978681; lr: 2.587104799522469e-05; Time/iteration: 0.409m; Time so far/epoch: 1.056h
2024-05-01 22:34:16,025 - trainer - INFO - Train Epoch: 5 dl0 [88704/321526 (28%)] Loss: 1.961665; lr: 2.5861737427919173e-05; Time/iteration: 0.392m; Time so far/epoch: 1.063h
2024-05-01 22:34:39,904 - trainer - INFO - Train Epoch: 5 dl0 [89280/321526 (28%)] Loss: 1.882871; lr: 2.585241807415979e-05; Time/iteration: 0.398m; Time so far/epoch: 1.070h
2024-05-01 22:35:04,510 - trainer - INFO - Train Epoch: 5 dl0 [89856/321526 (28%)] Loss: 1.929153; lr: 2.5843089941590864e-05; Time/iteration: 0.410m; Time so far/epoch: 1.076h
2024-05-01 22:35:28,902 - trainer - INFO - Train Epoch: 5 dl0 [90432/321526 (28%)] Loss: 1.944441; lr: 2.5833753037863936e-05; Time/iteration: 0.407m; Time so far/epoch: 1.083h
2024-05-01 22:35:53,403 - trainer - INFO - Train Epoch: 5 dl0 [91008/321526 (28%)] Loss: 2.015280; lr: 2.5824407370637734e-05; Time/iteration: 0.408m; Time so far/epoch: 1.090h
2024-05-01 22:36:17,316 - trainer - INFO - Train Epoch: 5 dl0 [91584/321526 (28%)] Loss: 1.876521; lr: 2.5815052947578162e-05; Time/iteration: 0.399m; Time so far/epoch: 1.097h
2024-05-01 22:36:40,564 - trainer - INFO - Train Epoch: 5 dl0 [92160/321526 (29%)] Loss: 1.902791; lr: 2.5805689776358327e-05; Time/iteration: 0.387m; Time so far/epoch: 1.103h
2024-05-01 22:37:04,637 - trainer - INFO - Train Epoch: 5 dl0 [92736/321526 (29%)] Loss: 1.949530; lr: 2.5796317864658502e-05; Time/iteration: 0.401m; Time so far/epoch: 1.110h
2024-05-01 22:37:29,289 - trainer - INFO - Train Epoch: 5 dl0 [93312/321526 (29%)] Loss: 1.847371; lr: 2.578693722016613e-05; Time/iteration: 0.411m; Time so far/epoch: 1.117h
2024-05-01 22:37:54,893 - trainer - INFO - Train Epoch: 5 dl0 [93888/321526 (29%)] Loss: 2.037245; lr: 2.5777547850575812e-05; Time/iteration: 0.427m; Time so far/epoch: 1.124h
2024-05-01 22:38:19,215 - trainer - INFO - Train Epoch: 5 dl0 [94464/321526 (29%)] Loss: 2.084931; lr: 2.5768149763589315e-05; Time/iteration: 0.405m; Time so far/epoch: 1.130h
2024-05-01 22:38:43,495 - trainer - INFO - Train Epoch: 5 dl0 [95040/321526 (30%)] Loss: 1.877016; lr: 2.5758742966915553e-05; Time/iteration: 0.405m; Time so far/epoch: 1.137h
2024-05-01 22:39:06,880 - trainer - INFO - Train Epoch: 5 dl0 [95616/321526 (30%)] Loss: 1.893130; lr: 2.5749327468270582e-05; Time/iteration: 0.389m; Time so far/epoch: 1.144h
2024-05-01 22:39:30,276 - trainer - INFO - Train Epoch: 5 dl0 [96192/321526 (30%)] Loss: 1.914526; lr: 2.5739903275377596e-05; Time/iteration: 0.390m; Time so far/epoch: 1.150h
2024-05-01 22:39:54,098 - trainer - INFO - Train Epoch: 5 dl0 [96768/321526 (30%)] Loss: 1.960258; lr: 2.5730470395966925e-05; Time/iteration: 0.397m; Time so far/epoch: 1.157h
2024-05-01 22:40:17,880 - trainer - INFO - Train Epoch: 5 dl0 [97344/321526 (30%)] Loss: 1.901564; lr: 2.572102883777603e-05; Time/iteration: 0.396m; Time so far/epoch: 1.163h
2024-05-01 22:40:42,267 - trainer - INFO - Train Epoch: 5 dl0 [97920/321526 (30%)] Loss: 1.929216; lr: 2.5711578608549462e-05; Time/iteration: 0.406m; Time so far/epoch: 1.170h
2024-05-01 22:41:06,478 - trainer - INFO - Train Epoch: 5 dl0 [98496/321526 (31%)] Loss: 1.944863; lr: 2.570211971603892e-05; Time/iteration: 0.404m; Time so far/epoch: 1.177h
2024-05-01 22:41:29,935 - trainer - INFO - Train Epoch: 5 dl0 [99072/321526 (31%)] Loss: 1.819658; lr: 2.5692652168003192e-05; Time/iteration: 0.391m; Time so far/epoch: 1.183h
2024-05-01 22:41:54,537 - trainer - INFO - Train Epoch: 5 dl0 [99648/321526 (31%)] Loss: 1.886448; lr: 2.568317597220817e-05; Time/iteration: 0.410m; Time so far/epoch: 1.190h
2024-05-01 22:45:30,020 - trainer - INFO - EgoClip_HOI epoch 5, Verb-Neg, Acc: 55.8;    EgoClip_HOI epoch 5, Noun-Neg, Acc: 69.0;    EgoClip_HOI epoch 5, HOI-Neg, Acc: 41.3;    
2024-05-01 22:45:30,028 - trainer - INFO -     epoch          : 5
2024-05-01 22:45:30,029 - trainer - INFO -     loss_0         : 0.5993178806601753
2024-05-01 22:45:30,029 - trainer - INFO -     val_loss_0     : 0.0
2024-05-01 22:45:30,029 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 55.820072174072266
2024-05-01 22:45:30,029 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 68.9843521118164
2024-05-01 22:45:30,029 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.31035614013672
2024-05-01 22:45:30,900 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch5.pth ...
2024-05-01 22:45:32,615 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-01 22:46:39,666 - trainer - INFO - Train Epoch: 6 dl0 [0/321526 (0%)] Loss: 1.944098; lr: 2.5678434633829697e-05; Time/iteration: 1.117m; Time so far/epoch: 0.019h
2024-05-01 22:47:06,239 - trainer - INFO - Train Epoch: 6 dl0 [576/321526 (0%)] Loss: 2.039909; lr: 2.5668945480972288e-05; Time/iteration: 0.443m; Time so far/epoch: 0.026h
2024-05-01 22:47:34,398 - trainer - INFO - Train Epoch: 6 dl0 [1152/321526 (0%)] Loss: 1.929579; lr: 2.5659447699801323e-05; Time/iteration: 0.469m; Time so far/epoch: 0.034h
2024-05-01 22:48:02,232 - trainer - INFO - Train Epoch: 6 dl0 [1728/321526 (1%)] Loss: 1.949500; lr: 2.5649941298107495e-05; Time/iteration: 0.464m; Time so far/epoch: 0.042h
2024-05-01 22:48:30,639 - trainer - INFO - Train Epoch: 6 dl0 [2304/321526 (1%)] Loss: 1.926659; lr: 2.564042628368856e-05; Time/iteration: 0.473m; Time so far/epoch: 0.049h
2024-05-01 22:48:56,797 - trainer - INFO - Train Epoch: 6 dl0 [2880/321526 (1%)] Loss: 2.002926; lr: 2.563090266434935e-05; Time/iteration: 0.436m; Time so far/epoch: 0.057h
2024-05-01 22:49:31,533 - trainer - INFO - Train Epoch: 6 dl0 [3456/321526 (1%)] Loss: 1.887005; lr: 2.5621370447901742e-05; Time/iteration: 0.579m; Time so far/epoch: 0.066h
2024-05-01 22:50:03,939 - trainer - INFO - Train Epoch: 6 dl0 [4032/321526 (1%)] Loss: 1.827329; lr: 2.5611829642164677e-05; Time/iteration: 0.540m; Time so far/epoch: 0.075h
2024-05-01 22:50:29,286 - trainer - INFO - Train Epoch: 6 dl0 [4608/321526 (1%)] Loss: 1.914392; lr: 2.5602280254964136e-05; Time/iteration: 0.422m; Time so far/epoch: 0.082h
2024-05-01 22:50:55,417 - trainer - INFO - Train Epoch: 6 dl0 [5184/321526 (2%)] Loss: 1.897083; lr: 2.5592722294133126e-05; Time/iteration: 0.436m; Time so far/epoch: 0.090h
2024-05-01 22:51:21,570 - trainer - INFO - Train Epoch: 6 dl0 [5760/321526 (2%)] Loss: 2.123122; lr: 2.5583155767511715e-05; Time/iteration: 0.436m; Time so far/epoch: 0.097h
2024-05-01 22:51:47,817 - trainer - INFO - Train Epoch: 6 dl0 [6336/321526 (2%)] Loss: 1.980597; lr: 2.5573580682946975e-05; Time/iteration: 0.437m; Time so far/epoch: 0.104h
2024-05-01 22:52:12,309 - trainer - INFO - Train Epoch: 6 dl0 [6912/321526 (2%)] Loss: 1.813298; lr: 2.5563997048293004e-05; Time/iteration: 0.408m; Time so far/epoch: 0.111h
2024-05-01 22:52:37,324 - trainer - INFO - Train Epoch: 6 dl0 [7488/321526 (2%)] Loss: 1.869129; lr: 2.5554404871410913e-05; Time/iteration: 0.417m; Time so far/epoch: 0.118h
2024-05-01 22:53:02,006 - trainer - INFO - Train Epoch: 6 dl0 [8064/321526 (3%)] Loss: 1.908755; lr: 2.5544804160168822e-05; Time/iteration: 0.411m; Time so far/epoch: 0.125h
2024-05-01 22:53:26,435 - trainer - INFO - Train Epoch: 6 dl0 [8640/321526 (3%)] Loss: 2.067165; lr: 2.553519492244185e-05; Time/iteration: 0.407m; Time so far/epoch: 0.132h
2024-05-01 22:53:50,854 - trainer - INFO - Train Epoch: 6 dl0 [9216/321526 (3%)] Loss: 1.894183; lr: 2.5525577166112108e-05; Time/iteration: 0.407m; Time so far/epoch: 0.138h
2024-05-01 22:54:14,644 - trainer - INFO - Train Epoch: 6 dl0 [9792/321526 (3%)] Loss: 1.907544; lr: 2.55159508990687e-05; Time/iteration: 0.396m; Time so far/epoch: 0.145h
2024-05-01 22:54:38,490 - trainer - INFO - Train Epoch: 6 dl0 [10368/321526 (3%)] Loss: 2.060154; lr: 2.5506316129207704e-05; Time/iteration: 0.397m; Time so far/epoch: 0.152h
2024-05-01 22:55:03,192 - trainer - INFO - Train Epoch: 6 dl0 [10944/321526 (3%)] Loss: 1.955967; lr: 2.5496672864432176e-05; Time/iteration: 0.412m; Time so far/epoch: 0.158h
2024-05-01 22:55:28,155 - trainer - INFO - Train Epoch: 6 dl0 [11520/321526 (4%)] Loss: 1.945023; lr: 2.5487021112652146e-05; Time/iteration: 0.416m; Time so far/epoch: 0.165h
2024-05-01 22:55:52,215 - trainer - INFO - Train Epoch: 6 dl0 [12096/321526 (4%)] Loss: 1.916933; lr: 2.5477360881784593e-05; Time/iteration: 0.401m; Time so far/epoch: 0.172h
2024-05-01 22:56:16,364 - trainer - INFO - Train Epoch: 6 dl0 [12672/321526 (4%)] Loss: 2.029478; lr: 2.546769217975346e-05; Time/iteration: 0.402m; Time so far/epoch: 0.179h
2024-05-01 22:56:40,506 - trainer - INFO - Train Epoch: 6 dl0 [13248/321526 (4%)] Loss: 1.932827; lr: 2.5458015014489637e-05; Time/iteration: 0.402m; Time so far/epoch: 0.186h
2024-05-01 22:57:05,294 - trainer - INFO - Train Epoch: 6 dl0 [13824/321526 (4%)] Loss: 1.965236; lr: 2.544832939393095e-05; Time/iteration: 0.413m; Time so far/epoch: 0.192h
2024-05-01 22:57:31,014 - trainer - INFO - Train Epoch: 6 dl0 [14400/321526 (4%)] Loss: 1.903123; lr: 2.5438635326022178e-05; Time/iteration: 0.429m; Time so far/epoch: 0.200h
2024-05-01 22:57:55,396 - trainer - INFO - Train Epoch: 6 dl0 [14976/321526 (5%)] Loss: 1.825959; lr: 2.5428932818715003e-05; Time/iteration: 0.406m; Time so far/epoch: 0.206h
2024-05-01 22:58:19,610 - trainer - INFO - Train Epoch: 6 dl0 [15552/321526 (5%)] Loss: 1.939251; lr: 2.5419221879968054e-05; Time/iteration: 0.404m; Time so far/epoch: 0.213h
2024-05-01 22:58:43,746 - trainer - INFO - Train Epoch: 6 dl0 [16128/321526 (5%)] Loss: 1.969164; lr: 2.5409502517746863e-05; Time/iteration: 0.402m; Time so far/epoch: 0.220h
2024-05-01 22:59:07,281 - trainer - INFO - Train Epoch: 6 dl0 [16704/321526 (5%)] Loss: 1.850297; lr: 2.5399774740023873e-05; Time/iteration: 0.392m; Time so far/epoch: 0.226h
2024-05-01 22:59:31,082 - trainer - INFO - Train Epoch: 6 dl0 [17280/321526 (5%)] Loss: 1.890641; lr: 2.539003855477843e-05; Time/iteration: 0.397m; Time so far/epoch: 0.233h
2024-05-01 22:59:55,421 - trainer - INFO - Train Epoch: 6 dl0 [17856/321526 (6%)] Loss: 1.951480; lr: 2.538029396999678e-05; Time/iteration: 0.406m; Time so far/epoch: 0.240h
2024-05-01 23:00:20,118 - trainer - INFO - Train Epoch: 6 dl0 [18432/321526 (6%)] Loss: 2.043471; lr: 2.5370540993672053e-05; Time/iteration: 0.412m; Time so far/epoch: 0.247h
2024-05-01 23:00:44,273 - trainer - INFO - Train Epoch: 6 dl0 [19008/321526 (6%)] Loss: 1.969186; lr: 2.5360779633804267e-05; Time/iteration: 0.403m; Time so far/epoch: 0.253h
2024-05-01 23:01:07,828 - trainer - INFO - Train Epoch: 6 dl0 [19584/321526 (6%)] Loss: 1.842857; lr: 2.535100989840032e-05; Time/iteration: 0.393m; Time so far/epoch: 0.260h
2024-05-01 23:01:31,563 - trainer - INFO - Train Epoch: 6 dl0 [20160/321526 (6%)] Loss: 1.864737; lr: 2.5341231795473966e-05; Time/iteration: 0.396m; Time so far/epoch: 0.266h
2024-05-01 23:01:55,520 - trainer - INFO - Train Epoch: 6 dl0 [20736/321526 (6%)] Loss: 1.880638; lr: 2.5331445333045836e-05; Time/iteration: 0.399m; Time so far/epoch: 0.273h
2024-05-01 23:02:20,531 - trainer - INFO - Train Epoch: 6 dl0 [21312/321526 (7%)] Loss: 2.022066; lr: 2.532165051914342e-05; Time/iteration: 0.417m; Time so far/epoch: 0.280h
2024-05-01 23:02:44,601 - trainer - INFO - Train Epoch: 6 dl0 [21888/321526 (7%)] Loss: 2.029308; lr: 2.5311847361801046e-05; Time/iteration: 0.401m; Time so far/epoch: 0.287h
2024-05-01 23:03:08,010 - trainer - INFO - Train Epoch: 6 dl0 [22464/321526 (7%)] Loss: 1.883058; lr: 2.5302035869059892e-05; Time/iteration: 0.390m; Time so far/epoch: 0.293h
2024-05-01 23:03:32,505 - trainer - INFO - Train Epoch: 6 dl0 [23040/321526 (7%)] Loss: 1.899158; lr: 2.5292216048967976e-05; Time/iteration: 0.408m; Time so far/epoch: 0.300h
2024-05-01 23:03:56,552 - trainer - INFO - Train Epoch: 6 dl0 [23616/321526 (7%)] Loss: 1.933108; lr: 2.5282387909580145e-05; Time/iteration: 0.401m; Time so far/epoch: 0.307h
2024-05-01 23:04:20,931 - trainer - INFO - Train Epoch: 6 dl0 [24192/321526 (8%)] Loss: 2.014596; lr: 2.5272551458958062e-05; Time/iteration: 0.406m; Time so far/epoch: 0.313h
2024-05-01 23:04:44,612 - trainer - INFO - Train Epoch: 6 dl0 [24768/321526 (8%)] Loss: 1.969453; lr: 2.5262706705170227e-05; Time/iteration: 0.395m; Time so far/epoch: 0.320h
2024-05-01 23:05:08,423 - trainer - INFO - Train Epoch: 6 dl0 [25344/321526 (8%)] Loss: 1.997969; lr: 2.5252853656291927e-05; Time/iteration: 0.397m; Time so far/epoch: 0.327h
2024-05-01 23:05:32,070 - trainer - INFO - Train Epoch: 6 dl0 [25920/321526 (8%)] Loss: 1.835682; lr: 2.524299232040527e-05; Time/iteration: 0.394m; Time so far/epoch: 0.333h
2024-05-01 23:05:56,715 - trainer - INFO - Train Epoch: 6 dl0 [26496/321526 (8%)] Loss: 1.897745; lr: 2.523312270559915e-05; Time/iteration: 0.411m; Time so far/epoch: 0.340h
2024-05-01 23:06:22,089 - trainer - INFO - Train Epoch: 6 dl0 [27072/321526 (8%)] Loss: 1.953450; lr: 2.5223244819969265e-05; Time/iteration: 0.423m; Time so far/epoch: 0.347h
2024-05-01 23:06:45,981 - trainer - INFO - Train Epoch: 6 dl0 [27648/321526 (9%)] Loss: 1.843548; lr: 2.5213358671618092e-05; Time/iteration: 0.398m; Time so far/epoch: 0.354h
2024-05-01 23:07:09,340 - trainer - INFO - Train Epoch: 6 dl0 [28224/321526 (9%)] Loss: 1.894701; lr: 2.5203464268654875e-05; Time/iteration: 0.389m; Time so far/epoch: 0.360h
2024-05-01 23:07:32,755 - trainer - INFO - Train Epoch: 6 dl0 [28800/321526 (9%)] Loss: 1.943111; lr: 2.5193561619195645e-05; Time/iteration: 0.390m; Time so far/epoch: 0.367h
2024-05-01 23:07:56,794 - trainer - INFO - Train Epoch: 6 dl0 [29376/321526 (9%)] Loss: 1.908421; lr: 2.5183650731363182e-05; Time/iteration: 0.401m; Time so far/epoch: 0.373h
2024-05-01 23:08:21,416 - trainer - INFO - Train Epoch: 6 dl0 [29952/321526 (9%)] Loss: 2.052827; lr: 2.5173731613287044e-05; Time/iteration: 0.410m; Time so far/epoch: 0.380h
2024-05-01 23:08:45,693 - trainer - INFO - Train Epoch: 6 dl0 [30528/321526 (9%)] Loss: 1.897496; lr: 2.5163804273103516e-05; Time/iteration: 0.405m; Time so far/epoch: 0.387h
2024-05-01 23:09:10,022 - trainer - INFO - Train Epoch: 6 dl0 [31104/321526 (10%)] Loss: 1.879481; lr: 2.5153868718955642e-05; Time/iteration: 0.405m; Time so far/epoch: 0.394h
2024-05-01 23:09:33,293 - trainer - INFO - Train Epoch: 6 dl0 [31680/321526 (10%)] Loss: 1.933175; lr: 2.5143924958993207e-05; Time/iteration: 0.388m; Time so far/epoch: 0.400h
2024-05-01 23:09:57,262 - trainer - INFO - Train Epoch: 6 dl0 [32256/321526 (10%)] Loss: 2.003753; lr: 2.5133973001372715e-05; Time/iteration: 0.399m; Time so far/epoch: 0.407h
2024-05-01 23:10:21,399 - trainer - INFO - Train Epoch: 6 dl0 [32832/321526 (10%)] Loss: 1.840578; lr: 2.5124012854257394e-05; Time/iteration: 0.402m; Time so far/epoch: 0.414h
2024-05-01 23:10:46,051 - trainer - INFO - Train Epoch: 6 dl0 [33408/321526 (10%)] Loss: 1.888072; lr: 2.5114044525817207e-05; Time/iteration: 0.411m; Time so far/epoch: 0.420h
2024-05-01 23:11:10,353 - trainer - INFO - Train Epoch: 6 dl0 [33984/321526 (11%)] Loss: 2.014615; lr: 2.510406802422881e-05; Time/iteration: 0.405m; Time so far/epoch: 0.427h
2024-05-01 23:11:34,004 - trainer - INFO - Train Epoch: 6 dl0 [34560/321526 (11%)] Loss: 1.946427; lr: 2.509408335767557e-05; Time/iteration: 0.394m; Time so far/epoch: 0.434h
2024-05-01 23:11:58,215 - trainer - INFO - Train Epoch: 6 dl0 [35136/321526 (11%)] Loss: 1.824821; lr: 2.508409053434755e-05; Time/iteration: 0.404m; Time so far/epoch: 0.440h
2024-05-01 23:12:22,745 - trainer - INFO - Train Epoch: 6 dl0 [35712/321526 (11%)] Loss: 1.983275; lr: 2.5074089562441506e-05; Time/iteration: 0.409m; Time so far/epoch: 0.447h
2024-05-01 23:12:46,807 - trainer - INFO - Train Epoch: 6 dl0 [36288/321526 (11%)] Loss: 1.876325; lr: 2.5064080450160876e-05; Time/iteration: 0.401m; Time so far/epoch: 0.454h
2024-05-01 23:13:10,655 - trainer - INFO - Train Epoch: 6 dl0 [36864/321526 (11%)] Loss: 1.992915; lr: 2.5054063205715775e-05; Time/iteration: 0.397m; Time so far/epoch: 0.461h
2024-05-01 23:13:34,760 - trainer - INFO - Train Epoch: 6 dl0 [37440/321526 (12%)] Loss: 1.897263; lr: 2.5044037837322986e-05; Time/iteration: 0.402m; Time so far/epoch: 0.467h
2024-05-01 23:13:58,754 - trainer - INFO - Train Epoch: 6 dl0 [38016/321526 (12%)] Loss: 1.873741; lr: 2.5034004353205968e-05; Time/iteration: 0.400m; Time so far/epoch: 0.474h
2024-05-01 23:14:23,686 - trainer - INFO - Train Epoch: 6 dl0 [38592/321526 (12%)] Loss: 1.953627; lr: 2.502396276159482e-05; Time/iteration: 0.416m; Time so far/epoch: 0.481h
2024-05-01 23:14:49,187 - trainer - INFO - Train Epoch: 6 dl0 [39168/321526 (12%)] Loss: 2.053833; lr: 2.5013913070726302e-05; Time/iteration: 0.425m; Time so far/epoch: 0.488h
2024-05-01 23:15:13,118 - trainer - INFO - Train Epoch: 6 dl0 [39744/321526 (12%)] Loss: 1.904871; lr: 2.5003855288843815e-05; Time/iteration: 0.399m; Time so far/epoch: 0.495h
2024-05-01 23:15:37,264 - trainer - INFO - Train Epoch: 6 dl0 [40320/321526 (13%)] Loss: 1.827552; lr: 2.4993789424197394e-05; Time/iteration: 0.402m; Time so far/epoch: 0.501h
2024-05-01 23:16:00,901 - trainer - INFO - Train Epoch: 6 dl0 [40896/321526 (13%)] Loss: 1.953422; lr: 2.4983715485043714e-05; Time/iteration: 0.394m; Time so far/epoch: 0.508h
2024-05-01 23:16:24,511 - trainer - INFO - Train Epoch: 6 dl0 [41472/321526 (13%)] Loss: 1.962998; lr: 2.4973633479646055e-05; Time/iteration: 0.393m; Time so far/epoch: 0.514h
2024-05-01 23:16:49,188 - trainer - INFO - Train Epoch: 6 dl0 [42048/321526 (13%)] Loss: 1.976883; lr: 2.4963543416274332e-05; Time/iteration: 0.411m; Time so far/epoch: 0.521h
2024-05-01 23:17:13,769 - trainer - INFO - Train Epoch: 6 dl0 [42624/321526 (13%)] Loss: 2.052950; lr: 2.495344530320506e-05; Time/iteration: 0.410m; Time so far/epoch: 0.528h
2024-05-01 23:17:38,079 - trainer - INFO - Train Epoch: 6 dl0 [43200/321526 (13%)] Loss: 1.907211; lr: 2.4943339148721353e-05; Time/iteration: 0.405m; Time so far/epoch: 0.535h
2024-05-01 23:18:01,608 - trainer - INFO - Train Epoch: 6 dl0 [43776/321526 (14%)] Loss: 1.897903; lr: 2.493322496111294e-05; Time/iteration: 0.392m; Time so far/epoch: 0.541h
2024-05-01 23:18:25,358 - trainer - INFO - Train Epoch: 6 dl0 [44352/321526 (14%)] Loss: 1.948877; lr: 2.492310274867612e-05; Time/iteration: 0.396m; Time so far/epoch: 0.548h
2024-05-01 23:18:49,798 - trainer - INFO - Train Epoch: 6 dl0 [44928/321526 (14%)] Loss: 1.896461; lr: 2.4912972519713775e-05; Time/iteration: 0.407m; Time so far/epoch: 0.555h
2024-05-01 23:19:14,016 - trainer - INFO - Train Epoch: 6 dl0 [45504/321526 (14%)] Loss: 1.848331; lr: 2.4902834282535376e-05; Time/iteration: 0.404m; Time so far/epoch: 0.561h
2024-05-01 23:19:38,680 - trainer - INFO - Train Epoch: 6 dl0 [46080/321526 (14%)] Loss: 1.793022; lr: 2.4892688045456948e-05; Time/iteration: 0.411m; Time so far/epoch: 0.568h
2024-05-01 23:20:02,261 - trainer - INFO - Train Epoch: 6 dl0 [46656/321526 (15%)] Loss: 1.886791; lr: 2.488253381680109e-05; Time/iteration: 0.393m; Time so far/epoch: 0.575h
2024-05-01 23:20:26,434 - trainer - INFO - Train Epoch: 6 dl0 [47232/321526 (15%)] Loss: 1.960425; lr: 2.487237160489695e-05; Time/iteration: 0.403m; Time so far/epoch: 0.582h
2024-05-01 23:20:50,020 - trainer - INFO - Train Epoch: 6 dl0 [47808/321526 (15%)] Loss: 1.801042; lr: 2.486220141808023e-05; Time/iteration: 0.393m; Time so far/epoch: 0.588h
2024-05-01 23:21:14,432 - trainer - INFO - Train Epoch: 6 dl0 [48384/321526 (15%)] Loss: 1.797361; lr: 2.4852023264693163e-05; Time/iteration: 0.407m; Time so far/epoch: 0.595h
2024-05-01 23:21:39,038 - trainer - INFO - Train Epoch: 6 dl0 [48960/321526 (15%)] Loss: 1.920007; lr: 2.4841837153084527e-05; Time/iteration: 0.410m; Time so far/epoch: 0.602h
2024-05-01 23:22:03,161 - trainer - INFO - Train Epoch: 6 dl0 [49536/321526 (15%)] Loss: 1.871751; lr: 2.483164309160962e-05; Time/iteration: 0.402m; Time so far/epoch: 0.608h
2024-05-01 23:22:26,501 - trainer - INFO - Train Epoch: 6 dl0 [50112/321526 (16%)] Loss: 1.924121; lr: 2.482144108863027e-05; Time/iteration: 0.389m; Time so far/epoch: 0.615h
2024-05-01 23:22:49,914 - trainer - INFO - Train Epoch: 6 dl0 [50688/321526 (16%)] Loss: 1.955652; lr: 2.4811231152514813e-05; Time/iteration: 0.390m; Time so far/epoch: 0.621h
2024-05-01 23:23:13,343 - trainer - INFO - Train Epoch: 6 dl0 [51264/321526 (16%)] Loss: 1.847107; lr: 2.4801013291638093e-05; Time/iteration: 0.390m; Time so far/epoch: 0.628h
2024-05-01 23:23:38,214 - trainer - INFO - Train Epoch: 6 dl0 [51840/321526 (16%)] Loss: 2.071993; lr: 2.479078751438145e-05; Time/iteration: 0.415m; Time so far/epoch: 0.635h
2024-05-01 23:24:02,957 - trainer - INFO - Train Epoch: 6 dl0 [52416/321526 (16%)] Loss: 1.947389; lr: 2.4780553829132728e-05; Time/iteration: 0.412m; Time so far/epoch: 0.642h
2024-05-01 23:24:28,375 - trainer - INFO - Train Epoch: 6 dl0 [52992/321526 (16%)] Loss: 1.949503; lr: 2.477031224428625e-05; Time/iteration: 0.424m; Time so far/epoch: 0.649h
2024-05-01 23:24:52,977 - trainer - INFO - Train Epoch: 6 dl0 [53568/321526 (17%)] Loss: 1.998529; lr: 2.4760062768242813e-05; Time/iteration: 0.410m; Time so far/epoch: 0.656h
2024-05-01 23:25:17,804 - trainer - INFO - Train Epoch: 6 dl0 [54144/321526 (17%)] Loss: 1.952887; lr: 2.4749805409409708e-05; Time/iteration: 0.414m; Time so far/epoch: 0.663h
2024-05-01 23:25:41,181 - trainer - INFO - Train Epoch: 6 dl0 [54720/321526 (17%)] Loss: 2.071494; lr: 2.4739540176200666e-05; Time/iteration: 0.390m; Time so far/epoch: 0.669h
2024-05-01 23:26:05,330 - trainer - INFO - Train Epoch: 6 dl0 [55296/321526 (17%)] Loss: 2.059731; lr: 2.47292670770359e-05; Time/iteration: 0.402m; Time so far/epoch: 0.676h
2024-05-01 23:26:29,951 - trainer - INFO - Train Epoch: 6 dl0 [55872/321526 (17%)] Loss: 1.907868; lr: 2.4718986120342057e-05; Time/iteration: 0.410m; Time so far/epoch: 0.683h
2024-05-01 23:26:54,296 - trainer - INFO - Train Epoch: 6 dl0 [56448/321526 (18%)] Loss: 2.033444; lr: 2.4708697314552246e-05; Time/iteration: 0.406m; Time so far/epoch: 0.689h
2024-05-01 23:27:18,928 - trainer - INFO - Train Epoch: 6 dl0 [57024/321526 (18%)] Loss: 1.836352; lr: 2.4698400668105996e-05; Time/iteration: 0.411m; Time so far/epoch: 0.696h
2024-05-01 23:27:42,499 - trainer - INFO - Train Epoch: 6 dl0 [57600/321526 (18%)] Loss: 1.911285; lr: 2.4688096189449277e-05; Time/iteration: 0.393m; Time so far/epoch: 0.703h
2024-05-01 23:28:07,209 - trainer - INFO - Train Epoch: 6 dl0 [58176/321526 (18%)] Loss: 1.965780; lr: 2.4677783887034488e-05; Time/iteration: 0.412m; Time so far/epoch: 0.710h
2024-05-01 23:28:31,588 - trainer - INFO - Train Epoch: 6 dl0 [58752/321526 (18%)] Loss: 1.929147; lr: 2.466746376932044e-05; Time/iteration: 0.406m; Time so far/epoch: 0.716h
2024-05-01 23:28:58,341 - trainer - INFO - Train Epoch: 6 dl0 [59328/321526 (18%)] Loss: 1.881444; lr: 2.465713584477235e-05; Time/iteration: 0.446m; Time so far/epoch: 0.724h
2024-05-01 23:29:23,804 - trainer - INFO - Train Epoch: 6 dl0 [59904/321526 (19%)] Loss: 1.936696; lr: 2.464680012186185e-05; Time/iteration: 0.424m; Time so far/epoch: 0.731h
2024-05-01 23:29:48,546 - trainer - INFO - Train Epoch: 6 dl0 [60480/321526 (19%)] Loss: 1.944395; lr: 2.463645660906696e-05; Time/iteration: 0.412m; Time so far/epoch: 0.738h
2024-05-01 23:30:13,063 - trainer - INFO - Train Epoch: 6 dl0 [61056/321526 (19%)] Loss: 1.974502; lr: 2.4626105314872092e-05; Time/iteration: 0.409m; Time so far/epoch: 0.745h
2024-05-01 23:30:37,724 - trainer - INFO - Train Epoch: 6 dl0 [61632/321526 (19%)] Loss: 1.872454; lr: 2.4615746247768045e-05; Time/iteration: 0.411m; Time so far/epoch: 0.751h
2024-05-01 23:31:03,078 - trainer - INFO - Train Epoch: 6 dl0 [62208/321526 (19%)] Loss: 1.783401; lr: 2.4605379416251983e-05; Time/iteration: 0.422m; Time so far/epoch: 0.758h
2024-05-01 23:31:28,628 - trainer - INFO - Train Epoch: 6 dl0 [62784/321526 (20%)] Loss: 1.889563; lr: 2.4595004828827453e-05; Time/iteration: 0.426m; Time so far/epoch: 0.766h
2024-05-01 23:31:53,172 - trainer - INFO - Train Epoch: 6 dl0 [63360/321526 (20%)] Loss: 1.880506; lr: 2.4584622494004352e-05; Time/iteration: 0.409m; Time so far/epoch: 0.772h
2024-05-01 23:32:17,909 - trainer - INFO - Train Epoch: 6 dl0 [63936/321526 (20%)] Loss: 1.859294; lr: 2.457423242029894e-05; Time/iteration: 0.412m; Time so far/epoch: 0.779h
2024-05-01 23:32:42,401 - trainer - INFO - Train Epoch: 6 dl0 [64512/321526 (20%)] Loss: 1.818492; lr: 2.4563834616233816e-05; Time/iteration: 0.408m; Time so far/epoch: 0.786h
2024-05-01 23:33:08,233 - trainer - INFO - Train Epoch: 6 dl0 [65088/321526 (20%)] Loss: 1.898748; lr: 2.4553429090337934e-05; Time/iteration: 0.431m; Time so far/epoch: 0.793h
2024-05-01 23:33:32,487 - trainer - INFO - Train Epoch: 6 dl0 [65664/321526 (20%)] Loss: 1.844846; lr: 2.4543015851146566e-05; Time/iteration: 0.404m; Time so far/epoch: 0.800h
2024-05-01 23:33:57,219 - trainer - INFO - Train Epoch: 6 dl0 [66240/321526 (21%)] Loss: 1.807237; lr: 2.4532594907201326e-05; Time/iteration: 0.412m; Time so far/epoch: 0.807h
2024-05-01 23:34:21,403 - trainer - INFO - Train Epoch: 6 dl0 [66816/321526 (21%)] Loss: 1.897143; lr: 2.4522166267050133e-05; Time/iteration: 0.403m; Time so far/epoch: 0.814h
2024-05-01 23:34:46,369 - trainer - INFO - Train Epoch: 6 dl0 [67392/321526 (21%)] Loss: 2.063903; lr: 2.4511729939247233e-05; Time/iteration: 0.416m; Time so far/epoch: 0.820h
2024-05-01 23:35:11,089 - trainer - INFO - Train Epoch: 6 dl0 [67968/321526 (21%)] Loss: 1.829627; lr: 2.4501285932353164e-05; Time/iteration: 0.412m; Time so far/epoch: 0.827h
2024-05-01 23:35:36,305 - trainer - INFO - Train Epoch: 6 dl0 [68544/321526 (21%)] Loss: 1.879840; lr: 2.4490834254934775e-05; Time/iteration: 0.420m; Time so far/epoch: 0.834h
2024-05-01 23:36:00,382 - trainer - INFO - Train Epoch: 6 dl0 [69120/321526 (21%)] Loss: 1.810831; lr: 2.44803749155652e-05; Time/iteration: 0.401m; Time so far/epoch: 0.841h
2024-05-01 23:36:24,234 - trainer - INFO - Train Epoch: 6 dl0 [69696/321526 (22%)] Loss: 2.109339; lr: 2.4469907922823863e-05; Time/iteration: 0.398m; Time so far/epoch: 0.848h
2024-05-01 23:36:48,765 - trainer - INFO - Train Epoch: 6 dl0 [70272/321526 (22%)] Loss: 1.905067; lr: 2.445943328529646e-05; Time/iteration: 0.409m; Time so far/epoch: 0.854h
2024-05-01 23:37:13,390 - trainer - INFO - Train Epoch: 6 dl0 [70848/321526 (22%)] Loss: 1.931977; lr: 2.4448951011574958e-05; Time/iteration: 0.410m; Time so far/epoch: 0.861h
2024-05-01 23:37:38,925 - trainer - INFO - Train Epoch: 6 dl0 [71424/321526 (22%)] Loss: 1.862657; lr: 2.4438461110257598e-05; Time/iteration: 0.426m; Time so far/epoch: 0.868h
2024-05-01 23:38:03,252 - trainer - INFO - Train Epoch: 6 dl0 [72000/321526 (22%)] Loss: 1.897750; lr: 2.442796358994886e-05; Time/iteration: 0.405m; Time so far/epoch: 0.875h
2024-05-01 23:38:27,824 - trainer - INFO - Train Epoch: 6 dl0 [72576/321526 (23%)] Loss: 1.820801; lr: 2.441745845925948e-05; Time/iteration: 0.410m; Time so far/epoch: 0.882h
2024-05-01 23:38:53,083 - trainer - INFO - Train Epoch: 6 dl0 [73152/321526 (23%)] Loss: 1.882128; lr: 2.440694572680646e-05; Time/iteration: 0.421m; Time so far/epoch: 0.889h
2024-05-01 23:39:17,545 - trainer - INFO - Train Epoch: 6 dl0 [73728/321526 (23%)] Loss: 1.887471; lr: 2.4396425401213e-05; Time/iteration: 0.408m; Time so far/epoch: 0.896h
2024-05-01 23:39:42,076 - trainer - INFO - Train Epoch: 6 dl0 [74304/321526 (23%)] Loss: 1.973035; lr: 2.438589749110855e-05; Time/iteration: 0.409m; Time so far/epoch: 0.903h
2024-05-01 23:40:06,937 - trainer - INFO - Train Epoch: 6 dl0 [74880/321526 (23%)] Loss: 1.887285; lr: 2.4375362005128774e-05; Time/iteration: 0.414m; Time so far/epoch: 0.910h
2024-05-01 23:40:32,150 - trainer - INFO - Train Epoch: 6 dl0 [75456/321526 (23%)] Loss: 1.985312; lr: 2.4364818951915562e-05; Time/iteration: 0.420m; Time so far/epoch: 0.917h
2024-05-01 23:40:56,333 - trainer - INFO - Train Epoch: 6 dl0 [76032/321526 (24%)] Loss: 1.994799; lr: 2.4354268340116994e-05; Time/iteration: 0.403m; Time so far/epoch: 0.923h
2024-05-01 23:41:21,249 - trainer - INFO - Train Epoch: 6 dl0 [76608/321526 (24%)] Loss: 1.937265; lr: 2.434371017838736e-05; Time/iteration: 0.415m; Time so far/epoch: 0.930h
2024-05-01 23:41:45,885 - trainer - INFO - Train Epoch: 6 dl0 [77184/321526 (24%)] Loss: 1.901591; lr: 2.433314447538714e-05; Time/iteration: 0.411m; Time so far/epoch: 0.937h
2024-05-01 23:42:10,917 - trainer - INFO - Train Epoch: 6 dl0 [77760/321526 (24%)] Loss: 1.937208; lr: 2.4322571239783007e-05; Time/iteration: 0.417m; Time so far/epoch: 0.944h
2024-05-01 23:42:35,308 - trainer - INFO - Train Epoch: 6 dl0 [78336/321526 (24%)] Loss: 1.955591; lr: 2.43119904802478e-05; Time/iteration: 0.406m; Time so far/epoch: 0.951h
2024-05-01 23:42:59,469 - trainer - INFO - Train Epoch: 6 dl0 [78912/321526 (25%)] Loss: 1.883646; lr: 2.430140220546054e-05; Time/iteration: 0.403m; Time so far/epoch: 0.957h
2024-05-01 23:43:24,494 - trainer - INFO - Train Epoch: 6 dl0 [79488/321526 (25%)] Loss: 1.944928; lr: 2.429080642410641e-05; Time/iteration: 0.417m; Time so far/epoch: 0.964h
2024-05-01 23:43:50,470 - trainer - INFO - Train Epoch: 6 dl0 [80064/321526 (25%)] Loss: 1.880157; lr: 2.4280203144876742e-05; Time/iteration: 0.433m; Time so far/epoch: 0.972h
2024-05-01 23:44:14,965 - trainer - INFO - Train Epoch: 6 dl0 [80640/321526 (25%)] Loss: 1.873145; lr: 2.4269592376469035e-05; Time/iteration: 0.408m; Time so far/epoch: 0.978h
2024-05-01 23:44:39,172 - trainer - INFO - Train Epoch: 6 dl0 [81216/321526 (25%)] Loss: 1.880245; lr: 2.4258974127586918e-05; Time/iteration: 0.403m; Time so far/epoch: 0.985h
2024-05-01 23:45:03,234 - trainer - INFO - Train Epoch: 6 dl0 [81792/321526 (25%)] Loss: 1.968245; lr: 2.424834840694016e-05; Time/iteration: 0.401m; Time so far/epoch: 0.992h
2024-05-01 23:45:27,947 - trainer - INFO - Train Epoch: 6 dl0 [82368/321526 (26%)] Loss: 2.011716; lr: 2.4237715223244652e-05; Time/iteration: 0.412m; Time so far/epoch: 0.999h
2024-05-01 23:45:52,832 - trainer - INFO - Train Epoch: 6 dl0 [82944/321526 (26%)] Loss: 2.022416; lr: 2.422707458522242e-05; Time/iteration: 0.415m; Time so far/epoch: 1.006h
2024-05-01 23:46:17,044 - trainer - INFO - Train Epoch: 6 dl0 [83520/321526 (26%)] Loss: 1.961344; lr: 2.42164265016016e-05; Time/iteration: 0.404m; Time so far/epoch: 1.012h
2024-05-01 23:46:41,088 - trainer - INFO - Train Epoch: 6 dl0 [84096/321526 (26%)] Loss: 1.962961; lr: 2.4205770981116426e-05; Time/iteration: 0.401m; Time so far/epoch: 1.019h
2024-05-01 23:47:05,059 - trainer - INFO - Train Epoch: 6 dl0 [84672/321526 (26%)] Loss: 2.076919; lr: 2.4195108032507244e-05; Time/iteration: 0.400m; Time so far/epoch: 1.026h
2024-05-01 23:47:30,360 - trainer - INFO - Train Epoch: 6 dl0 [85248/321526 (27%)] Loss: 2.023037; lr: 2.4184437664520484e-05; Time/iteration: 0.422m; Time so far/epoch: 1.033h
2024-05-01 23:47:56,041 - trainer - INFO - Train Epoch: 6 dl0 [85824/321526 (27%)] Loss: 1.948334; lr: 2.417375988590867e-05; Time/iteration: 0.428m; Time so far/epoch: 1.040h
2024-05-01 23:48:20,493 - trainer - INFO - Train Epoch: 6 dl0 [86400/321526 (27%)] Loss: 1.920752; lr: 2.41630747054304e-05; Time/iteration: 0.408m; Time so far/epoch: 1.047h
2024-05-01 23:48:45,087 - trainer - INFO - Train Epoch: 6 dl0 [86976/321526 (27%)] Loss: 1.844223; lr: 2.415238213185034e-05; Time/iteration: 0.410m; Time so far/epoch: 1.053h
2024-05-01 23:49:08,367 - trainer - INFO - Train Epoch: 6 dl0 [87552/321526 (27%)] Loss: 1.897743; lr: 2.414168217393923e-05; Time/iteration: 0.388m; Time so far/epoch: 1.060h
2024-05-01 23:49:33,355 - trainer - INFO - Train Epoch: 6 dl0 [88128/321526 (27%)] Loss: 1.902136; lr: 2.4130974840473855e-05; Time/iteration: 0.416m; Time so far/epoch: 1.067h
2024-05-01 23:49:58,302 - trainer - INFO - Train Epoch: 6 dl0 [88704/321526 (28%)] Loss: 1.930827; lr: 2.4120260140237066e-05; Time/iteration: 0.416m; Time so far/epoch: 1.074h
2024-05-01 23:50:22,343 - trainer - INFO - Train Epoch: 6 dl0 [89280/321526 (28%)] Loss: 1.868008; lr: 2.410953808201774e-05; Time/iteration: 0.401m; Time so far/epoch: 1.080h
2024-05-01 23:50:46,811 - trainer - INFO - Train Epoch: 6 dl0 [89856/321526 (28%)] Loss: 1.990076; lr: 2.4098808674610797e-05; Time/iteration: 0.408m; Time so far/epoch: 1.087h
2024-05-01 23:51:11,243 - trainer - INFO - Train Epoch: 6 dl0 [90432/321526 (28%)] Loss: 1.868108; lr: 2.4088071926817188e-05; Time/iteration: 0.407m; Time so far/epoch: 1.094h
2024-05-01 23:51:35,769 - trainer - INFO - Train Epoch: 6 dl0 [91008/321526 (28%)] Loss: 1.858579; lr: 2.4077327847443878e-05; Time/iteration: 0.409m; Time so far/epoch: 1.101h
2024-05-01 23:52:00,347 - trainer - INFO - Train Epoch: 6 dl0 [91584/321526 (28%)] Loss: 1.929839; lr: 2.4066576445303854e-05; Time/iteration: 0.410m; Time so far/epoch: 1.108h
2024-05-01 23:52:24,955 - trainer - INFO - Train Epoch: 6 dl0 [92160/321526 (29%)] Loss: 1.817797; lr: 2.4055817729216103e-05; Time/iteration: 0.410m; Time so far/epoch: 1.115h
2024-05-01 23:52:49,492 - trainer - INFO - Train Epoch: 6 dl0 [92736/321526 (29%)] Loss: 2.045507; lr: 2.4045051708005615e-05; Time/iteration: 0.409m; Time so far/epoch: 1.121h
2024-05-01 23:53:14,109 - trainer - INFO - Train Epoch: 6 dl0 [93312/321526 (29%)] Loss: 1.873557; lr: 2.403427839050337e-05; Time/iteration: 0.410m; Time so far/epoch: 1.128h
2024-05-01 23:53:38,850 - trainer - INFO - Train Epoch: 6 dl0 [93888/321526 (29%)] Loss: 1.830104; lr: 2.4023497785546334e-05; Time/iteration: 0.412m; Time so far/epoch: 1.135h
2024-05-01 23:54:03,290 - trainer - INFO - Train Epoch: 6 dl0 [94464/321526 (29%)] Loss: 1.889746; lr: 2.401270990197745e-05; Time/iteration: 0.407m; Time so far/epoch: 1.142h
2024-05-01 23:54:27,983 - trainer - INFO - Train Epoch: 6 dl0 [95040/321526 (30%)] Loss: 1.962001; lr: 2.4001914748645635e-05; Time/iteration: 0.412m; Time so far/epoch: 1.149h
2024-05-01 23:54:51,688 - trainer - INFO - Train Epoch: 6 dl0 [95616/321526 (30%)] Loss: 1.925862; lr: 2.3991112334405756e-05; Time/iteration: 0.395m; Time so far/epoch: 1.155h
2024-05-01 23:55:15,943 - trainer - INFO - Train Epoch: 6 dl0 [96192/321526 (30%)] Loss: 1.831094; lr: 2.3980302668118657e-05; Time/iteration: 0.404m; Time so far/epoch: 1.162h
2024-05-01 23:55:40,605 - trainer - INFO - Train Epoch: 6 dl0 [96768/321526 (30%)] Loss: 1.972957; lr: 2.3969485758651118e-05; Time/iteration: 0.411m; Time so far/epoch: 1.169h
2024-05-01 23:56:06,066 - trainer - INFO - Train Epoch: 6 dl0 [97344/321526 (30%)] Loss: 1.937736; lr: 2.3958661614875858e-05; Time/iteration: 0.424m; Time so far/epoch: 1.176h
2024-05-01 23:56:31,203 - trainer - INFO - Train Epoch: 6 dl0 [97920/321526 (30%)] Loss: 1.868002; lr: 2.394783024567153e-05; Time/iteration: 0.419m; Time so far/epoch: 1.183h
2024-05-01 23:56:55,325 - trainer - INFO - Train Epoch: 6 dl0 [98496/321526 (31%)] Loss: 1.831986; lr: 2.3936991659922722e-05; Time/iteration: 0.402m; Time so far/epoch: 1.190h
2024-05-01 23:57:19,494 - trainer - INFO - Train Epoch: 6 dl0 [99072/321526 (31%)] Loss: 1.828219; lr: 2.3926145866519947e-05; Time/iteration: 0.403m; Time so far/epoch: 1.196h
2024-05-01 23:57:44,009 - trainer - INFO - Train Epoch: 6 dl0 [99648/321526 (31%)] Loss: 1.938411; lr: 2.3915292874359605e-05; Time/iteration: 0.409m; Time so far/epoch: 1.203h
2024-05-02 00:01:28,796 - trainer - INFO - EgoClip_HOI epoch 6, Verb-Neg, Acc: 56.1;    EgoClip_HOI epoch 6, Noun-Neg, Acc: 69.1;    EgoClip_HOI epoch 6, HOI-Neg, Acc: 41.6;    
2024-05-02 00:01:28,805 - trainer - INFO -     epoch          : 6
2024-05-02 00:01:28,806 - trainer - INFO -     loss_0         : 0.5973732506433411
2024-05-02 00:01:28,806 - trainer - INFO -     val_loss_0     : 0.0
2024-05-02 00:01:28,806 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 56.113433837890625
2024-05-02 00:01:28,806 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 69.05854034423828
2024-05-02 00:01:28,806 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.634071350097656
2024-05-02 00:01:29,884 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch6.pth ...
2024-05-02 00:01:31,467 - trainer - INFO - Saving current best: model_best.pth ...
2024-05-02 00:02:40,763 - trainer - INFO - Train Epoch: 7 dl0 [0/321526 (0%)] Loss: 1.948643; lr: 2.390986368152709e-05; Time/iteration: 1.155m; Time so far/epoch: 0.019h
2024-05-02 00:03:07,438 - trainer - INFO - Train Epoch: 7 dl0 [576/321526 (0%)] Loss: 1.882272; lr: 2.3898999907924103e-05; Time/iteration: 0.444m; Time so far/epoch: 0.027h
2024-05-02 00:03:43,268 - trainer - INFO - Train Epoch: 7 dl0 [1152/321526 (0%)] Loss: 1.819586; lr: 2.3888128957830402e-05; Time/iteration: 0.597m; Time so far/epoch: 0.037h
2024-05-02 00:04:10,768 - trainer - INFO - Train Epoch: 7 dl0 [1728/321526 (1%)] Loss: 1.887057; lr: 2.3877250840163052e-05; Time/iteration: 0.458m; Time so far/epoch: 0.044h
2024-05-02 00:04:37,408 - trainer - INFO - Train Epoch: 7 dl0 [2304/321526 (1%)] Loss: 1.817795; lr: 2.386636556384497e-05; Time/iteration: 0.444m; Time so far/epoch: 0.052h
2024-05-02 00:05:05,171 - trainer - INFO - Train Epoch: 7 dl0 [2880/321526 (1%)] Loss: 1.969278; lr: 2.385547313780497e-05; Time/iteration: 0.463m; Time so far/epoch: 0.059h
2024-05-02 00:05:32,268 - trainer - INFO - Train Epoch: 7 dl0 [3456/321526 (1%)] Loss: 1.948415; lr: 2.384457357097771e-05; Time/iteration: 0.452m; Time so far/epoch: 0.067h
2024-05-02 00:06:04,902 - trainer - INFO - Train Epoch: 7 dl0 [4032/321526 (1%)] Loss: 1.938301; lr: 2.3833666872303713e-05; Time/iteration: 0.544m; Time so far/epoch: 0.076h
2024-05-02 00:06:31,723 - trainer - INFO - Train Epoch: 7 dl0 [4608/321526 (1%)] Loss: 1.890660; lr: 2.3822753050729362e-05; Time/iteration: 0.447m; Time so far/epoch: 0.083h
2024-05-02 00:06:57,689 - trainer - INFO - Train Epoch: 7 dl0 [5184/321526 (2%)] Loss: 1.874696; lr: 2.3811832115206864e-05; Time/iteration: 0.433m; Time so far/epoch: 0.091h
2024-05-02 00:07:23,903 - trainer - INFO - Train Epoch: 7 dl0 [5760/321526 (2%)] Loss: 1.840547; lr: 2.380090407469427e-05; Time/iteration: 0.437m; Time so far/epoch: 0.098h
2024-05-02 00:07:49,294 - trainer - INFO - Train Epoch: 7 dl0 [6336/321526 (2%)] Loss: 1.818831; lr: 2.3789968938155464e-05; Time/iteration: 0.423m; Time so far/epoch: 0.105h
2024-05-02 00:08:13,870 - trainer - INFO - Train Epoch: 7 dl0 [6912/321526 (2%)] Loss: 1.933895; lr: 2.3779026714560147e-05; Time/iteration: 0.410m; Time so far/epoch: 0.112h
2024-05-02 00:08:38,632 - trainer - INFO - Train Epoch: 7 dl0 [7488/321526 (2%)] Loss: 1.929852; lr: 2.3768077412883826e-05; Time/iteration: 0.413m; Time so far/epoch: 0.119h
2024-05-02 00:09:03,434 - trainer - INFO - Train Epoch: 7 dl0 [8064/321526 (3%)] Loss: 2.023058; lr: 2.3757121042107828e-05; Time/iteration: 0.413m; Time so far/epoch: 0.126h
2024-05-02 00:09:28,660 - trainer - INFO - Train Epoch: 7 dl0 [8640/321526 (3%)] Loss: 1.913005; lr: 2.3746157611219265e-05; Time/iteration: 0.420m; Time so far/epoch: 0.133h
2024-05-02 00:09:52,897 - trainer - INFO - Train Epoch: 7 dl0 [9216/321526 (3%)] Loss: 1.974179; lr: 2.3735187129211048e-05; Time/iteration: 0.404m; Time so far/epoch: 0.139h
2024-05-02 00:10:17,546 - trainer - INFO - Train Epoch: 7 dl0 [9792/321526 (3%)] Loss: 1.841420; lr: 2.3724209605081872e-05; Time/iteration: 0.411m; Time so far/epoch: 0.146h
2024-05-02 00:10:41,612 - trainer - INFO - Train Epoch: 7 dl0 [10368/321526 (3%)] Loss: 1.973759; lr: 2.3713225047836206e-05; Time/iteration: 0.401m; Time so far/epoch: 0.153h
2024-05-02 00:11:06,060 - trainer - INFO - Train Epoch: 7 dl0 [10944/321526 (3%)] Loss: 1.860266; lr: 2.3702233466484285e-05; Time/iteration: 0.407m; Time so far/epoch: 0.160h
2024-05-02 00:11:31,835 - trainer - INFO - Train Epoch: 7 dl0 [11520/321526 (4%)] Loss: 1.949793; lr: 2.369123487004211e-05; Time/iteration: 0.430m; Time so far/epoch: 0.167h
2024-05-02 00:11:55,850 - trainer - INFO - Train Epoch: 7 dl0 [12096/321526 (4%)] Loss: 1.978542; lr: 2.3680229267531433e-05; Time/iteration: 0.400m; Time so far/epoch: 0.173h
2024-05-02 00:12:19,841 - trainer - INFO - Train Epoch: 7 dl0 [12672/321526 (4%)] Loss: 1.817063; lr: 2.3669216667979758e-05; Time/iteration: 0.400m; Time so far/epoch: 0.180h
2024-05-02 00:12:43,678 - trainer - INFO - Train Epoch: 7 dl0 [13248/321526 (4%)] Loss: 1.980127; lr: 2.3658197080420325e-05; Time/iteration: 0.397m; Time so far/epoch: 0.187h
2024-05-02 00:13:09,541 - trainer - INFO - Train Epoch: 7 dl0 [13824/321526 (4%)] Loss: 1.992437; lr: 2.36471705138921e-05; Time/iteration: 0.431m; Time so far/epoch: 0.194h
2024-05-02 00:13:34,269 - trainer - INFO - Train Epoch: 7 dl0 [14400/321526 (4%)] Loss: 1.858627; lr: 2.36361369774398e-05; Time/iteration: 0.412m; Time so far/epoch: 0.201h
2024-05-02 00:13:58,706 - trainer - INFO - Train Epoch: 7 dl0 [14976/321526 (5%)] Loss: 1.932220; lr: 2.362509648011381e-05; Time/iteration: 0.407m; Time so far/epoch: 0.208h
2024-05-02 00:14:24,163 - trainer - INFO - Train Epoch: 7 dl0 [15552/321526 (5%)] Loss: 1.856459; lr: 2.3614049030970278e-05; Time/iteration: 0.424m; Time so far/epoch: 0.215h
2024-05-02 00:14:48,499 - trainer - INFO - Train Epoch: 7 dl0 [16128/321526 (5%)] Loss: 2.059928; lr: 2.3602994639071015e-05; Time/iteration: 0.406m; Time so far/epoch: 0.221h
2024-05-02 00:15:12,835 - trainer - INFO - Train Epoch: 7 dl0 [16704/321526 (5%)] Loss: 1.906482; lr: 2.3591933313483547e-05; Time/iteration: 0.405m; Time so far/epoch: 0.228h
2024-05-02 00:15:37,044 - trainer - INFO - Train Epoch: 7 dl0 [17280/321526 (5%)] Loss: 2.103345; lr: 2.3580865063281087e-05; Time/iteration: 0.403m; Time so far/epoch: 0.235h
2024-05-02 00:16:02,234 - trainer - INFO - Train Epoch: 7 dl0 [17856/321526 (6%)] Loss: 1.950940; lr: 2.3569789897542514e-05; Time/iteration: 0.420m; Time so far/epoch: 0.242h
2024-05-02 00:16:27,332 - trainer - INFO - Train Epoch: 7 dl0 [18432/321526 (6%)] Loss: 1.912460; lr: 2.35587078253524e-05; Time/iteration: 0.418m; Time so far/epoch: 0.249h
2024-05-02 00:16:51,375 - trainer - INFO - Train Epoch: 7 dl0 [19008/321526 (6%)] Loss: 1.896530; lr: 2.3547618855800965e-05; Time/iteration: 0.401m; Time so far/epoch: 0.256h
2024-05-02 00:17:15,819 - trainer - INFO - Train Epoch: 7 dl0 [19584/321526 (6%)] Loss: 1.894648; lr: 2.3536522997984092e-05; Time/iteration: 0.407m; Time so far/epoch: 0.262h
2024-05-02 00:17:40,509 - trainer - INFO - Train Epoch: 7 dl0 [20160/321526 (6%)] Loss: 1.871808; lr: 2.3525420261003318e-05; Time/iteration: 0.411m; Time so far/epoch: 0.269h
2024-05-02 00:18:05,781 - trainer - INFO - Train Epoch: 7 dl0 [20736/321526 (6%)] Loss: 1.814874; lr: 2.3514310653965817e-05; Time/iteration: 0.421m; Time so far/epoch: 0.276h
2024-05-02 00:18:31,482 - trainer - INFO - Train Epoch: 7 dl0 [21312/321526 (7%)] Loss: 1.801792; lr: 2.350319418598441e-05; Time/iteration: 0.428m; Time so far/epoch: 0.283h
2024-05-02 00:18:58,054 - trainer - INFO - Train Epoch: 7 dl0 [21888/321526 (7%)] Loss: 2.005156; lr: 2.3492070866177518e-05; Time/iteration: 0.443m; Time so far/epoch: 0.291h
2024-05-02 00:19:24,923 - trainer - INFO - Train Epoch: 7 dl0 [22464/321526 (7%)] Loss: 1.948538; lr: 2.3480940703669216e-05; Time/iteration: 0.448m; Time so far/epoch: 0.298h
2024-05-02 00:19:51,124 - trainer - INFO - Train Epoch: 7 dl0 [23040/321526 (7%)] Loss: 1.960784; lr: 2.3469803707589178e-05; Time/iteration: 0.437m; Time so far/epoch: 0.305h
2024-05-02 00:20:17,412 - trainer - INFO - Train Epoch: 7 dl0 [23616/321526 (7%)] Loss: 1.938787; lr: 2.3458659887072673e-05; Time/iteration: 0.438m; Time so far/epoch: 0.313h
2024-05-02 00:20:43,240 - trainer - INFO - Train Epoch: 7 dl0 [24192/321526 (8%)] Loss: 1.925075; lr: 2.344750925126058e-05; Time/iteration: 0.430m; Time so far/epoch: 0.320h
2024-05-02 00:21:08,802 - trainer - INFO - Train Epoch: 7 dl0 [24768/321526 (8%)] Loss: 2.095294; lr: 2.3436351809299375e-05; Time/iteration: 0.426m; Time so far/epoch: 0.327h
2024-05-02 00:21:34,691 - trainer - INFO - Train Epoch: 7 dl0 [25344/321526 (8%)] Loss: 1.785061; lr: 2.3425187570341095e-05; Time/iteration: 0.431m; Time so far/epoch: 0.334h
2024-05-02 00:21:59,838 - trainer - INFO - Train Epoch: 7 dl0 [25920/321526 (8%)] Loss: 1.922375; lr: 2.341401654354337e-05; Time/iteration: 0.419m; Time so far/epoch: 0.341h
2024-05-02 00:22:25,947 - trainer - INFO - Train Epoch: 7 dl0 [26496/321526 (8%)] Loss: 1.848618; lr: 2.340283873806939e-05; Time/iteration: 0.435m; Time so far/epoch: 0.348h
2024-05-02 00:22:49,526 - trainer - INFO - Train Epoch: 7 dl0 [27072/321526 (8%)] Loss: 1.933781; lr: 2.339165416308791e-05; Time/iteration: 0.393m; Time so far/epoch: 0.355h
2024-05-02 00:23:13,138 - trainer - INFO - Train Epoch: 7 dl0 [27648/321526 (9%)] Loss: 1.921986; lr: 2.3380462827773238e-05; Time/iteration: 0.394m; Time so far/epoch: 0.362h
2024-05-02 00:23:36,552 - trainer - INFO - Train Epoch: 7 dl0 [28224/321526 (9%)] Loss: 1.917282; lr: 2.336926474130522e-05; Time/iteration: 0.390m; Time so far/epoch: 0.368h
2024-05-02 00:24:00,967 - trainer - INFO - Train Epoch: 7 dl0 [28800/321526 (9%)] Loss: 1.928073; lr: 2.335805991286924e-05; Time/iteration: 0.407m; Time so far/epoch: 0.375h
2024-05-02 00:24:25,479 - trainer - INFO - Train Epoch: 7 dl0 [29376/321526 (9%)] Loss: 1.976804; lr: 2.334684835165623e-05; Time/iteration: 0.409m; Time so far/epoch: 0.382h
2024-05-02 00:24:49,160 - trainer - INFO - Train Epoch: 7 dl0 [29952/321526 (9%)] Loss: 1.915827; lr: 2.3335630066862625e-05; Time/iteration: 0.395m; Time so far/epoch: 0.388h
2024-05-02 00:25:12,812 - trainer - INFO - Train Epoch: 7 dl0 [30528/321526 (9%)] Loss: 1.964717; lr: 2.3324405067690377e-05; Time/iteration: 0.394m; Time so far/epoch: 0.395h
2024-05-02 00:25:36,191 - trainer - INFO - Train Epoch: 7 dl0 [31104/321526 (10%)] Loss: 2.000085; lr: 2.3313173363346958e-05; Time/iteration: 0.390m; Time so far/epoch: 0.401h
2024-05-02 00:26:00,351 - trainer - INFO - Train Epoch: 7 dl0 [31680/321526 (10%)] Loss: 1.812008; lr: 2.330193496304533e-05; Time/iteration: 0.403m; Time so far/epoch: 0.408h
2024-05-02 00:26:24,813 - trainer - INFO - Train Epoch: 7 dl0 [32256/321526 (10%)] Loss: 1.806110; lr: 2.3290689876003944e-05; Time/iteration: 0.408m; Time so far/epoch: 0.415h
2024-05-02 00:26:49,285 - trainer - INFO - Train Epoch: 7 dl0 [32832/321526 (10%)] Loss: 1.946471; lr: 2.327943811144674e-05; Time/iteration: 0.408m; Time so far/epoch: 0.422h
2024-05-02 00:27:13,753 - trainer - INFO - Train Epoch: 7 dl0 [33408/321526 (10%)] Loss: 1.783986; lr: 2.326817967860315e-05; Time/iteration: 0.408m; Time so far/epoch: 0.428h
2024-05-02 00:27:37,380 - trainer - INFO - Train Epoch: 7 dl0 [33984/321526 (11%)] Loss: 1.856752; lr: 2.325691458670805e-05; Time/iteration: 0.394m; Time so far/epoch: 0.435h
2024-05-02 00:28:02,000 - trainer - INFO - Train Epoch: 7 dl0 [34560/321526 (11%)] Loss: 1.975216; lr: 2.3245642845001798e-05; Time/iteration: 0.410m; Time so far/epoch: 0.442h
2024-05-02 00:28:26,367 - trainer - INFO - Train Epoch: 7 dl0 [35136/321526 (11%)] Loss: 1.951740; lr: 2.3234364462730193e-05; Time/iteration: 0.406m; Time so far/epoch: 0.449h
2024-05-02 00:28:51,635 - trainer - INFO - Train Epoch: 7 dl0 [35712/321526 (11%)] Loss: 1.967354; lr: 2.322307944914449e-05; Time/iteration: 0.421m; Time so far/epoch: 0.456h
2024-05-02 00:29:15,228 - trainer - INFO - Train Epoch: 7 dl0 [36288/321526 (11%)] Loss: 2.019045; lr: 2.3211787813501388e-05; Time/iteration: 0.393m; Time so far/epoch: 0.462h
2024-05-02 00:29:39,085 - trainer - INFO - Train Epoch: 7 dl0 [36864/321526 (11%)] Loss: 1.827085; lr: 2.3200489565062997e-05; Time/iteration: 0.398m; Time so far/epoch: 0.469h
2024-05-02 00:30:03,447 - trainer - INFO - Train Epoch: 7 dl0 [37440/321526 (12%)] Loss: 1.965667; lr: 2.3189184713096873e-05; Time/iteration: 0.406m; Time so far/epoch: 0.476h
2024-05-02 00:30:27,818 - trainer - INFO - Train Epoch: 7 dl0 [38016/321526 (12%)] Loss: 1.897184; lr: 2.3177873266875985e-05; Time/iteration: 0.406m; Time so far/epoch: 0.482h
2024-05-02 00:30:52,633 - trainer - INFO - Train Epoch: 7 dl0 [38592/321526 (12%)] Loss: 1.896080; lr: 2.3166555235678694e-05; Time/iteration: 0.414m; Time so far/epoch: 0.489h
2024-05-02 00:31:17,707 - trainer - INFO - Train Epoch: 7 dl0 [39168/321526 (12%)] Loss: 1.955210; lr: 2.315523062878878e-05; Time/iteration: 0.418m; Time so far/epoch: 0.496h
2024-05-02 00:31:42,859 - trainer - INFO - Train Epoch: 7 dl0 [39744/321526 (12%)] Loss: 1.797132; lr: 2.3143899455495418e-05; Time/iteration: 0.419m; Time so far/epoch: 0.503h
2024-05-02 00:32:08,251 - trainer - INFO - Train Epoch: 7 dl0 [40320/321526 (13%)] Loss: 1.996999; lr: 2.3132561725093155e-05; Time/iteration: 0.423m; Time so far/epoch: 0.510h
2024-05-02 00:32:33,445 - trainer - INFO - Train Epoch: 7 dl0 [40896/321526 (13%)] Loss: 1.938283; lr: 2.312121744688193e-05; Time/iteration: 0.420m; Time so far/epoch: 0.517h
2024-05-02 00:33:00,002 - trainer - INFO - Train Epoch: 7 dl0 [41472/321526 (13%)] Loss: 1.798696; lr: 2.3109866630167045e-05; Time/iteration: 0.443m; Time so far/epoch: 0.525h
2024-05-02 00:33:26,454 - trainer - INFO - Train Epoch: 7 dl0 [42048/321526 (13%)] Loss: 1.996208; lr: 2.3098509284259165e-05; Time/iteration: 0.441m; Time so far/epoch: 0.532h
2024-05-02 00:33:53,224 - trainer - INFO - Train Epoch: 7 dl0 [42624/321526 (13%)] Loss: 1.853696; lr: 2.3087145418474315e-05; Time/iteration: 0.446m; Time so far/epoch: 0.539h
2024-05-02 00:34:19,254 - trainer - INFO - Train Epoch: 7 dl0 [43200/321526 (13%)] Loss: 1.981198; lr: 2.307577504213387e-05; Time/iteration: 0.434m; Time so far/epoch: 0.547h
2024-05-02 00:34:44,055 - trainer - INFO - Train Epoch: 7 dl0 [43776/321526 (14%)] Loss: 1.738715; lr: 2.3064398164564543e-05; Time/iteration: 0.413m; Time so far/epoch: 0.553h
2024-05-02 00:35:09,052 - trainer - INFO - Train Epoch: 7 dl0 [44352/321526 (14%)] Loss: 1.937229; lr: 2.3053014795098368e-05; Time/iteration: 0.417m; Time so far/epoch: 0.560h
2024-05-02 00:35:31,944 - trainer - INFO - Train Epoch: 7 dl0 [44928/321526 (14%)] Loss: 1.968650; lr: 2.3041624943072723e-05; Time/iteration: 0.382m; Time so far/epoch: 0.567h
2024-05-02 00:35:55,190 - trainer - INFO - Train Epoch: 7 dl0 [45504/321526 (14%)] Loss: 1.976817; lr: 2.3030228617830292e-05; Time/iteration: 0.387m; Time so far/epoch: 0.573h
2024-05-02 00:36:18,921 - trainer - INFO - Train Epoch: 7 dl0 [46080/321526 (14%)] Loss: 1.790695; lr: 2.3018825828719074e-05; Time/iteration: 0.395m; Time so far/epoch: 0.580h
2024-05-02 00:36:43,741 - trainer - INFO - Train Epoch: 7 dl0 [46656/321526 (15%)] Loss: 2.014376; lr: 2.300741658509237e-05; Time/iteration: 0.414m; Time so far/epoch: 0.587h
2024-05-02 00:37:07,581 - trainer - INFO - Train Epoch: 7 dl0 [47232/321526 (15%)] Loss: 1.839921; lr: 2.2996000896308765e-05; Time/iteration: 0.397m; Time so far/epoch: 0.593h
2024-05-02 00:37:30,436 - trainer - INFO - Train Epoch: 7 dl0 [47808/321526 (15%)] Loss: 1.899731; lr: 2.298457877173214e-05; Time/iteration: 0.381m; Time so far/epoch: 0.600h
2024-05-02 00:37:54,802 - trainer - INFO - Train Epoch: 7 dl0 [48384/321526 (15%)] Loss: 2.004925; lr: 2.2973150220731665e-05; Time/iteration: 0.406m; Time so far/epoch: 0.606h
2024-05-02 00:38:18,557 - trainer - INFO - Train Epoch: 7 dl0 [48960/321526 (15%)] Loss: 1.860035; lr: 2.2961715252681758e-05; Time/iteration: 0.396m; Time so far/epoch: 0.613h
2024-05-02 00:38:43,346 - trainer - INFO - Train Epoch: 7 dl0 [49536/321526 (15%)] Loss: 1.950750; lr: 2.2950273876962117e-05; Time/iteration: 0.413m; Time so far/epoch: 0.620h
2024-05-02 00:39:07,865 - trainer - INFO - Train Epoch: 7 dl0 [50112/321526 (16%)] Loss: 1.897060; lr: 2.2938826102957697e-05; Time/iteration: 0.409m; Time so far/epoch: 0.627h
2024-05-02 00:39:31,711 - trainer - INFO - Train Epoch: 7 dl0 [50688/321526 (16%)] Loss: 1.945692; lr: 2.292737194005869e-05; Time/iteration: 0.397m; Time so far/epoch: 0.633h
2024-05-02 00:39:55,785 - trainer - INFO - Train Epoch: 7 dl0 [51264/321526 (16%)] Loss: 1.832948; lr: 2.2915911397660537e-05; Time/iteration: 0.401m; Time so far/epoch: 0.640h
2024-05-02 00:40:19,749 - trainer - INFO - Train Epoch: 7 dl0 [51840/321526 (16%)] Loss: 1.972892; lr: 2.2904444485163905e-05; Time/iteration: 0.399m; Time so far/epoch: 0.647h
2024-05-02 00:40:45,393 - trainer - INFO - Train Epoch: 7 dl0 [52416/321526 (16%)] Loss: 1.895815; lr: 2.2892971211974704e-05; Time/iteration: 0.427m; Time so far/epoch: 0.654h
2024-05-02 00:41:09,406 - trainer - INFO - Train Epoch: 7 dl0 [52992/321526 (16%)] Loss: 1.981588; lr: 2.2881491587504034e-05; Time/iteration: 0.400m; Time so far/epoch: 0.661h
2024-05-02 00:41:34,109 - trainer - INFO - Train Epoch: 7 dl0 [53568/321526 (17%)] Loss: 1.904435; lr: 2.2870005621168227e-05; Time/iteration: 0.412m; Time so far/epoch: 0.667h
2024-05-02 00:41:58,688 - trainer - INFO - Train Epoch: 7 dl0 [54144/321526 (17%)] Loss: 1.990322; lr: 2.2858513322388804e-05; Time/iteration: 0.410m; Time so far/epoch: 0.674h
2024-05-02 00:42:22,831 - trainer - INFO - Train Epoch: 7 dl0 [54720/321526 (17%)] Loss: 1.829711; lr: 2.2847014700592492e-05; Time/iteration: 0.402m; Time so far/epoch: 0.681h
2024-05-02 00:42:47,112 - trainer - INFO - Train Epoch: 7 dl0 [55296/321526 (17%)] Loss: 1.971591; lr: 2.2835509765211194e-05; Time/iteration: 0.405m; Time so far/epoch: 0.688h
2024-05-02 00:43:10,660 - trainer - INFO - Train Epoch: 7 dl0 [55872/321526 (17%)] Loss: 1.940210; lr: 2.2823998525681994e-05; Time/iteration: 0.392m; Time so far/epoch: 0.694h
2024-05-02 00:43:34,271 - trainer - INFO - Train Epoch: 7 dl0 [56448/321526 (18%)] Loss: 2.134773; lr: 2.2812480991447153e-05; Time/iteration: 0.394m; Time so far/epoch: 0.701h
2024-05-02 00:43:58,034 - trainer - INFO - Train Epoch: 7 dl0 [57024/321526 (18%)] Loss: 1.874229; lr: 2.2800957171954085e-05; Time/iteration: 0.396m; Time so far/epoch: 0.707h
2024-05-02 00:44:22,304 - trainer - INFO - Train Epoch: 7 dl0 [57600/321526 (18%)] Loss: 1.810503; lr: 2.2789427076655373e-05; Time/iteration: 0.404m; Time so far/epoch: 0.714h
2024-05-02 00:44:46,647 - trainer - INFO - Train Epoch: 7 dl0 [58176/321526 (18%)] Loss: 1.895625; lr: 2.277789071500873e-05; Time/iteration: 0.406m; Time so far/epoch: 0.721h
2024-05-02 00:45:10,045 - trainer - INFO - Train Epoch: 7 dl0 [58752/321526 (18%)] Loss: 1.851815; lr: 2.2766348096477036e-05; Time/iteration: 0.390m; Time so far/epoch: 0.727h
2024-05-02 00:45:34,068 - trainer - INFO - Train Epoch: 7 dl0 [59328/321526 (18%)] Loss: 1.888999; lr: 2.2754799230528272e-05; Time/iteration: 0.400m; Time so far/epoch: 0.734h
2024-05-02 00:45:57,278 - trainer - INFO - Train Epoch: 7 dl0 [59904/321526 (19%)] Loss: 1.987977; lr: 2.2743244126635562e-05; Time/iteration: 0.387m; Time so far/epoch: 0.740h
2024-05-02 00:46:22,418 - trainer - INFO - Train Epoch: 7 dl0 [60480/321526 (19%)] Loss: 1.836840; lr: 2.2731682794277152e-05; Time/iteration: 0.419m; Time so far/epoch: 0.747h
2024-05-02 00:46:46,668 - trainer - INFO - Train Epoch: 7 dl0 [61056/321526 (19%)] Loss: 2.057341; lr: 2.272011524293637e-05; Time/iteration: 0.404m; Time so far/epoch: 0.754h
2024-05-02 00:47:10,366 - trainer - INFO - Train Epoch: 7 dl0 [61632/321526 (19%)] Loss: 1.948125; lr: 2.270854148210168e-05; Time/iteration: 0.395m; Time so far/epoch: 0.761h
2024-05-02 00:47:34,764 - trainer - INFO - Train Epoch: 7 dl0 [62208/321526 (19%)] Loss: 2.066259; lr: 2.2696961521266613e-05; Time/iteration: 0.407m; Time so far/epoch: 0.768h
2024-05-02 00:47:58,178 - trainer - INFO - Train Epoch: 7 dl0 [62784/321526 (20%)] Loss: 1.789202; lr: 2.2685375369929805e-05; Time/iteration: 0.390m; Time so far/epoch: 0.774h
2024-05-02 00:48:22,541 - trainer - INFO - Train Epoch: 7 dl0 [63360/321526 (20%)] Loss: 1.928022; lr: 2.2673783037594954e-05; Time/iteration: 0.406m; Time so far/epoch: 0.781h
2024-05-02 00:48:47,083 - trainer - INFO - Train Epoch: 7 dl0 [63936/321526 (20%)] Loss: 1.773349; lr: 2.266218453377083e-05; Time/iteration: 0.409m; Time so far/epoch: 0.788h
2024-05-02 00:49:11,382 - trainer - INFO - Train Epoch: 7 dl0 [64512/321526 (20%)] Loss: 1.905128; lr: 2.265057986797128e-05; Time/iteration: 0.405m; Time so far/epoch: 0.794h
2024-05-02 00:49:34,894 - trainer - INFO - Train Epoch: 7 dl0 [65088/321526 (20%)] Loss: 1.885845; lr: 2.2638969049715182e-05; Time/iteration: 0.392m; Time so far/epoch: 0.801h
2024-05-02 00:49:58,366 - trainer - INFO - Train Epoch: 7 dl0 [65664/321526 (20%)] Loss: 1.967731; lr: 2.2627352088526485e-05; Time/iteration: 0.391m; Time so far/epoch: 0.807h
2024-05-02 00:50:23,418 - trainer - INFO - Train Epoch: 7 dl0 [66240/321526 (21%)] Loss: 1.767968; lr: 2.261572899393416e-05; Time/iteration: 0.418m; Time so far/epoch: 0.814h
2024-05-02 00:50:47,302 - trainer - INFO - Train Epoch: 7 dl0 [66816/321526 (21%)] Loss: 1.887842; lr: 2.2604099775472216e-05; Time/iteration: 0.398m; Time so far/epoch: 0.821h
2024-05-02 00:51:11,605 - trainer - INFO - Train Epoch: 7 dl0 [67392/321526 (21%)] Loss: 1.968171; lr: 2.2592464442679682e-05; Time/iteration: 0.405m; Time so far/epoch: 0.828h
2024-05-02 00:51:34,972 - trainer - INFO - Train Epoch: 7 dl0 [67968/321526 (21%)] Loss: 1.933808; lr: 2.2580823005100607e-05; Time/iteration: 0.389m; Time so far/epoch: 0.834h
2024-05-02 00:51:58,668 - trainer - INFO - Train Epoch: 7 dl0 [68544/321526 (21%)] Loss: 1.914591; lr: 2.2569175472284042e-05; Time/iteration: 0.395m; Time so far/epoch: 0.841h
2024-05-02 00:52:22,937 - trainer - INFO - Train Epoch: 7 dl0 [69120/321526 (21%)] Loss: 1.864049; lr: 2.2557521853784047e-05; Time/iteration: 0.404m; Time so far/epoch: 0.848h
2024-05-02 00:52:47,481 - trainer - INFO - Train Epoch: 7 dl0 [69696/321526 (22%)] Loss: 1.990559; lr: 2.2545862159159652e-05; Time/iteration: 0.409m; Time so far/epoch: 0.854h
2024-05-02 00:53:12,398 - trainer - INFO - Train Epoch: 7 dl0 [70272/321526 (22%)] Loss: 1.859588; lr: 2.25341963979749e-05; Time/iteration: 0.415m; Time so far/epoch: 0.861h
2024-05-02 00:53:37,278 - trainer - INFO - Train Epoch: 7 dl0 [70848/321526 (22%)] Loss: 1.902084; lr: 2.2522524579798788e-05; Time/iteration: 0.415m; Time so far/epoch: 0.868h
2024-05-02 00:54:01,724 - trainer - INFO - Train Epoch: 7 dl0 [71424/321526 (22%)] Loss: 2.006355; lr: 2.25108467142053e-05; Time/iteration: 0.407m; Time so far/epoch: 0.875h
2024-05-02 00:54:25,262 - trainer - INFO - Train Epoch: 7 dl0 [72000/321526 (22%)] Loss: 1.941995; lr: 2.249916281077336e-05; Time/iteration: 0.392m; Time so far/epoch: 0.882h
2024-05-02 00:54:49,313 - trainer - INFO - Train Epoch: 7 dl0 [72576/321526 (23%)] Loss: 1.901995; lr: 2.2487472879086857e-05; Time/iteration: 0.401m; Time so far/epoch: 0.888h
2024-05-02 00:55:13,238 - trainer - INFO - Train Epoch: 7 dl0 [73152/321526 (23%)] Loss: 1.832310; lr: 2.2475776928734622e-05; Time/iteration: 0.399m; Time so far/epoch: 0.895h
2024-05-02 00:55:37,317 - trainer - INFO - Train Epoch: 7 dl0 [73728/321526 (23%)] Loss: 1.982527; lr: 2.2464074969310433e-05; Time/iteration: 0.401m; Time so far/epoch: 0.902h
2024-05-02 00:56:02,285 - trainer - INFO - Train Epoch: 7 dl0 [74304/321526 (23%)] Loss: 1.845810; lr: 2.2452367010412974e-05; Time/iteration: 0.416m; Time so far/epoch: 0.909h
2024-05-02 00:56:25,653 - trainer - INFO - Train Epoch: 7 dl0 [74880/321526 (23%)] Loss: 1.941680; lr: 2.2440653061645867e-05; Time/iteration: 0.389m; Time so far/epoch: 0.915h
2024-05-02 00:56:49,605 - trainer - INFO - Train Epoch: 7 dl0 [75456/321526 (23%)] Loss: 2.010171; lr: 2.2428933132617653e-05; Time/iteration: 0.399m; Time so far/epoch: 0.922h
2024-05-02 00:57:13,639 - trainer - INFO - Train Epoch: 7 dl0 [76032/321526 (24%)] Loss: 1.902664; lr: 2.2417207232941757e-05; Time/iteration: 0.401m; Time so far/epoch: 0.928h
2024-05-02 00:57:38,547 - trainer - INFO - Train Epoch: 7 dl0 [76608/321526 (24%)] Loss: 1.882251; lr: 2.240547537223652e-05; Time/iteration: 0.415m; Time so far/epoch: 0.935h
2024-05-02 00:58:03,087 - trainer - INFO - Train Epoch: 7 dl0 [77184/321526 (24%)] Loss: 1.923144; lr: 2.2393737560125165e-05; Time/iteration: 0.409m; Time so far/epoch: 0.942h
2024-05-02 00:58:26,889 - trainer - INFO - Train Epoch: 7 dl0 [77760/321526 (24%)] Loss: 1.869873; lr: 2.23819938062358e-05; Time/iteration: 0.397m; Time so far/epoch: 0.949h
2024-05-02 00:58:50,991 - trainer - INFO - Train Epoch: 7 dl0 [78336/321526 (24%)] Loss: 1.910335; lr: 2.23702441202014e-05; Time/iteration: 0.402m; Time so far/epoch: 0.955h
2024-05-02 00:59:14,791 - trainer - INFO - Train Epoch: 7 dl0 [78912/321526 (25%)] Loss: 1.881581; lr: 2.235848851165982e-05; Time/iteration: 0.397m; Time so far/epoch: 0.962h
2024-05-02 00:59:39,680 - trainer - INFO - Train Epoch: 7 dl0 [79488/321526 (25%)] Loss: 1.885522; lr: 2.2346726990253756e-05; Time/iteration: 0.415m; Time so far/epoch: 0.969h
2024-05-02 01:00:04,151 - trainer - INFO - Train Epoch: 7 dl0 [80064/321526 (25%)] Loss: 1.893800; lr: 2.2334959565630764e-05; Time/iteration: 0.408m; Time so far/epoch: 0.976h
2024-05-02 01:00:28,428 - trainer - INFO - Train Epoch: 7 dl0 [80640/321526 (25%)] Loss: 1.927721; lr: 2.2323186247443242e-05; Time/iteration: 0.405m; Time so far/epoch: 0.982h
2024-05-02 01:00:52,704 - trainer - INFO - Train Epoch: 7 dl0 [81216/321526 (25%)] Loss: 1.891786; lr: 2.2311407045348416e-05; Time/iteration: 0.404m; Time so far/epoch: 0.989h
2024-05-02 01:01:16,125 - trainer - INFO - Train Epoch: 7 dl0 [81792/321526 (25%)] Loss: 1.950817; lr: 2.2299621969008348e-05; Time/iteration: 0.390m; Time so far/epoch: 0.996h
2024-05-02 01:01:40,669 - trainer - INFO - Train Epoch: 7 dl0 [82368/321526 (26%)] Loss: 1.927632; lr: 2.228783102808991e-05; Time/iteration: 0.409m; Time so far/epoch: 1.003h
2024-05-02 01:02:04,582 - trainer - INFO - Train Epoch: 7 dl0 [82944/321526 (26%)] Loss: 1.919756; lr: 2.227603423226479e-05; Time/iteration: 0.399m; Time so far/epoch: 1.009h
2024-05-02 01:02:28,390 - trainer - INFO - Train Epoch: 7 dl0 [83520/321526 (26%)] Loss: 1.808816; lr: 2.2264231591209472e-05; Time/iteration: 0.397m; Time so far/epoch: 1.016h
2024-05-02 01:02:52,526 - trainer - INFO - Train Epoch: 7 dl0 [84096/321526 (26%)] Loss: 1.897947; lr: 2.225242311460525e-05; Time/iteration: 0.402m; Time so far/epoch: 1.023h
2024-05-02 01:03:16,245 - trainer - INFO - Train Epoch: 7 dl0 [84672/321526 (26%)] Loss: 1.864045; lr: 2.224060881213818e-05; Time/iteration: 0.395m; Time so far/epoch: 1.029h
2024-05-02 01:03:41,355 - trainer - INFO - Train Epoch: 7 dl0 [85248/321526 (27%)] Loss: 1.871704; lr: 2.222878869349912e-05; Time/iteration: 0.418m; Time so far/epoch: 1.036h
2024-05-02 01:04:05,275 - trainer - INFO - Train Epoch: 7 dl0 [85824/321526 (27%)] Loss: 1.841984; lr: 2.221696276838368e-05; Time/iteration: 0.399m; Time so far/epoch: 1.043h
2024-05-02 01:04:29,612 - trainer - INFO - Train Epoch: 7 dl0 [86400/321526 (27%)] Loss: 1.922499; lr: 2.220513104649225e-05; Time/iteration: 0.406m; Time so far/epoch: 1.049h
2024-05-02 01:04:53,293 - trainer - INFO - Train Epoch: 7 dl0 [86976/321526 (27%)] Loss: 1.920465; lr: 2.2193293537529962e-05; Time/iteration: 0.395m; Time so far/epoch: 1.056h
2024-05-02 01:05:16,758 - trainer - INFO - Train Epoch: 7 dl0 [87552/321526 (27%)] Loss: 1.923461; lr: 2.2181450251206707e-05; Time/iteration: 0.391m; Time so far/epoch: 1.063h
2024-05-02 01:05:40,681 - trainer - INFO - Train Epoch: 7 dl0 [88128/321526 (27%)] Loss: 1.778376; lr: 2.2169601197237102e-05; Time/iteration: 0.399m; Time so far/epoch: 1.069h
2024-05-02 01:06:04,791 - trainer - INFO - Train Epoch: 7 dl0 [88704/321526 (28%)] Loss: 2.144109; lr: 2.21577463853405e-05; Time/iteration: 0.402m; Time so far/epoch: 1.076h
2024-05-02 01:06:29,814 - trainer - INFO - Train Epoch: 7 dl0 [89280/321526 (28%)] Loss: 1.941952; lr: 2.214588582524098e-05; Time/iteration: 0.417m; Time so far/epoch: 1.083h
2024-05-02 01:06:53,392 - trainer - INFO - Train Epoch: 7 dl0 [89856/321526 (28%)] Loss: 1.905798; lr: 2.2134019526667333e-05; Time/iteration: 0.393m; Time so far/epoch: 1.089h
2024-05-02 01:07:17,290 - trainer - INFO - Train Epoch: 7 dl0 [90432/321526 (28%)] Loss: 1.929022; lr: 2.2122147499353063e-05; Time/iteration: 0.398m; Time so far/epoch: 1.096h
2024-05-02 01:07:41,646 - trainer - INFO - Train Epoch: 7 dl0 [91008/321526 (28%)] Loss: 2.011217; lr: 2.211026975303636e-05; Time/iteration: 0.406m; Time so far/epoch: 1.103h
2024-05-02 01:08:05,519 - trainer - INFO - Train Epoch: 7 dl0 [91584/321526 (28%)] Loss: 1.897177; lr: 2.209838629746012e-05; Time/iteration: 0.398m; Time so far/epoch: 1.109h
2024-05-02 01:08:30,160 - trainer - INFO - Train Epoch: 7 dl0 [92160/321526 (29%)] Loss: 1.886009; lr: 2.2086497142371904e-05; Time/iteration: 0.411m; Time so far/epoch: 1.116h
2024-05-02 01:08:53,559 - trainer - INFO - Train Epoch: 7 dl0 [92736/321526 (29%)] Loss: 1.864659; lr: 2.2074602297523978e-05; Time/iteration: 0.390m; Time so far/epoch: 1.123h
2024-05-02 01:09:18,537 - trainer - INFO - Train Epoch: 7 dl0 [93312/321526 (29%)] Loss: 1.859208; lr: 2.206270177267324e-05; Time/iteration: 0.416m; Time so far/epoch: 1.130h
2024-05-02 01:09:42,057 - trainer - INFO - Train Epoch: 7 dl0 [93888/321526 (29%)] Loss: 1.873719; lr: 2.2050795577581272e-05; Time/iteration: 0.392m; Time so far/epoch: 1.136h
2024-05-02 01:10:06,496 - trainer - INFO - Train Epoch: 7 dl0 [94464/321526 (29%)] Loss: 2.000500; lr: 2.203888372201429e-05; Time/iteration: 0.407m; Time so far/epoch: 1.143h
2024-05-02 01:10:32,016 - trainer - INFO - Train Epoch: 7 dl0 [95040/321526 (30%)] Loss: 1.997960; lr: 2.2026966215743176e-05; Time/iteration: 0.425m; Time so far/epoch: 1.150h
2024-05-02 01:10:55,644 - trainer - INFO - Train Epoch: 7 dl0 [95616/321526 (30%)] Loss: 2.118943; lr: 2.201504306854342e-05; Time/iteration: 0.394m; Time so far/epoch: 1.157h
2024-05-02 01:11:19,262 - trainer - INFO - Train Epoch: 7 dl0 [96192/321526 (30%)] Loss: 1.805010; lr: 2.2003114290195156e-05; Time/iteration: 0.394m; Time so far/epoch: 1.163h
2024-05-02 01:11:43,103 - trainer - INFO - Train Epoch: 7 dl0 [96768/321526 (30%)] Loss: 1.940185; lr: 2.1991179890483135e-05; Time/iteration: 0.397m; Time so far/epoch: 1.170h
2024-05-02 01:12:08,058 - trainer - INFO - Train Epoch: 7 dl0 [97344/321526 (30%)] Loss: 1.937810; lr: 2.1979239879196714e-05; Time/iteration: 0.416m; Time so far/epoch: 1.177h
2024-05-02 01:12:32,252 - trainer - INFO - Train Epoch: 7 dl0 [97920/321526 (30%)] Loss: 1.924262; lr: 2.1967294266129857e-05; Time/iteration: 0.403m; Time so far/epoch: 1.184h
2024-05-02 01:12:55,458 - trainer - INFO - Train Epoch: 7 dl0 [98496/321526 (31%)] Loss: 1.829572; lr: 2.195534306108112e-05; Time/iteration: 0.387m; Time so far/epoch: 1.190h
2024-05-02 01:13:19,350 - trainer - INFO - Train Epoch: 7 dl0 [99072/321526 (31%)] Loss: 1.924566; lr: 2.194338627385365e-05; Time/iteration: 0.398m; Time so far/epoch: 1.197h
2024-05-02 01:13:42,618 - trainer - INFO - Train Epoch: 7 dl0 [99648/321526 (31%)] Loss: 1.910908; lr: 2.1931423914255174e-05; Time/iteration: 0.387m; Time so far/epoch: 1.203h
2024-05-02 01:17:22,019 - trainer - INFO - EgoClip_HOI epoch 7, Verb-Neg, Acc: 56.1;    EgoClip_HOI epoch 7, Noun-Neg, Acc: 69.2;    EgoClip_HOI epoch 7, HOI-Neg, Acc: 41.5;    
2024-05-02 01:17:22,026 - trainer - INFO -     epoch          : 7
2024-05-02 01:17:22,027 - trainer - INFO -     loss_0         : 0.5957384638278088
2024-05-02 01:17:22,027 - trainer - INFO -     val_loss_0     : 0.0
2024-05-02 01:17:22,028 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Verb-Neg: 56.066226959228516
2024-05-02 01:17:22,028 - trainer - INFO -     val_0_egohoi_accuracy_metrics_Noun-Neg: 69.23725891113281
2024-05-02 01:17:22,028 - trainer - INFO -     val_0_egohoi_accuracy_metrics_HOI-Neg: 41.543025970458984
2024-05-02 01:17:23,082 - trainer - INFO - Saving checkpoint: results/EgoHOI/verb_noun_and_t2v/lora_10w_3e-5_neg10/models/0501_16/checkpoint-epoch7.pth ...
2024-05-02 01:17:25,231 - trainer - INFO - Saving current best: model_best.pth ...
